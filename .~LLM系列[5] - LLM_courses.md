# Learning Notes - LLM courses

> æƒ³å­¦ä¹ å¤§è¯­è¨€æ¨¡å‹(LLM)ï¼Œåº”è¯¥ä»å“ªä¸ªå¼€æºæ¨¡å‹å¼€å§‹ï¼Ÿ - LeonYiçš„å›ç­” - çŸ¥ä¹
> https://www.zhihu.com/question/608820310/answer/3401824221

> <img src="assets/image-20240415151449094.png" alt="image-20240415151449094" style="zoom: 16%;" /> <img src="assets/image-20240415151531485.png" alt="image-20240415151531485" style="zoom: 17%;" /><img src="assets/image-20240415151559174.png" alt="image-20240415151559174" style="zoom: 20%;" />

â‘  The LLM architecture

- [x] **[Visual intro to Transformers](https://www.youtube.com/watch?v=wjZofJX0v4M&t=187s) by 3Blue1Brown: Simple easy to understand visual intro to Transformers**
- [x] **[Attention? Attention!](https://lilianweng.github.io/posts/2018-06-24-attention/) by Lilian Weng: Introduce the need for attention in a more formal way.**
- [x] **[Decoding Strategies in LLMs](https://mlabonne.github.io/blog/posts/2023-06-07-Decoding_strategies.html): Provide code and a visual introduction to the different decoding strategies to generate text.**

â‘¡ Building an instruction dataset

- [x] [Preparing a Dataset for Instruction tuning](https://wandb.ai/capecape/alpaca_ft/reports/How-to-Fine-Tune-an-LLM-Part-1-Preparing-a-Dataset-for-Instruction-Tuning--Vmlldzo1NTcxNzE2) by Thomas Capelle: 

  Exploration of the Alpaca and Alpaca-GPT4 datasets and how to format them.

- [x] [Generating a Clinical Instruction Dataset](https://medium.com/mlearning-ai/generating-a-clinical-instruction-dataset-in-portuguese-with-langchain-and-gpt-4-6ee9abfa41ae) by Solano Todeschini: Tutorial on how to create a synthetic instruction dataset using GPT-4.

- [x] [Dataset creation for fine-tuning LLM](https://colab.research.google.com/drive/1GH8PW9-zAe4cXEZyOIE-T9uHXblIldAg?usp=sharing): Notebook that contains a few techniques to filter a dataset and upload the result.

- [x] [Chat Template](https://huggingface.co/blog/chat-templates) by Matthew Carrigan: Hugging Face's page about prompt templates

â‘¢ Pre-training models

- [x] [LLMDataHub](https://github.com/Zjh-819/LLMDataHub) by Junhao Zhao: Curated list of datasets for pre-training, fine-tuning, and RLHF.
- [x] **[TinyLlama](https://github.com/jzhang38/TinyLlama) by Zhang et al.: Check this project to get a good understanding of how a Llama model is trained from scratch.**
- [x] **[Chinchilla's wild implications](https://www.lesswrong.com/posts/6Fpvch8RR29qLEWNH/chinchilla-s-wild-implications) by nostalgebraist: Discuss the scaling laws and explain what they mean to LLMs in general.**
- [x] **[BLOOM](https://bigscience.notion.site/BLOOM-BigScience-176B-Model-ad073ca07cdf479398d5f95d88e218c4) by BigScience: Notion page that describes how the BLOOM model was built, with a lot of useful information about the engineering part and the problems that were encountered.**
- [x] **[OPT-175 Logbook](https://github.com/facebookresearch/metaseq/blob/main/projects/OPT/chronicles/OPT175B_Logbook.pdf) by Meta: Research logs showing what went wrong and what went right. Useful if you're planning to pre-train a very large language model (in this case, 175B parameters).**
- [x] [LLM 360](https://www.llm360.ai/): A framework for open-source LLMs with training and data preparation code, data, metrics, and models.

â‘£ Supervised Fine-Tuning

- [x] **[The Novice's LLM Training Guide](https://rentry.org/llm-training) by Alpin: **

  **Overview of the main concepts and parameters to consider when fine-tuning LLMs.**

- [x] [LoRA insights](https://lightning.ai/pages/community/lora-insights/) by Sebastian Raschka: Practical insights about LoRA and how to select the best parameters.

- [x] [Fine-Tune Your Own Llama 2 Model](https://mlabonne.github.io/blog/posts/Fine_Tune_Your_Own_Llama_2_Model_in_a_Colab_Notebook.html): Hands-on tutorial on how to fine-tune a Llama 2 model using Hugging Face libraries.

â‘¤ Reinforcement Learning from Human Feedback

- [x] **[An Introduction to Training LLMs using RLHF](https://wandb.ai/ayush-thakur/Intro-RLAIF/reports/An-Introduction-to-Training-LLMs-Using-Reinforcement-Learning-From-Human-Feedback-RLHF---VmlldzozMzYyNjcy) by Ayush Thakur: **

  **Explain why RLHF is desirable to reduce bias and increase performance in LLMs.**

- [x] **[Illustration RLHF](https://huggingface.co/blog/rlhf) by Hugging Face: Introduction to RLHF with reward model training and fine-tuning with reinforcement learning.**

- [x] **[LLM Training: RLHF and Its Alternatives](https://substack.com/profile/27393275-sebastian-raschka-phd) by Sebastian Rashcka: Overview of the RLHF process and alternatives like RLAIF.**

  > [LLM Training: RLHF and Its Alternatives (sebastianraschka.com)](https://magazine.sebastianraschka.com/p/llm-training-rlhf-and-its-alternatives?utm_source=%2Fsearch%2FRLHF%20and%20Its%20Alternatives&utm_medium=reader2)

- [x] [Fine-tune Mistral-7b with DPO](https://huggingface.co/blog/dpo-trl): Tutorial to fine-tune a Mistral-7b model with DPO and reproduce [NeuralHermes-2.5](https://huggingface.co/mlabonne/NeuralHermes-2.5-Mistral-7B).

â‘¥ Evaluation

- [x] **[Perplexity of fixed-length models](https://huggingface.co/docs/transformers/perplexity) by Hugging Face: Overview of perplexity with code to implement it with the transformers library.**
- [x] **[BLEU at your own risk](https://towardsdatascience.com/evaluating-text-output-in-nlp-bleu-at-your-own-risk-e8609665a213) by Rachael Tatman: Overview of the BLEU score and its many issues with examples.**

- [x] **[A Survey on Evaluation of LLMs](https://arxiv.org/abs/2307.03109) by Chang et al.:** 

  **Comprehensive paper about what to evaluate, where to evaluate, and how to evaluate.**

- [x] **[Chatbot Arena Leaderboard](https://huggingface.co/spaces/lmsys/chatbot-arena-leaderboard) by lmsys: Elo rating of general-purpose LLMs, based on comparisons made by humans.**

â‘¦ Quantization

- [x] **[Introduction to quantization](https://mlabonne.github.io/blog/posts/Introduction_to_Weight_Quantization.html): Overview of quantization, absmax and zero-point quantization, and LLM.int8() with code.** 

â‘§ New Trends (MoE)

- [x] **[Extending the RoPE](https://blog.eleuther.ai/yarn/) by EleutherAI: Article that summarizes the different position-encoding techniques.**
- [x] [Merge LLMs with mergekit](https://mlabonne.github.io/blog/posts/2024-01-08_Merge_LLMs_with_mergekit.html): Tutorial about model merging using mergekit.
- [x] **[Mixture of Experts Explained](https://huggingface.co/blog/moe) by Hugging Face: Exhaustive guide about MoEs and how they work.**

---

## Part â…  The LLM architecture

### â‘  ç†è§£ Transformers By 3B1B

> **3Blue1Brown: Simple easy to understand visual intro to Transformers**
>
> **[ä½†ä»€ä¹ˆæ˜¯ GPTï¼Ÿé€šè¿‡å›¾å½¢åŒ–çš„æ–¹å¼æ¥ç†è§£ Transformer æ¶æ„ | æ·±åº¦å­¦ä¹ ï¼Œç¬¬ 5 ç«  (youtube.com)](https://www.youtube.com/watch?v=wjZofJX0v4M&t=187s)**
>
> **[å¯è§†åŒ–æ³¨æ„åŠ›ï¼Œå˜å½¢é‡‘åˆšçš„å¿ƒè„ | ç¬¬ 6 ç« ï¼Œæ·±åº¦å­¦ä¹  (youtube.com)](https://www.youtube.com/watch?v=eMlx5fFNoYc)**

åœ¨ Transformers ä¸­,æ³¨æ„åŠ›æœºåˆ¶ (Attention Mechanism) æ‰®æ¼”ç€è‡³å…³é‡è¦çš„è§’è‰²ã€‚

å…¶ä¸­,$Q$ (Query)ã€$K$ (Key) å’Œ $V$ (Value) æ˜¯æ³¨æ„åŠ›è®¡ç®—è¿‡ç¨‹ä¸­çš„ä¸‰ä¸ªæ ¸å¿ƒæ¦‚å¿µã€‚$Q$ å’Œ $K$ è¿›è¡Œç‚¹ç§¯è®¡ç®—, æœ¬è´¨ä¸Šæ˜¯åœ¨å‘é‡ç©ºé—´ä¸­è¿›è¡ŒæŸ¥è¯¢å’ŒåŒ¹é…çš„è¿‡ç¨‹ [ ç‚¹ç§¯çš„æ ¸å¿ƒæ¦‚å¿µ ]ã€‚è¿™ä¸ªè¿‡ç¨‹å¯ä»¥ç†è§£ä¸ºç”¨ $K$ å»åŒ¹é… $Q$, æ‰¾åˆ°ä¸ $Q$ æœ€ç›¸å…³çš„ä¿¡æ¯ã€‚æ¥ä¸‹æ¥,é€šè¿‡å¯¹ç‚¹ç§¯ç»“æœåº”ç”¨ Softmax å‡½æ•°,å¯ä»¥å¾—åˆ°ä¸€ä¸ªæ¦‚ç‡åˆ†å¸ƒ,è¡¨ç¤ºä¸åŒä½ç½®ä¸Šçš„å†…å®¹å¯¹å½“å‰æŸ¥è¯¢çš„ç›¸å…³æ€§ã€‚

é€šå¸¸æƒ…å†µä¸‹,$K$ å’Œ $V$ æ¥è‡ªç›¸åŒçš„è¾“å…¥, è€Œ $Q$ åˆ™ä»£è¡¨å½“å‰çš„æŸ¥è¯¢ã€‚é€šè¿‡ $Q$ ä¸ $K$ çš„åŒ¹é…è¿‡ç¨‹, å†ç»è¿‡æ•°å€¼å˜æ¢,æœ€ç»ˆä» $V$ ä¸­æå–å‡ºä¸æŸ¥è¯¢æœ€ç›¸å…³çš„ä¿¡æ¯,å½¢æˆäº†ä¸€ä¸ª **"æ”¹å˜é‡"**ã€‚è¿™ä¸ª "æ”¹å˜é‡" ä»£è¡¨äº†æŸ¥è¯¢ $Q$ åœ¨å½“å‰ä¸Šä¸‹æ–‡ä¸­çš„è¯­ä¹‰è¡¨ç¤ºã€‚æœ€å,é€šè¿‡å°†è¿™ä¸ª "æ”¹å˜é‡" ä¸åŸå§‹æŸ¥è¯¢ $Q$ **ç›¸åŠ **,å¯ä»¥å¾—åˆ°ä¸€ä¸ªæ›´æ–°åçš„æŸ¥è¯¢è¡¨ç¤º,å³æŸ¥è¯¢æ–¹å‘åœ¨è¯­ä¹‰ç©ºé—´ä¸­çš„æ”¹å˜ã€‚

### â‘¡ ç”Ÿæˆæ¨¡å‹çš„ Decoder ç­–ç•¥ 

> **[Decoding Strategies in LLMs](https://mlabonne.github.io/blog/posts/2023-06-07-Decoding_strategies.html): **
>
> **Provide code and a visual introduction to the different decoding strategies to generate text.**

åœ¨å¤§å‹è¯­è¨€æ¨¡å‹(LLM)çš„æ–‡æœ¬ç”Ÿæˆä»»åŠ¡ä¸­,è§£ç ç­–ç•¥çš„é€‰æ‹©å¯¹ç”Ÿæˆæ–‡æœ¬çš„è´¨é‡å’Œé£æ ¼æœ‰ç€é‡è¦å½±å“ã€‚ä»¥ä¸‹æ˜¯å››ç§å¸¸ç”¨çš„è§£ç æ–¹æ³•çš„ç®€ä»‹,åŒ…æ‹¬å®ƒä»¬çš„ç‰¹ç‚¹ã€å¸¸ç”¨å‚æ•°ã€å‚æ•°æ“ä½œçš„å½±å“ä»¥åŠåœ¨å®é™…å·¥ç¨‹åº”ç”¨ä¸­çš„ç»éªŒå€¼é€‰æ‹©åŠå…¶åŸå› ã€‚

â‘  è´ªå©ªæœç´¢(Greedy Search)

è´ªå©ªæœç´¢æ˜¯æœ€ç®€å•çš„è§£ç ç­–ç•¥,æ¯ä¸€æ­¥ä»…é€‰æ‹©æ¦‚ç‡æœ€é«˜çš„å•è¯ã€‚è¿™ç§æ–¹æ³•çš„ä¼˜ç‚¹æ˜¯è®¡ç®—æ•ˆç‡é«˜,ä½†ç¼ºç‚¹æ˜¯ç”Ÿæˆçš„æ–‡æœ¬å¯èƒ½ç¼ºä¹å¤šæ ·æ€§å’Œåˆ›é€ æ€§,å› ä¸ºå®ƒæ€»æ˜¯é€‰æ‹©å½“å‰æœ€å¯èƒ½çš„é€‰é¡¹,å®¹æ˜“é™·å…¥å±€éƒ¨æœ€ä¼˜ã€‚

â‘¡ æŸæœç´¢(Beam Search) 

æŸæœç´¢æ˜¯ä¸€ç§å¹³è¡¡è¾“å‡ºè´¨é‡å’Œè®¡ç®—æˆæœ¬çš„æ–¹æ³•,é€šè¿‡åœ¨æ¯ä¸€æ­¥ä¿æŒå¤šä¸ª(ç”±å‚æ•°`num_beams`æ§åˆ¶)æœ€ä¼˜å€™é€‰åºåˆ—æ¥å®ç°ã€‚å¸¸è§çš„`num_beams`å€¼åœ¨2åˆ°10ä¹‹é—´,è¾ƒé«˜çš„å€¼å¯ä»¥æé«˜è¾“å‡ºè´¨é‡,ä½†è®¡ç®—æˆæœ¬ä¹Ÿç›¸åº”å¢åŠ ã€‚æŸæœç´¢é€‚ç”¨äºéœ€è¦è¾ƒé«˜è´¨é‡è¾“å‡ºçš„åœºæ™¯,å¦‚æœºå™¨ç¿»è¯‘æˆ–å¤æ‚çš„æ–‡æœ¬ç”Ÿæˆä»»åŠ¡ã€‚åœ¨å®é™…åº”ç”¨ä¸­,`num_beams`çš„é€‰æ‹©é€šå¸¸åœ¨5åˆ°10ä¹‹é—´,ä»¥åœ¨è¾“å‡ºè´¨é‡å’Œè®¡ç®—æ•ˆç‡ä¹‹é—´å–å¾—å¹³è¡¡ã€‚

â‘¢ Top-k æŠ½æ ·(Top-k Sampling)

Top-k æŠ½æ ·åœ¨æ¯ä¸€æ­¥ä»æ¦‚ç‡æœ€é«˜çš„kä¸ªå•è¯ä¸­éšæœºé€‰æ‹©ä¸€ä¸ª,é€šè¿‡å‚æ•°`top_k`æ§åˆ¶ã€‚è¿™ç§æ–¹æ³•å¼•å…¥äº†éšæœºæ€§,ä½¿å¾—ç”Ÿæˆçš„æ–‡æœ¬æ›´åŠ å¤šæ ·åŒ–å’Œä¸å¯é¢„æµ‹ã€‚`top_k`çš„å¸¸ç”¨å€¼é€šå¸¸åœ¨10åˆ°50ä¹‹é—´,è¾ƒå¤§çš„`top_k`å€¼å¢åŠ äº†æ–‡æœ¬çš„å¤šæ ·æ€§,ä½†å¯èƒ½é™ä½æ–‡æœ¬çš„è¿è´¯æ€§å’Œç›¸å…³æ€§ã€‚åœ¨å®è·µä¸­,`top_k`çš„é€‰æ‹©éœ€è¦æ ¹æ®ä»»åŠ¡çš„éœ€æ±‚æ¥æƒè¡¡,ä¸€èˆ¬åœ¨20åˆ°40ä¹‹é—´é€‰æ‹©ã€‚

â‘£ Nucleus æŠ½æ ·(Top-p Sampling)

NucleusæŠ½æ ·æ˜¯æ ¹æ®æ¦‚ç‡ç´¯ç§¯é˜ˆå€¼`top_p`æ¥åŠ¨æ€é€‰æ‹©å€™é€‰å•è¯é›†åˆçš„æ–¹æ³•ã€‚è¿™ç§ç­–ç•¥åœ¨ä¿æŒæ–‡æœ¬å¤šæ ·æ€§çš„åŒæ—¶,é€šè¿‡æ§åˆ¶æ¦‚ç‡çš„ç´¯ç§¯åˆ†å¸ƒæ¥é™åˆ¶éšæœºæ€§,å¸¸ç”¨çš„`top_p`å€¼åœ¨0.9å·¦å³ã€‚è¾ƒé«˜çš„`top_p`å€¼å¯ä»¥ä¿è¯ç”Ÿæˆæ–‡æœ¬çš„æµç•…æ€§å’Œç›¸å…³æ€§,è€Œè¾ƒä½çš„å€¼åˆ™å¯èƒ½ä½¿æ–‡æœ¬æ›´åŠ åˆ›æ–°ä½†ä¸å¤Ÿè¿è´¯ã€‚åœ¨å®é™…åº”ç”¨ä¸­,`top_p`çš„é€‰æ‹©ä¸€èˆ¬åœ¨0.8åˆ°0.95ä¹‹é—´,éœ€è¦åœ¨æµç•…æ€§å’Œåˆ›æ–°æ€§ä¹‹é—´å–å¾—å¹³è¡¡ã€‚

åœ¨é€‰æ‹©è¿™äº›å‚æ•°æ—¶,éœ€è¦æ ¹æ®å…·ä½“çš„åº”ç”¨åœºæ™¯å’Œä»»åŠ¡è¦æ±‚è¿›è¡Œæƒè¡¡ã€‚ä¾‹å¦‚,å¯¹äºéœ€è¦é«˜åº¦åˆ›æ–°æ€§çš„æ–‡æœ¬ç”Ÿæˆä»»åŠ¡,å¯èƒ½ä¼šé€‰æ‹©è¾ƒé«˜çš„`top_k`æˆ–`top_p`å€¼ï¼›è€Œå¯¹äºéœ€è¦é«˜åº¦ç²¾ç¡®å’Œç›¸å…³çš„è¾“å‡º,å¦‚å†…å®¹æ¨èæˆ–ç”¨æˆ·äº¤äº’åœºæ™¯,åˆ™å¯èƒ½é€‰æ‹©è¾ƒä½çš„è¿™äº›å€¼æˆ–ä½¿ç”¨æŸæœç´¢ã€‚åœ¨å®é™…å·¥ç¨‹å®è·µä¸­,ç»éªŒå€¼çš„é€‰æ‹©é€šå¸¸åŸºäºåå¤çš„å®éªŒå’Œè°ƒæ•´,ä»¥æ‰¾åˆ°æœ€ä½³çš„å¹³è¡¡ç‚¹ã€‚ä¸€èˆ¬æƒ…å†µä¸‹,å¯ä»¥å…ˆä»è¾ƒä¸ºä¿å®ˆçš„å‚æ•°å€¼å¼€å§‹è°ƒè¯•,å¦‚`num_beams=5`, `top_k=20`, `top_p=0.9`,ç„¶åæ ¹æ®å®é™…æ•ˆæœè¿›è¡Œè¿›ä¸€æ­¥çš„å¾®è°ƒ,ç›´åˆ°æ‰¾åˆ°æœ€é€‚åˆå…·ä½“ä»»åŠ¡çš„å‚æ•°ç»„åˆã€‚åŒæ—¶ä¹Ÿè¦æ³¨æ„, ä¸åŒçš„æ¨¡å‹å’Œæ•°æ®é›†å¯èƒ½å¯¹å‚æ•°çš„æ•æ„Ÿåº¦ä¸åŒ,éœ€è¦é’ˆå¯¹æ€§åœ°è¿›è¡Œå®éªŒå’Œè°ƒä¼˜ã€‚

## Part â…¡ Building an instruction dataset

### â‘  Instruction Tuning æ•°æ®å‡†å¤‡

>[Preparing a Dataset for Instruction tuning](https://wandb.ai/capecape/alpaca_ft/reports/How-to-Fine-Tune-an-LLM-Part-1-Preparing-a-Dataset-for-Instruction-Tuning--Vmlldzo1NTcxNzE2) by Thomas Capelle: 
>
>Exploration of the Alpaca and Alpaca-GPT4 datasets and how to format them.
>
>**In (almost) pure PyTorch.**
>
>è®°å½•äº†ä¹‹åå¦‚ä½•ä½¿ç”¨å…¶è¿›è¡Œè®­ç»ƒ, å¦‚æœ‰éœ€è¦çœ‹ä¹‹åçš„æ–‡ç« 

Tips : 

* `transformers` åº“ ä¸ `W&B` è¿›è¡Œäº†å¾ˆå¥½çš„é›†æˆ. `Axolotl` ä½œä¸ºå¼€æºè½¯ä»¶ ç»§æ‰¿äº†å¤šç§ Tricks çš„åº“, æ¯”å¦‚ `transformers` `peft` `bitsandbytes` `deepspeed`

* é«˜è´¨é‡çš„ Instruction æ•°æ®é›†æœ‰äººå·¥åˆ¶ä½œçš„ [Flan Collection](https://github.com/google-research/FLAN) and [Dolly15k dataset](https://www.databricks.com/blog/2023/04/12/dolly-first-open-commercially-viable-instruction-tuned-llm) å’Œ LLMç”Ÿæˆçš„å¦‚  [Alpaca dataset](https://crfm.stanford.edu/2023/03/13/alpaca.html) | Some of the recent datasets like [OpenOrca](https://huggingface.co/datasets/Open-Orca/OpenOrca), [Platypus](https://huggingface.co/datasets/garage-bAInd/Open-Platypus), [OpenHermes ](https://huggingface.co/datasets/teknium/openhermes)produce very high-quality fine-tuned models that score high on the leaderboards and different evaluation tasks.
* æ‚¨å¯ä»¥å°†é¢„å¤„ç†åçš„æ•°æ®é›†å­˜å‚¨ä¸º W&B å·¥ä»¶ï¼Œè¿™æ ·å°±å¯ä»¥é¿å…æ¯æ¬¡éƒ½é‡æ–°è¿›è¡Œå¤„ç†äº†

#### Alpaca-GPT4 Dataset

Alpaca-GPT4 æ•°æ®é›†åªæ˜¯ä¸€ä¸ªå•ç‹¬çš„ JSON æ–‡ä»¶ï¼Œalpaca_gpt4_data.json åŒ…å«ç”± GPT-4 ç”Ÿæˆçš„ 52K æŒ‡ä»¤è·Ÿéšæ•°æ®å’Œ Alpaca ä¸­çš„æç¤ºã€‚è¯¥ JSON æ–‡ä»¶ä¸ Alpaca æ•°æ®æ ¼å¼ç›¸åŒï¼Œåªæ˜¯è¾“å‡ºç”± GPT-4 ç”Ÿæˆã€‚

[GPT-4-LLM/data/alpaca_gpt4_data.json at main Â· Instruction-Tuning-with-GPT-4/GPT-4-LLM Â· GitHub](https://github.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM/blob/main/data/alpaca_gpt4_data.json) | 41MB

```json
instruction: str, describes the task the model should perform. 
                  Each of the 52K instructions is unique.
input:       str, optional context or input for the task.
output:      str, the answer to the instruction as generated by GPT-4.
```

æˆ‘é¼“åŠ±å¤§å®¶æ¢ç´¢æ•°æ®é›†ã€‚æœ‰äº›ä»»åŠ¡å¾ˆç®€å•ï¼Œæœ‰äº›åˆ™ä¸é‚£ä¹ˆç®€å•ã€‚å°½ç®¡å¦‚æ­¤ï¼šGPT-4 ç”Ÿæˆçš„è¿™äº›æ•°æ®è¿˜æ˜¯ä»¤äººå°è±¡æ·±åˆ»ã€‚

#### STEP 0 Prompt æ•°æ®å‡†å¤‡

 ```json
 one_row = {
    'instruction': 'What are the three primary colors?',
    'input': '',
    'output': 'The three primary colors are red, blue, and yellow.'
 }
 ```

æˆ‘ä»¬éœ€è¦è¿›è¡Œä¸€äº›é¢„å¤„ç†ï¼Œä»¥ä¾¿å°†è¿™äº›æ•°æ®è¾“å…¥ LLMã€‚è®©æˆ‘ä»¬å®šä¹‰ä¸€äº›å‡½æ•°æ¥æ ¼å¼åŒ–æŒ‡ä»¤

```python
def prompt_no_input(row):
    return ("Below is an instruction that describes a task. "
            "Write a response that appropriately completes the request.\n\n"
            "### Instruction:\n{instruction}\n\n### Response:\n").format_map(row)


def prompt_input(row):
    return ("Below is an instruction that describes a task, paired with an input that provides further context. "
            "Write a response that appropriately completes the request.\n\n"
            "### Instruction:\n{instruction}\n\n### Input:\n{input}\n\n### Response:\n").format_map(row)

```

æˆ‘ä»¬æœ‰å¸¦æç¤ºå’Œä¸å¸¦Promptçš„instructionï¼Œå› æ­¤å¿…é¡»åˆ†åˆ«å¤„ç†ã€‚æˆ‘ä»¬æœ¬å¯ä»¥åŒæ—¶ä¸²è”è¾“å‡ºï¼Œä½†ç”±äºç¨ååœ¨æŒ‡ä»¤å¾®è°ƒæ—¶å°†é‡å¤ä½¿ç”¨è¿™äº›æŒ‡ä»¤ï¼Œå› æ­¤æˆ‘ä»¬å°†å…¶åˆ†å¼€å¤„ç†

```python
row = alpaca[232]
print(prompt_input(row))


>> Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.


### Instruction:
What are the three primary colors?


### Input:


### Response:
```

ç„¶åï¼Œæˆ‘ä»¬å°±å¯ä»¥å°†è¿™ä¸¤æ¡è·¯å¾„åˆå¹¶ä¸º

```python
def create_prompt(row):
    return prompt_no_input(row) if row["input"] == "" else prompt_input(row)


prompts = [create_prompt(row) for row in alpaca]  # all LLM inputs are here
```

#### STEP 1 : End of String Tokens (EOS)

**å‘Šè¯‰ model ä½•æ—¶åœæ­¢** 

We will append this token after each response:

```python
EOS_TOKEN = "</s>"
outputs = [row['output'] + EOS_TOKEN for row in alpaca]
---------------------------------------------
outputs[0]
# this is a oneliner split here for readability
>> 1.Eat a balanced diet and make sure to include plenty of fruits and vegetables. 
\n2. Exercise regularly to keep your body active and strong.
\n3. Get enough sleep and maintain a consistent sleep schedule.</s>' 
```

æˆ‘ä»¬è¿˜å°†å­˜å‚¨æŒ‡ä»¤å’Œè¾“å‡ºçš„ concatenationï¼š

```python
dataset = [{"prompt":s, "output":t, "example": s+t} for s, t in zip(prompts, outputs)]
```

##### String To Tokenizer | Use transformers 

è¿™ä¸ªåº“å¯ä»¥å®Œæˆä»¥ä¸‹ä»»åŠ¡

* String 2 Tokens
* å°†è¾“å‡ºè½¬æ¢ä¸º PyTorch å¼ é‡
* å¡«å……è¾“å…¥ä»¥åŒ¹é…é•¿åº¦

```python
model_id = 'meta-llama/Llama-2-7b-hf'
tokenizer = AutoTokenizer.from_pretrained(model_id)
tokenizer.pad_token = tokenizer.eos_token
```

æˆ‘ä»¬å¿…é¡»å‘Šè¯‰ä»¤ç‰Œç”Ÿæˆå™¨ä½¿ç”¨ä»€ä¹ˆä»¤ç‰Œè¿›è¡Œå¡«å……ï¼›

åœ¨æœ¬ä¾‹ä¸­ï¼Œä½¿ç”¨çš„æ˜¯ EOS ä»¤ç‰Œï¼ˆid = 2ï¼‰ã€‚æˆ‘ä»¬å¯ä»¥æŒ‡å®šå¡«å……åºåˆ—çš„é•¿åº¦ï¼Œå¹¶æ®æ­¤å®Œæˆå®ƒã€‚

```python
tokenizer.encode("My experiments are going strong!")
# >> [1, 1619, 15729, 526, 2675, 4549, 29991]

tokenizer.encode("My experiments are going strong!", padding='max_length', max_length=10)
# >> [1, 1619, 15729, 526, 2675, 4549, 29991, 2, 2, 2]
```

æˆ‘ä»¬è¿˜å¯ä»¥ç›´æ¥è·å– PyTorch å¼ é‡ï¼š

```python
tokenizer.encode("My experiments are going strong!", 
                 padding='max_length', 
                 max_length=10,
                 return_tensors="pt")
# >> tensor([[    1,  1619, 15729,   526,  2675,  4549, 29991,     2,     2,     2]])
```

åè€…çš„å¥½å¤„æ˜¯ï¼Œæˆ‘ä»¬å¯ä»¥æŠŠ tokenizer æ”¾åœ¨ collate å‡½æ•°ä¸­ï¼è¿™æ ·ï¼Œæˆ‘ä»¬ä» dataloader çš„å­—ç¬¦ä¸²ä¸­é‡‡æ ·ï¼Œç„¶åcollateå‡½æ•°å°†å…¶ tokenizer å¹¶è½¬æ¢ä¸º PyTorch å¼ é‡

> #### ä»€ä¹ˆæ˜¯ Collate å‡½æ•°ï¼Ÿ
>
> åœ¨ PyTorch ä¸­ï¼Œ`collate_fn` æ˜¯ DataLoader çš„ä¸€ä¸ªå‚æ•°ï¼Œç”¨äºæŒ‡å®šå¦‚ä½•å°†å¤šä¸ªæ•°æ®æ ·æœ¬ï¼ˆé€šå¸¸æ˜¯ä¸€ä¸ªæ‰¹æ¬¡çš„æ•°æ®ï¼‰ç»„åˆæˆä¸€ä¸ªæ‰¹æ¬¡ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼ŒDataLoader ä¼šå°è¯•å°†æ ·æœ¬ç®€å•åœ°å †å èµ·æ¥ï¼Œä½†å½“æ•°æ®éœ€è¦å¤æ‚çš„å¤„ç†æ—¶ï¼ˆæ¯”å¦‚ä¸åŒé•¿åº¦çš„åºåˆ—ï¼‰ï¼Œå°±éœ€è¦è‡ªå®šä¹‰ `collate_fn`ã€‚
>
> #### Collate å‡½æ•°çš„ä½œç”¨
>
> `collate_fn` å…è®¸å¼€å‘è€…è‡ªå®šä¹‰æ•°æ®çš„æ‰¹æ¬¡å¤„ç†æ–¹å¼ã€‚ä¾‹å¦‚ï¼Œå½“å¤„ç†æ–‡æœ¬æ•°æ®æ—¶ï¼Œä¸åŒçš„æ–‡æœ¬é•¿åº¦ä¼šå¯¼è‡´æ— æ³•ç›´æ¥å †å ï¼Œå› æ­¤å¯ä»¥åœ¨ `collate_fn` ä¸­å®ç°å¦‚ä¸‹åŠŸèƒ½ï¼š
>
> - å¯¹æ•°æ®è¿›è¡Œå¡«å……ï¼ˆpaddingï¼‰ä»¥ä¿è¯æ‰€æœ‰æ•°æ®å…·æœ‰ç›¸åŒçš„é•¿åº¦ï¼›
> - å°†æ•°æ®å°è£…æˆ Tensorï¼›
> - å¯ä»¥è¿›è¡Œæ›´å¤æ‚çš„æ“ä½œï¼Œä¾‹å¦‚æ•°æ®å¢å¼ºã€åŠ¨æ€è°ƒæ•´å¡«å……é•¿åº¦ç­‰ã€‚
>
> #### åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­çš„ä½¿ç”¨
>
> åœ¨ç¥ç»ç½‘ç»œè®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œå½“ä» DataLoader è·å–æ•°æ®æ‰¹æ¬¡æ—¶ï¼Œ`collate_fn` è¢«è°ƒç”¨ï¼Œä»¥ç¡®ä¿æ¯ä¸ªæ‰¹æ¬¡çš„æ•°æ®æ ¼å¼æ­£ç¡®ï¼Œå¯ä»¥è¢«æ¨¡å‹æ­£ç¡®å¤„ç†ã€‚

#### STEP 2 : Creating a Train-Eval Split

```python
import random
random.shuffle(dataset). # shuffle inplace


train_dataset = dataset[:-1000]
eval_dataset = dataset[-1000:]


train_table = wandb.Table(dataframe=pd.DataFrame(train_dataset))
eval_table  = wandb.Table(dataframe=pd.DataFrame(eval_dataset))


with wandb.init(project="alpaca_ft", job_type="split_data"):
    wandb.log({"train_dataset":train_table, "eval_dataset":eval_table})

```

#### STEP 3 : Packing | Combining multiple samples into a longer sequence

ä¸ºäº†æé«˜è®­ç»ƒæ•ˆç‡ï¼Œå¹¶åˆ©**ç”¨è¿™äº› LLM çš„è¾ƒé•¿ä¸Šä¸‹æ–‡**ï¼Œæˆ‘ä»¬å°†é‡‡å–ä¸€ç§ç§°ä¸º "æ‰“åŒ…Packing "çš„æ–¹æ³•ã€‚æˆ‘ä»¬å°†åˆå¹¶å¤šä¸ªç¤ºä¾‹æ¥å¡«å……æ¨¡å‹çš„å†…å­˜ï¼Œä»è€Œæé«˜è®­ç»ƒæ•ˆç‡ï¼Œè€Œä¸æ˜¯å•ç‹¬è¾“å…¥ç¤ºä¾‹ã€‚è¿™æ ·ï¼Œæˆ‘ä»¬å°±å¯ä»¥**é¿å…è¿›è¡Œå¤§é‡å¡«å……å’Œå¤„ç†ä¸åŒçš„é•¿åº¦**ã€‚

![img](assets/d9f4c0c2.png)

è¿™é‡Œçš„ä¸»è¦æ€è·¯æ˜¯ï¼ŒæŒ‡ä»¤/è¾“å‡ºæ ·æœ¬éƒ½å¾ˆçŸ­ï¼Œå› æ­¤æˆ‘ä»¬å¯ä»¥å°†å®ƒä»¬ä¸²è”èµ·æ¥ï¼Œå¹¶ç”¨ EOS æ ‡è®°éš”å¼€ã€‚æˆ‘ä»¬è¿˜å¯ä»¥å¯¹æ•°æ®é›†è¿›è¡Œé¢„æ ‡è®°å’Œé¢„æ‰“åŒ…ï¼Œè®©ä¸€åˆ‡å˜å¾—æ›´å¿«ï¼  å¦‚æœæˆ‘ä»¬å®šä¹‰ max_seq_len = 1024ï¼Œé‚£ä¹ˆæ‰“åŒ…çš„ä»£ç å°†å¦‚ä¸‹æ‰€ç¤ºï¼š

```python
max_seq_len = 1024


def pack(dataset, max_seq_len=1024):
    tkds_ids = tokenizer([s["example"] for s in dataset])["input_ids"]
    
    all_token_ids = []
    for tokenized_input in tkds_ids:
        all_token_ids.extend(tokenized_input + [tokenizer.eos_token_id])
    
    packed_ds = []
    for i in range(0, len(all_token_ids), max_seq_len+1):
        input_ids = all_token_ids[i : i + max_seq_len+1]
        if len(input_ids) == (max_seq_len+1):
            packed_ds.append({"input_ids": input_ids[:-1], "labels": input_ids[1:]})  # < --- â€¼ï¸ â›”ï¸
	    # if you use the model.output.loss you don't need to shift, it is done for you!
    return packed_ds


train_ds_packed = pack(train_dataset)
eval_ds_packed = pack(eval_dataset)

```

è¿™æ ·ï¼Œæˆ‘ä»¬å°±å¾—åˆ°äº†è¶…è¿‡ 11k ä¸ªé•¿åº¦ä¸º 1024 çš„åºåˆ—ã€‚(åŸæœ¬52k)

#### STEP 4 : Second Option | Batching multiple sequences of different lengths

> **è¿™ç§è§£å†³æ–¹æ¡ˆæ€§èƒ½ä¸ä½³ï¼Œå› ä¸ºæ¯ä¸ªæ‰¹æ¬¡çš„é•¿åº¦éƒ½ä¸ä¸€æ ·ï¼Œè€Œä¸”åŒ…å«çš„æ ‡è®°å¯¹æ¨¡å‹æ²¡æœ‰ä»»ä½•å¯å‘ã€‚**

è¿˜æœ‰ä¸€ç§æ–¹æ³•å¯ä»¥ä»ä¸åŒå¤§å°çš„è¡Œä¸­æ„å»ºæ‰¹æ¬¡ï¼›é‚£å°±æ˜¯å¯¹åºåˆ—è¿›è¡Œå¡«å……ï¼Œä½¿å®ƒä»¬å˜å¾—æ›´é•¿ï¼Œè¿™æ ·å°±å¯ä»¥å°†å®ƒä»¬é›†ä¸­åœ¨ä¸€èµ·ã€‚

æ ‡è®°åŒ–å™¨æœ‰ä¸€ä¸ªæ‰¹å¤„ç†å‡½æ•°ï¼Œå¯ä»¥æ ¹æ®æ‰€éœ€çš„ç­–ç•¥ä»ä¸åŒçš„æ ·æœ¬å’Œå¡«å……ä¸­åˆ›å»ºæ‰¹å¤„ç†ã€‚

![img](assets/ff512cfb.png)

```python
tokenizer(["My experiments are going strong!", 
           "I love Llamas"], 
          padding='longest',
          return_tensors="pt")


>> {'input_ids': tensor([[    1,  1619, 15729,   526,  2675,  4549, 29991],
                         [    1,   306,  5360,   365,  5288,   294,     2]]), 
    'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1],
                              [1, 1, 1, 1, 1, 1, 0]])}


tokenizer(["My experiments are going strong!", 
           "I love Llamas"], 
          # padding='max_length', 
          padding='max_length',
          max_length=10,
          return_tensors="pt")


>> {'input_ids': tensor([[    1,  1619, 15729,   526,  2675,  4549, 29991,     2,     2,     2],
                         [    1,   306,  5360,   365,  5288,   294,     2,     2,     2,     2]]), 
    'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 0, 0, 0],
                              [1, 1, 1, 1, 1, 1, 0, 0, 0, 0]])}
```

å› æ­¤ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨è¯¥å‡½æ•°åˆ›å»ºæœ€ç»ˆæ‰¹æ¬¡ï¼Œå¹¶å°†å…¶ä¼ é€’ç»™æ¨¡å‹ã€‚

è¿˜è¦æ³¨æ„çš„æ˜¯ï¼Œè¿™é¡¹ä»»åŠ¡å¯ä»¥ç¦»çº¿å®Œæˆï¼Œåªéœ€å¯¹æ•´ä¸ªæ•°æ®é›†è¿›è¡Œä¸€æ¬¡é¢„å¤„ç†ã€‚åœ¨å¤§å¤šæ•°æƒ…å†µä¸‹éƒ½æ˜¯è¿™æ ·åšçš„ï¼Œäººä»¬ä»æ ‡è®°åŒ–çš„æ•°æ®é›†ä¸­è¿›è¡Œæµå¼å¤„ç†ã€‚è½¬æ¢å™¨åº“ä¸­ç”šè‡³æœ‰ä¸€ä¸ªç”¨ Rust å®ç°çš„ FastTokenizer ç±»ï¼Œå¯ä»¥è®©è¿™ä¸€æ­¥å˜å¾—æ›´å¿«ã€‚

#### STEP 5 : Storing our preprocessed dataset on W&B 

 ç°åœ¨ï¼Œæˆ‘ä»¬å·²ç»æ‰“åŒ…å¥½æ•°æ®é›†ï¼Œå¯ä»¥å®‰å…¨åœ°ä¿å­˜æ•°æ®é›†ä»¥è®­ç»ƒæ¨¡å‹ï¼

ä¸ºäº†è·å¾—æ¨¡å‹çš„è„‰ç»œï¼Œå¹¶å‡†ç¡®åœ°çŸ¥é“å“ªä¸ªæ•°æ®é›†ç”¨äºå¾®è°ƒæˆ‘ä»¬çš„æ¨¡å‹ï¼Œå¥½çš„åšæ³•æ˜¯å¯¹æ•°æ®è¿›è¡Œç‰ˆæœ¬åŒ–ï¼Œå¹¶å°†ä¸€åˆ‡éƒ½æ•´ç†å¾—äº•äº•æœ‰æ¡ã€‚æˆ‘ä»¬å°†æŠŠæ•°æ®é›†è®°å½•ä¸º W&B å·¥ä»¶ã€‚

æˆ‘ä»¬å¯ä»¥å°†æ•°æ®å­˜å‚¨ä¸º JSONL æ ¼å¼ï¼Œå…¶ä¸­æ¯ä¸€è¡Œå¯¹åº”ä¸€ä¸ªå­—å…¸å¯¹è±¡ï¼š

```python
import json
def save_jsonl(data, filename):
    with open(filename, 'w') as file:
        for entry in data:
            json.dump(entry, file)
            file.write('\n')


# dump everything to jsonl files
save_jsonl(train_ds_packed, "train_packed_alpaca.jsonl")
save_jsonl(eval_ds_packed, "eval_packed_alpaca.jsonl")


# Create a W&B artifact
packed_at = wandb.Artifact(
    name="packed_alpaca",
    type="dataset",
    description="Alpaca dataset packed in sequences",
    metadata={"max_seq_len":1024, "model_id":model_id})


packed_at.add_file("train_packed_alpaca.jsonl")
packed_at.add_file("eval_packed_alpaca.jsonl")


# log the artifact to the project, we can give this run a job_type like `preprocess`
with wandb.init(project="alpaca_ft", job_type="preprocess"):
    wandb.log_artifact(packed_at)

```

å¦‚æœéœ€è¦ï¼Œæ‚¨å¯ä»¥åœ¨æè¿°å’Œå…ƒæ•°æ®å‚æ•°ä¸­å­˜å‚¨æ•°æ®é›†çš„ç›¸å…³ä¿¡æ¯ã€‚

### â‘¡ æ„å»ºåˆæˆæ•°æ®

> [Generating a Clinical Instruction Dataset](https://medium.com/mlearning-ai/generating-a-clinical-instruction-dataset-in-portuguese-with-langchain-and-gpt-4-6ee9abfa41ae) by Solano Todeschini: 
>
> Tutorial on how to create a synthetic instruction dataset using GPT-4.
>
> ä½¿ç”¨ pytorch | OpenAI api | langchain | => è¯¦ç»†è¯·è§åŸæ–‡

åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å°†æ¢è®¨åœ¨ Langchain åº“çš„è¾…åŠ©ä¸‹ï¼Œä½¿ç”¨ OpenAI çš„ GPT-4 æ¨¡å‹åˆ›å»ºé«˜è´¨é‡æŒ‡ä»¤è·Ÿéšæ•°æ®é›†çš„è¿‡ç¨‹ï¼Œè¯¥è¿‡ç¨‹åŸºäºç”Ÿæˆ Alpaca æ•°æ®é›†çš„ç›¸åŒæ–¹æ³• (https://huggingface.co/datasets/tatsu-lab/alpaca)ã€‚

> åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œæˆ‘ä»¬å‡†å¤‡äº†ä¸€ä¸ªæ•°æ®é›†ï¼Œå…¶ä¸­åŒ…å« 17 å¯¹ä¸ä¸´åºŠé¢†åŸŸç›¸å…³çš„å·´è¥¿è‘¡è„ç‰™è¯­æŒ‡ä»¤ã€‚æˆ‘ä»¬é¦–å…ˆåˆ›å»ºäº†ä¸€ä¸ª .csv æ–‡ä»¶ï¼Œå…¶ä¸­åŒ…å«æŒ‡ä»¤ã€è¾“å…¥å’Œè¾“å‡ºåˆ—ã€‚
>
> ç„¶åï¼Œæˆ‘ä»¬å°†è¯¥æ–‡ä»¶è¯»å…¥ pandas DataFrameï¼Œå¹¶å°† DataFrame è½¬æ¢ä¸º JSON å¯¹è±¡åˆ—è¡¨ã€‚ç„¶åå°†è¯¥åˆ—è¡¨ä¿å­˜ä¸º .json æ–‡ä»¶ï¼Œå…¶æ ¼å¼é€‚åˆä½œä¸ºæç¤ºä¿¡æ¯ä¼ é€’ç»™ GPT-4ã€‚

#### STEP 1 : Preparing Your Seed Tasks

åœ¨å¼€å§‹ç”ŸæˆæŒ‡ä»¤æ•°æ®é›†ä¹‹å‰ï¼Œæ‚¨é¦–å…ˆéœ€è¦ä¸€ç»„ç§å­ä»»åŠ¡ã€‚è¿™äº›ä»»åŠ¡é€šå¸¸ä»¥æŒ‡ä»¤çš„å½¢å¼å‡ºç°ï¼Œåé¢è·Ÿç€ç›¸åº”çš„è¾“å…¥å’Œè¾“å‡ºï¼Œæ˜¯æ•°æ®é›†ç”Ÿæˆè¿‡ç¨‹çš„åŸºç¡€ã€‚å®ƒä»¬ç”¨äºæä¾›ä¸Šä¸‹æ–‡ï¼Œå¹¶ä¿ƒä½¿ LLM ç”Ÿæˆæ›´å¤šä»»åŠ¡ã€‚

```python
{'instruction': 'What is the scientific name for a beaver?',
 'input': '',
 'output': 'The scientific name for a beaver is Castor canadensis.
```

#### STEP 2 : Creating a Prompt Template

å‡†å¤‡å¥½ç§å­ä»»åŠ¡åï¼Œä¸‹ä¸€æ­¥å°±æ˜¯å°†è¿™äº›ä»»åŠ¡ç¼–ç æˆå¯ä¾› Langchain é“¾ä½¿ç”¨çš„ç‰¹å®šæ ¼å¼ã€‚

```
You are asked to come up with a set of 20 diverse task instructions. These task instructions will be given to a GPT model and we will evaluate the GPT model for completing the instructions.

Here are the requirements:
1. Try not to repeat the verb for each instruction to maximize diversity.
2. The language used for the instruction also should be diverse. For example, you should combine questions with imperative instrucitons.
3. The type of instructions should be diverse. The list should include diverse types of tasks like open-ended generation, classification, editing, etc.
2. A GPT language model should be able to complete the instruction. For example, do not ask the assistant to create any visual or audio output. For another example, do not ask the assistant to wake you up at 5pm or set a reminder because it cannot perform any action.
3. The instructions should be in English.
4. The instructions should be 1 to 2 sentences long. Either an imperative sentence or a question is permitted.
5. You should generate an appropriate input to the instruction. The input field should contain a specific example provided for the instruction. It should involve realistic data and should not contain simple placeholders. The input should provide substantial content to make the instruction challenging but should ideally not exceed 100 words.
6. Not all instructions require input. For example, when a instruction asks about some general information, "what is the highest peak in the world", it is not necssary to provide a specific context. In this case, we simply put "<noinput>" in the input field.
7. The output should be an appropriate response to the instruction and the input. Make sure the output is less than 100 words.

List of 20 tasks:
```

#### STEP 3 : Mixing Seed Tasks and Format the Final Prompts

åœ¨é€‚å½“åˆ›å»ºæç¤ºæ¨¡æ¿åï¼Œä¸‹ä¸€ä¸ªå…³é”®æ­¥éª¤æ˜¯å¼€å‘ä¸€ä¸ªç®¡é“ï¼Œéšæœºè·å–ç§å­æŒ‡ä»¤ï¼Œå¹¶å°†å…¶æ ¼å¼åŒ–åˆ°æç¤ºæ¨¡æ¿ä¸­ï¼Œå½¢æˆä¸€ç»„æœ€ç»ˆæç¤ºï¼ŒæŒ‡ç¤º LLM ç”Ÿæˆæ–°ç¤ºä¾‹ã€‚

#### STEP 4 : Generating and Processing Instructions

![img](assets/1QKjcTU8ceMWP1PFPYJxMIA.png)

è®¾ç½®å®Œæˆåï¼Œæˆ‘ä»¬ç°åœ¨å¯ä»¥ä¸“æ³¨äºæµç¨‹çš„æ ¸å¿ƒéƒ¨åˆ†ï¼šç”Ÿæˆå’Œå¤„ç†æŒ‡ä»¤ã€‚è¿™åŒ…æ‹¬å‘ LLM å‘é€ç¼–ç æç¤ºï¼Œå¹¶å°†æ¥æ”¶åˆ°çš„å“åº”å¤„ç†ä¸ºé€‚åˆæŒ‡ä»¤æ•°æ®é›†çš„æ ¼å¼ã€‚

æŒ‰ç…§è¿™äº›æ­¥éª¤ï¼Œæ‚¨å°†èƒ½å¤Ÿåˆ©ç”¨ Langchain å’Œ GPT-4 ç”Ÿæˆä¸€ä¸ªå…¨é¢çš„æŒ‡ä»¤æ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†å¯ç”¨äºå¾®è°ƒæ‚¨çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œä»¥æ›´å¥½åœ°æ»¡è¶³æ‚¨çš„ç‰¹å®šéœ€æ±‚ã€‚

#### â‘¢ Instruction Datasets æ•°æ®è¿‡æ»¤

> [Dataset creation for fine-tuning LLM](https://colab.research.google.com/drive/1GH8PW9-zAe4cXEZyOIE-T9uHXblIldAg?usp=sharing): 
>
> Notebook that contains a few techniques to filter a dataset and upload the result.
>
> 1 Filter out rows with more than 2048 tokens
>
> 2 ä½¿ç”¨EmbeddingæŠ€æœ¯è¿›è¡Œå»é‡
>
> 3 ç­›å‡º Token å°‘çš„æ ·ä¾‹
>
> 4 å®šä¹‰æ¨¡æ¿ ä½œä¸ºè¾“å…¥

#### æ•°æ®é›†ç§ç±»

1. **Instruction datasets**ï¼š

   è¾“å…¥æ˜¯æŒ‡ä»¤ï¼ˆå¦‚é—®é¢˜ï¼‰ï¼Œè¾“å‡ºå¯¹åº”äºé¢„æœŸååº”ï¼ˆå¦‚ç­”æ¡ˆï¼‰ã€‚ç¤ºä¾‹ï¼šOpen-Orca

2. Raw completion : 

   è¿™æ˜¯é¢„è®­ç»ƒç›®æ ‡ï¼ˆä¸‹ä¸€ä¸ªæ ‡è®°é¢„æµ‹ï¼‰çš„ç»§ç»­ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œè®­ç»ƒå¥½çš„æ¨¡å‹ä¸æ˜¯ç”¨æ¥ä½œä¸ºè¾…åŠ©å·¥å…·çš„ã€‚ä¾‹å¦‚ï¼šMADLAD-400

3. **Preference datasets**ï¼š

   è¿™äº›æ•°æ®é›†ä¸å¼ºåŒ–å­¦ä¹ ä¸€èµ·ç”¨äºå¯¹å€™é€‰å›ç­”è¿›è¡Œæ’åºã€‚å®ƒä»¬å¯ä»¥ä¸ºåŒä¸€æŒ‡ä»¤æä¾›å¤šä¸ªç­”æ¡ˆï¼Œå¸®åŠ©æ¨¡å‹é€‰æ‹©æœ€ä½³ç­”æ¡ˆã€‚ç¤ºä¾‹ï¼šUltrafeedback_barinizedã€‚

4. **Others**

   ä¸­é—´å¡«å……ç›®æ ‡åœ¨ä»£ç å®Œæˆæ¨¡å‹ï¼ˆå¦‚ GitHub Copilot çš„ Codexï¼‰ä¸­éå¸¸æµè¡Œã€‚å…¶ä»–æ•°æ®é›†å¯ä»¥è®¾è®¡ç”¨äºåˆ†ç±»ï¼Œå…¶ä¸­çš„è¾“å‡ºä¸æˆ‘ä»¬æƒ³è¦é¢„æµ‹çš„æ ‡ç­¾ç›¸å¯¹åº”ï¼ˆåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ¨¡å‹éœ€è¦ä¸€ä¸ªé¢å¤–çš„åˆ†ç±»å¤´ï¼‰ã€‚

å®é™…ä¸Šï¼Œæœ‰ç›‘ç£çš„å¾®è°ƒåªèƒ½åˆ©ç”¨ç¬¬ä¸€ç±»æ•°æ®é›†ã€‚æˆ‘ä»¬æ—¢å¯ä»¥åˆ›å»ºè‡ªå·±çš„æŒ‡ä»¤æ•°æ®é›†ï¼Œä¹Ÿå¯ä»¥ä¿®æ”¹ç°æœ‰æ•°æ®é›†ï¼Œå¯¹å…¶è¿›è¡Œè¿‡æ»¤ã€æ”¹è¿›æˆ–ä¸°å¯Œã€‚

### â‘¢ Chat æ¨¡æ¿

> [Chat Template](https://huggingface.co/blog/chat-templates) by Matthew Carrigan: Hugging Face's page about prompt templates

ç°å­˜çš„èŠå¤©æ¨¡å‹ä½¿ç”¨çš„è®­ç»ƒæ•°æ®æ ¼å¼å„å„ä¸åŒï¼Œæˆ‘ä»¬éœ€è¦ç”¨è¿™äº›æ ¼å¼å°†å¯¹è¯è½¬æ¢ä¸ºå•ä¸ªå­—ç¬¦ä¸²å¹¶ä¼ ç»™åˆ†è¯å™¨ã€‚**å¦‚æœæˆ‘ä»¬åœ¨å¾®è°ƒæˆ–æ¨ç†æ—¶ä½¿ç”¨çš„æ ¼å¼ä¸æ¨¡å‹è®­ç»ƒæ—¶ä½¿ç”¨çš„æ ¼å¼ä¸åŒï¼Œé€šå¸¸ä¼šå¯¼è‡´ä¸¥é‡çš„ã€æ— å£°çš„æ€§èƒ½ä¸‹é™ï¼Œå› æ­¤åŒ¹é…è®­ç»ƒæœŸé—´ä½¿ç”¨çš„æ ¼å¼æå…¶é‡è¦ï¼** 

Hugging Face åˆ†è¯å™¨æ–°å¢äº† `chat_template` å±æ€§ï¼Œå¯ç”¨äºä¿å­˜æ¨¡å‹è®­ç»ƒæ—¶ä½¿ç”¨çš„èŠå¤©æ ¼å¼ã€‚æ­¤å±æ€§åŒ…å«ä¸€ä¸ª Jinja æ¨¡æ¿ï¼Œå¯å°†å¯¹è¯å†å²è®°å½•æ ¼å¼åŒ–ä¸ºæ­£ç¡®çš„å­—ç¬¦ä¸²ã€‚è¯·å‚é˜… [æŠ€æœ¯æ–‡æ¡£](https://huggingface.co/docs/transformers/main/en/chat_templated)ï¼Œä»¥äº†è§£æœ‰å…³å¦‚ä½•åœ¨ä»£ç ä¸­ç¼–å†™å’Œåº”ç”¨èŠå¤©æ¨¡æ¿ã€‚

#### 1 å¼•è¨€

æœ€å¸¸è§çš„ï¼Œè§’è‰²æ˜¯â€œç”¨æˆ·â€(ç”¨äºç”¨æˆ·å‘é€çš„æ¶ˆæ¯) ã€â€œåŠ©ç†â€(ç”¨äºæ¨¡å‹ç”Ÿæˆçš„å“åº”)ï¼Œä»¥åŠå¯é€‰çš„â€œç³»ç»Ÿâ€(æŒ‡åœ¨å¯¹è¯å¼€å§‹æ—¶ç»™å‡ºçš„é«˜çº§æŒ‡ä»¤)ã€‚

```json
[
    {"role": "user", "content": "Hi there!"},
    {"role": "assistant", "content": "Nice to meet you!"}
]
```

æ­¤æ¶ˆæ¯åºåˆ—éœ€è¦å…ˆè½¬æ¢ä¸ºä¸€ä¸ªæ–‡æœ¬å­—ç¬¦ä¸²ï¼Œç„¶åæ‰èƒ½å¯¹å…¶è¿›è¡Œåˆ†è¯ä»¥è¾“å…¥ç»™æ¨¡å‹ã€‚ä½†é—®é¢˜æ˜¯ï¼Œè½¬æ¢æ–¹æ³•æœ‰å¾ˆå¤šï¼ä¾‹å¦‚ï¼Œä½ å¯ä»¥å°†æ¶ˆæ¯åˆ—è¡¨è½¬æ¢ä¸ºâ€œå³æ—¶æ¶ˆæ¯â€æ ¼å¼:

```
User: Hey there!
Bot: Nice to meet you!
```

æˆ–è€…ä½ å¯ä»¥æ·»åŠ ç‰¹æ®Šè¯å…ƒæ¥æŒ‡ç¤ºè§’è‰²:

```
[USER] Hey there! [/USER]
[ASST] Nice to meet you! [/ASST]
```

æŠ‘æˆ–ä½ å¯ä»¥æ·»åŠ è¯å…ƒä»¥æŒ‡ç¤ºæ¶ˆæ¯ä¹‹é—´çš„è¾¹ç•Œï¼Œè€Œå°†è§’è‰²ä¿¡æ¯ä½œä¸ºå­—ç¬¦ä¸²æ’å…¥:

```
<|im_start|>user
Hey there!<|im_end|>
<|im_start|>assistant
Nice to meet you!<|im_end|>
```

æ–¹æ³•å¤šç§å¤šæ ·ï¼Œä½†æ²¡æœ‰å“ªç§æ–¹æ³•æ˜¯æœ€å¥½çš„æˆ–æ˜¯æœ€æ­£ç¡®çš„ã€‚å› æ­¤ï¼Œä¸åŒçš„æ¨¡å‹ä¼šé‡‡ç”¨æˆªç„¶ä¸åŒçš„æ ¼å¼è¿›è¡Œè®­ç»ƒã€‚ä¸Šé¢è¿™äº›ä¾‹å­ä¸æ˜¯æˆ‘ç¼–é€ çš„ï¼Œå®ƒä»¬éƒ½æ˜¯çœŸå®çš„ï¼Œå¹¶ä¸”è‡³å°‘è¢«ä¸€ä¸ªç°å­˜æ¨¡å‹ä½¿ç”¨è¿‡ï¼ä½†æ˜¯ï¼Œä¸€æ—¦æ¨¡å‹æ¥å—äº†æŸç§æ ¼å¼çš„è®­ç»ƒï¼Œä½ éœ€è¦ç¡®ä¿æœªæ¥çš„è¾“å…¥ä½¿ç”¨ç›¸åŒçš„æ ¼å¼ï¼Œå¦åˆ™å°±å¯èƒ½ä¼šå‡ºç°æŸå®³æ€§èƒ½çš„åˆ†å¸ƒæ¼‚ç§»ã€‚

#### 2 æ¨¡æ¿: ä¸€ç§ä¿å­˜æ ¼å¼ä¿¡æ¯çš„æ–¹å¼

èŠå¤©æ¨¡æ¿æ—¨åœ¨è§£å†³ä»¥ä¸‹å‡ ä¸ªé—®é¢˜ï¼š

1. **æ ¼å¼ä¸€è‡´æ€§å’Œæ­£ç¡®æ€§**ï¼šåœ¨ä½¿ç”¨æœºå™¨å­¦ä¹ æ¨¡å‹è¿›è¡ŒèŠå¤©æˆ–å…¶ä»–æ–‡æœ¬ç”Ÿæˆä»»åŠ¡æ—¶ï¼Œè¾“å…¥çš„æ ¼å¼éå¸¸é‡è¦ã€‚ä¸æ­£ç¡®çš„æ ¼å¼å¯èƒ½å¯¼è‡´æ¨¡å‹æ€§èƒ½ä¸‹é™ï¼Œä½†è¿™ç§ä¸‹é™æ˜¯éš¾ä»¥é€šè¿‡å¸¸è§„çš„é”™è¯¯æç¤ºæ¥è¯†åˆ«çš„ï¼ˆè¢«ç§°ä¸ºâ€œé™é»˜é”™è¯¯â€ï¼‰ã€‚èŠå¤©æ¨¡æ¿ç¡®ä¿è¾“å…¥æ ¼å¼ç¬¦åˆæ¨¡å‹çš„é¢„æœŸï¼Œä»è€Œé¿å…è¿™ç§é™é»˜é”™è¯¯ã€‚
2. **ç®€åŒ–æ¨¡å‹ä½¿ç”¨**ï¼šåœ¨æ²¡æœ‰èŠå¤©æ¨¡æ¿çš„æƒ…å†µä¸‹ï¼Œç”¨æˆ·éœ€è¦æ‰‹åŠ¨æŸ¥æ‰¾å¹¶ç¼–å†™ä»£ç æ¥ç¡®ä¿è¾“å…¥æ ¼å¼çš„æ­£ç¡®ï¼Œè¿™ä¸ä»…è€—æ—¶è€Œä¸”å®¹æ˜“å‡ºé”™ã€‚èŠå¤©æ¨¡æ¿é€šè¿‡æä¾›ä¸€ä¸ªé¢„å®šä¹‰çš„ã€å¯é‡ç”¨çš„æ¨¡æ¿å­—ç¬¦ä¸²ï¼Œç®€åŒ–äº†è¿™ä¸€æµç¨‹ã€‚

èŠå¤©æ¨¡æ¿æ˜¯ä¸€ä¸ª [Jinja æ¨¡æ¿å­—ç¬¦ä¸²](https://jinja.palletsprojects.com/en/3.1.x/)ï¼Œä½ å¯ä»¥ä½¿ç”¨åˆ†è¯å™¨ä¿å­˜å’ŒåŠ è½½å®ƒã€‚èŠå¤©æ¨¡æ¿åŒ…å«äº†å°†èŠå¤©æ¶ˆæ¯åˆ—è¡¨è½¬æ¢ä¸ºæ¨¡å‹æ‰€éœ€çš„ã€æ ¼å¼æ­£ç¡®çš„è¾“å…¥å­—ç¬¦ä¸²æ‰€éœ€è¦çš„å…¨éƒ¨ä¿¡æ¯, ä¸‹é¢æ˜¯ä¸‰ä¸ªèŠå¤©æ¨¡æ¿å­—ç¬¦ä¸²ï¼Œåˆ†åˆ«å¯¹åº”ä¸Šæ–‡æ‰€è¿°çš„ä¸‰ç§æ¶ˆæ¯æ ¼å¼:

```jinja2
{% for message in messages %}
    {% if message['role'] == 'user' %}
        {{ "User : " }}
    {% else %}
        {{ "Bot : " }}
    {{ message['content'] + '\n' }}
{% endfor %}
```

```jinja2
{% for message in messages %}
    {% if message['role'] == 'user' %}
        {{ "[USER]" + message['content'] + " [/USER]" }}
    {% else %}
        {{ "[ASST]" + message['content'] + " [/ASST]" }}
    {{ message['content'] + '\n' }}
{% endfor %}
```

```jinja2
"{% for message in messages %}"
    "{{'<|im_start|>' + message['role'] + '\n' + message['content'] + '<|im_end|>' + '\n'}}"
"{% endfor %}"
```

æˆ‘ä»¬è®¤ä¸ºæœ€æ¥è¿‘â€œæ ‡å‡†â€çš„æ ¼å¼æ˜¯ OpenAI åˆ›å»ºçš„ [ChatML æ ¼å¼](https://github.com/openai/openai-python/blob/main/chatml.md)ã€‚å¦‚æœä½ æ­£åœ¨è®­ç»ƒæ–°çš„èŠå¤©æ¨¡å‹ï¼Œå¹¶ä¸”æ­¤æ ¼å¼é€‚åˆä½ ï¼Œæˆ‘ä»¬å»ºè®®ä½ ä½¿ç”¨å®ƒå¹¶ç»™åˆ†è¯å™¨æ·»åŠ ç‰¹æ®Šçš„ `<|im_start|>` å’Œ `<|im_end|>` è¯å…ƒã€‚

å®ƒçš„ä¼˜ç‚¹æ˜¯è§’è‰²éå¸¸çµæ´»ï¼Œå› ä¸ºè§’è‰²åªæ˜¯ä½œä¸ºå­—ç¬¦ä¸²æ’å…¥ï¼Œè€Œä¸æ˜¯ç‰¹å®šçš„è§’è‰²è¯å…ƒã€‚å¦‚æœä½ æƒ³ä½¿ç”¨è¿™ä¸ªï¼Œå®ƒæ˜¯ä¸Šé¢çš„ç¬¬ä¸‰ä¸ªæ¨¡æ¿ï¼Œä½ å¯ä»¥ç®€å•åœ°ä½¿ç”¨ä¸€è¡Œä»£ç è¿›è¡Œè®¾ç½®

```python
tokenizer.chat_template = "{% for message in messages %}{{'<|im_start|>' + message['role'] + '\n' + message['content'] + '<|im_end|>' + '\n'}}{% endfor %}"
```

ä¸è¿‡ï¼Œé™¤äº†æ ¼å¼æ—ç«‹çš„ç°çŠ¶ä¹‹å¤–ï¼Œè¿˜æœ‰ç¬¬äºŒä¸ªä¸ç¡¬è®¾æ ‡å‡†æ ¼å¼çš„åŸå›  - æˆ‘ä»¬é¢„è®¡æ¨¡æ¿å°†å¹¿æ³›ç”¨äºå¤šç§ç±»å‹æ¨¡å‹çš„é¢„å¤„ç†ï¼ŒåŒ…æ‹¬é‚£äº›å¯èƒ½ä¸æ ‡å‡†èŠå¤©æ“ä½œè¿¥å¼‚çš„æ¨¡å‹ã€‚ç¡¬è®¾æ ‡å‡†æ ¼å¼é™åˆ¶äº†æ¨¡å‹å¼€å‘äººå‘˜ä½¿ç”¨æ­¤åŠŸèƒ½å®Œæˆæˆ‘ä»¬å°šæœªæƒ³åˆ°çš„ä»»åŠ¡çš„èƒ½åŠ›ï¼Œè€Œæ¨¡æ¿åˆ™ä¸ºç”¨æˆ·å’Œå¼€å‘äººå‘˜æä¾›äº†æœ€å¤§çš„è‡ªç”±åº¦ã€‚ç”šè‡³å¯ä»¥åœ¨æ¨¡æ¿ä¸­åŠ å…¥é€»è¾‘æ£€æŸ¥å’Œåˆ¤æ–­ï¼Œè¿™æ˜¯ç›®å‰ä»»ä½•é»˜è®¤æ¨¡æ¿ä¸­éƒ½æ²¡æœ‰æ·±å…¥ä½¿ç”¨çš„åŠŸèƒ½ï¼Œä½†æˆ‘ä»¬å¸Œæœ›å®ƒèƒ½æˆä¸ºå–œæ¬¢å†’é™©çš„ç”¨æˆ·æ‰‹ä¸­çš„åˆ©åˆƒã€‚æˆ‘ä»¬åšä¿¡ï¼Œå¼€æºç”Ÿæ€ç³»ç»Ÿåº”è¯¥è®©ä½ èƒ½å¤Ÿåšä½ æƒ³åšçš„äº‹ï¼Œè€Œä¸æ˜¯å‘½ä»¤ä½ åšä»€ä¹ˆã€‚

## Part â…¢ Pre-training models

### â‘  æ¨¡å‹çš„é¢„è®­ç»ƒ - å…¨æµç¨‹ - TinyLlama

> **[TinyLlama](https://github.com/jzhang38/TinyLlama) by Zhang et al.: Check this project to get a good understanding of how a Llama model is trained from scratch.**
>
> é‡Œé¢å±•ç°äº†å®Œæ•´çš„ (å°)å¤§æ¨¡å‹ ä»æ•°æ®åˆ°é¢„è®­ç»ƒçš„å®Œæ•´è¿‡ç¨‹, åŠå…¶å…¶ä¸­çš„è¯„ä¼°æ–¹å¼

- 1.1 B ç±» Llama æ¨¡å‹ | 3T Tokens | é¢„è®­ç»ƒ 16å— A100-40G GPU -> 90 Days å®Œæˆä»»åŠ¡ | 
- å¦‚æœè¦è®­ç»ƒ50äº¿ä»¥ä¸‹å‚æ•°çš„è¯­è¨€æ¨¡å‹, ä½ å…¶å®ä¸éœ€è¦Megatron-LM

| Setting                        | Description                                                  |
| ------------------------------ | ------------------------------------------------------------ |
| Parameters                     | 1.1B                                                         |
| Attention Variant              | Grouped Query Attention                                      |
| Model Size                     | Layers: 22, Heads: 32, Query Groups: 4, Embedding Size: 2048, Intermediate Size (Swiglu): 5632 |
| Sequence Length                | 2048                                                         |
| Batch Size                     | 2 million tokens (2048 * 1024)                               |
| Learning Rate                  | 4e-4                                                         |
| Learning Rate Schedule         | Cosine with 2000 warmup steps                                |
| Training Data                  | [Slimpajama](https://huggingface.co/datasets/cerebras/slimpajama-627b) & [Starcoderdata](https://huggingface.co/datasets/bigcode/starcoderdata) |
| Data Preprocessing             | Excluded GitHub subset of Slimpajama; Sampled all code from Starcoderdata |
| Combined Dataset Size          | Around 950B tokens                                           |
| Total Tokens During Training   | 3 trillion (slightly more than 3 epochs/143k steps)          |
| Natural Language to Code Ratio | 7:3                                                          |
| Hardware                       | 16 A100-40G GPUs                                             |

ä»£ç åº“æ”¯æŒä»¥ä¸‹ç‰¹æ€§ï¼š

- ä½¿ç”¨FSDPè¿›è¡Œå¤šGPUå’Œå¤šèŠ‚ç‚¹åˆ†å¸ƒå¼è®­ç»ƒ
- flash attention 2
- èåˆå±‚å½’ä¸€åŒ– (fused layernorm)
- èåˆswiglu (fused swiglu)
- èåˆäº¤å‰ç†µæŸå¤± (fused cross entropy loss)
- èåˆæ—‹è½¬ä½ç½®åµŒå…¥ (fused rotary positional embedding)

æœ‰äº†è¿™äº›ä¼˜åŒ–, æˆ‘ä»¬å¯ä»¥è¾¾åˆ°**24k tokens/ç§’/A100**çš„è®­ç»ƒé€Ÿåº¦ï¼Œä¹Ÿå°±æ˜¯56%çš„MFUï¼ˆåœ¨A100-80Gä¸Šçš„MFUä¼šæ›´é«˜ï¼‰ã€‚è¿™ä¸ªé€Ÿåº¦å¯ä»¥è®©ä½ å¯ä»¥åœ¨**8ä¸ªA100ä¸Šç”¨32å°æ—¶è®­ç»ƒä¸€ä¸ªchinchilla-optimialçš„æ¨¡å‹**(11äº¿å‚æ•°ï¼Œ220äº¿token)ã€‚è¿™äº›ä¼˜åŒ–ä¹Ÿå¤§å¤§å‡å°‘äº†æ˜¾å­˜å ç”¨, æˆ‘ä»¬å¯ä»¥æŠŠ11äº¿å‚æ•°çš„æ¨¡å‹å¡å…¥40GBçš„GPUé‡Œé¢è¿˜èƒ½åŒæ—¶ç»´æŒ16k tokensçš„per-gpu batch sizeã€‚åªéœ€è¦æŠŠbatch sizeæ”¹å°ä¸€ç‚¹ï¼Œ ä½ å°±å¯ä»¥åœ¨**RTX 3090/4090**ä¸Šé¢è®­ç»ƒTinyLlamaã€‚ 

### â‘¡ æ¨¡å‹çš„é¢„è®­ç»ƒ - å·¥ç¨‹ç»†èŠ‚ - BLOOM

> **[BLOOM](https://bigscience.notion.site/BLOOM-BigScience-176B-Model-ad073ca07cdf479398d5f95d88e218c4) by BigScience: **
>
> **Notion page that describes how the BLOOM model was built, with a lot of useful information about the engineering part and the problems that were encountered.**

BLOOM è®­ç»ƒä¿¡æ¯

**General**

- [ ] **176 B | 416 A100s | 100 Days** 
  - [ ] Traing : 384 A100 GPU with 80 Gb of memory each
  - [ ] Copy  : 48 GPUs (using 60 GB of memory on each GPU)
- [ ] **150 TFLOPs |** 

**Model Arch** 

- [ ] **70 layers | 112 attention heads per layers  |  hidden dimensionality of 14336  |  2048 tokens sequence length** 

**Data**

- [ ] **341.6 B tokens | 46 languages |** 

 ### â‘¢ æ¨¡å‹çš„é¢„è®­ç»ƒ - å·¥ç¨‹ç»†èŠ‚ - OPT

> **[OPT-175 Logbook](https://github.com/facebookresearch/metaseq/blob/main/projects/OPT/chronicles/OPT175B_Logbook.pdf) by Meta:** 
>
> **Research logs showing what went wrong and what went right. Useful if you're planning to pre-train a very large language model (in this case, 175B parameters).**

OPTï¼ˆOpen Pre-trained Transformerï¼‰æ˜¯ä¸€ç§é¢„è®­ç»ƒçš„å˜æ¢å™¨æ¨¡å‹ï¼Œç”±Metaï¼ˆåŸFacebookï¼‰å¼€å‘ã€‚è¯¥æ¨¡å‹è®¾è®¡ç”¨äºè‡ªç„¶è¯­è¨€å¤„ç†å’Œç†è§£ä»»åŠ¡ä¸­ï¼Œé‡‡ç”¨äº†ä¸GPTç±»ä¼¼çš„æ¶æ„ï¼Œå³åŸºäºTransformerçš„æ¶æ„ï¼Œé€šè¿‡å¤§è§„æ¨¡è¯­æ–™åº“è¿›è¡Œé¢„è®­ç»ƒï¼Œä»¥å­¦ä¹ è¯­è¨€çš„æ·±å±‚æ¬¡ç‰¹å¾ã€‚OPTæ¨¡å‹çš„å¼€æ”¾æ€§ä½“ç°åœ¨å…¶é¢„è®­ç»ƒæ¨¡å‹å’Œä»£ç çš„å…¬å¼€ï¼Œä½¿å¾—ç ”ç©¶äººå‘˜å’Œå¼€å‘è€…å¯ä»¥è‡ªç”±ä½¿ç”¨è¿™äº›èµ„æºï¼Œè¿›è¡Œä¸‹æ¸¸ä»»åŠ¡çš„å¾®è°ƒæˆ–ç ”ç©¶ã€‚

æœ¬æ–‡æ¡£æ˜¯å…³äºOPTæ¨¡å‹çš„ä¸€ä»½è®­ç»ƒæ—¥å¿—æŠ¥å‘Šï¼Œè®°å½•äº†æ¨¡å‹ä»åˆå§‹åŒ–åˆ°å¤šæ¬¡è®­ç»ƒå°è¯•çš„è¯¦ç»†è¿‡ç¨‹ã€‚

* æŠ¥å‘Šè¯¦ç»†è®°å½•äº†å„ç§è®­ç»ƒé…ç½®ã€é—®é¢˜è¯Šæ–­ã€è§£å†³æ–¹æ¡ˆä»¥åŠç»“æœã€‚
* æ–‡æ¡£ä¸­æ¶µç›–äº†ä»èŠ‚ç‚¹å’Œç¡¬ä»¶é—®é¢˜çš„å¤„ç†ï¼Œåˆ°æ¨¡å‹è¶…å‚æ•°çš„è°ƒæ•´ï¼Œå†åˆ°å®é™…è®­ç»ƒè¿‡ç¨‹ä¸­é‡åˆ°çš„å…·ä½“æŠ€æœ¯æŒ‘æˆ˜ã€‚

æŠ¥å‘Šä¸­åå¤æåŠäº†å¤šæ¬¡è¯•å›¾é€šè¿‡**ä¿®æ”¹å­¦ä¹ ç‡ã€æƒé‡è¡°å‡ç³»æ•°ã€æ¢¯åº¦è£å‰ªå€¼**ç­‰è¶…å‚æ•°æ¥ä¼˜åŒ–è®­ç»ƒè¿‡ç¨‹ï¼ŒåŒæ—¶ä¹Ÿå±•ç¤ºäº†åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¦‚ä½•**å¤„ç†å„ç§ç¡¬ä»¶å’Œè½¯ä»¶**å¼•èµ·çš„é—®é¢˜ï¼Œæ¯”å¦‚**GPUå¤±æ•ˆã€èŠ‚ç‚¹é€šä¿¡æ•…éšœ**ç­‰ã€‚æ­¤å¤–ï¼ŒæŠ¥å‘Šä¸­è¿˜æ¶‰åŠåˆ°äº†ä½¿ç”¨**ä¸åŒçš„æ•°æ®é›†ã€åˆå§‹åŒ–æ–¹æ³•**ã€ä»¥åŠ**æ¨¡å‹å¹¶è¡Œå¤„ç†æŠ€æœ¯**ç­‰å¤šç§å°è¯•ï¼Œæ—¨åœ¨æé«˜æ¨¡å‹æ€§èƒ½å¹¶å‡å°‘è®­ç»ƒæ—¶é—´ã€‚

æ•´ä½“æ¥çœ‹ï¼Œè¿™ä»½æŠ¥å‘Šæä¾›äº†ä¸€ä¸ªå…³äºå¤§è§„æ¨¡è¯­è¨€æ¨¡å‹è®­ç»ƒè¿‡ç¨‹çš„å…¨é¢è§†è§’ï¼Œå±•ç¤ºäº†åœ¨ç°å®ä¸–ç•Œä¸­è¿›è¡Œæ­¤ç±»è®­ç»ƒæ‰€éœ€é¢å¯¹çš„å¤æ‚æ€§å’ŒæŒ‘æˆ˜æ€§ï¼ŒåŒæ—¶ä¹Ÿçªæ˜¾äº†æŒç»­ä¼˜åŒ–å’Œé—®é¢˜è§£å†³ç­–ç•¥åœ¨æˆåŠŸè®­ç»ƒå¤§å‹æ¨¡å‹ä¸­çš„é‡è¦æ€§ã€‚

> ä¸€ã€æ¨¡å‹æ¦‚è§ˆ
> - æ¨¡å‹æ¶æ„: transformer_lm_megatron, ä½¿ç”¨äº†FSDP(Fully Sharded Data Parallel) å’Œ Tensor Parallelism
> - å±‚æ•°(nlay): 96 
> - åµŒå…¥ç»´åº¦(emb): 12288
> - æ‰¹å¤§å°(bm): 2048 (run 11.0å¼€å§‹, ä¹‹å‰ä¸º4096)
> - adam_beta2: 0.95 (run 11.7å¼€å§‹)
>
> äºŒã€æ•°æ®é›†
> - ä¸»è¦åŒ…å« BookCorpus, CC-Stories, OpenWebText2, Wikipedia,ä»¥åŠPush shift.ioç­‰è¯­æ–™
> - ä½¿ç”¨äº†å¤šç§è¿‡æ»¤å’Œæ¸…æ´—æ–¹æ³•, é€æ­¥ä¼˜åŒ–æ•°æ®è´¨é‡
> - run 11.7 å¼€å§‹ä½¿ç”¨æ‰‹å·¥æ­£åˆ™æ¸…æ´—åçš„æœ€ç»ˆè¯­æ–™
>
> ä¸‰ã€è®­ç»ƒè¶…å‚æ•°
> - ä¼˜åŒ–å™¨: Adamå’ŒFP16 Adam
> - æƒé‡è¡°å‡(weight_decay): 0.01 (run 6), 0.1 (run 8, 11.5), 0.05 (run 11.6, 11.8)
> - å­¦ä¹ ç‡(lr):
>     - 3e-4 (run 6,11.0), 7.5e-5 (run 11.1), 6e-5 (run 8, 11.9)
>     - ä½¿ç”¨çº¿æ€§lr warmup,æŒç»­çº¦290æ­¥(run 8)æˆ–1000æ­¥(run 11.0)
> - æ¢¯åº¦è£å‰ª(gradient clipping):
>     - 1.5 (run 11.2), 1.0 (run 8, 11.6, 11.7), 0.3 (run 12.16)
>     - run 11.5ç§»é™¤äº†æ¢¯åº¦è£å‰ª,æ”¹ä¸ºä¸¢å¼ƒè¶Šç•Œçš„batches
> - æ¯æ¬¡æ›´æ–°çš„tokens: 143052 (run 8), 147665 (run 9), 73832 (run 11.0)
> - æ¿€æ´»å‡½æ•°: GELU (run 11.0), ReLU (run 11.10, run 12.0)
> - æ€»æ›´æ–°æ­¥æ•°(max_updates):  286,720 (run 8), 147,666 (run 9, 11.0)
>
> å››ã€è®­ç»ƒæ¡†æ¶
> - Fairseq: æ¨¡å‹è®­ç»ƒæ¡†æ¶
> - Fairscale: æ”¯æŒFSDP(Fully Sharded Data Parallel)
> - Megatron-LM: æ”¯æŒTensor Parallelism
>
> äº”ã€è®­ç»ƒç¡¬ä»¶
> - Cloudé›†ç¾¤, æœ€å¤šä½¿ç”¨128ä¸ª8å¡A100-40GBèŠ‚ç‚¹
> - ç½‘ç»œäº’è”: Infiniband 200GB/s
> - NCCL + pytorchåˆ†å¸ƒå¼è®­ç»ƒ
>
> å…­ã€è®­ç»ƒç­–ç•¥
> - ä»checkpointæ¢å¤ä¸­æ–­çš„è®­ç»ƒ(æ¯”å¦‚run 12.25åˆ°run 12.54)
> - ä¼¸ç¼©å­¦ä¹ ç‡(æ¯”å¦‚run 12.42åˆ°run 12.52, ç¼©å‡lrè‡³0.75x)
> - æ›´æ¢æ¿€æ´»å‡½æ•° (ä»GELUåˆ°ReLU, run 11.10)
> - ç¼©å°æƒé‡åˆå§‹åŒ– (run 12.0)
> - è°ƒæ•´Adam betaæƒé‡(ä»0.98åˆ°0.95, run 11.7)
> - åœ¨è¶Šç•Œæ—¶è·³è¿‡æ›´æ–°, è€Œéè£å‰ªæ¢¯åº¦(run 11.6)
> - æ‰‹åŠ¨æ¸…æ´—è®­ç»ƒè¯­æ–™(run 11.7)
>
> ä¸ƒã€è®­ç»ƒç›‘æ§
> - åœ¨ä¸“é—¨çš„Tensorboardç›®å½•ä¸‹è®°å½•lossã€å­¦ä¹ ç‡ç­‰è®­ç»ƒæ›²çº¿
> - ç¼–å†™è„šæœ¬ç›‘æ§lossã€GPUçŠ¶æ€ã€è®­ç»ƒæ—¥å¿—æ˜¯å¦å¡ä½ç­‰
> - è½®å€¼å·¥ç¨‹å¸ˆå¯†åˆ‡å…³æ³¨è®­ç»ƒæ›²çº¿, æ ¹æ®å¼‚å¸¸å†³å®šæ˜¯å¦äººå·¥ä»‹å…¥
> - è¯¦ç»†è®°å½•æ¯æ¬¡æ“ä½œ, ç¡®ä¿å›¢é˜Ÿä¿¡æ¯åŒæ­¥
>
> ä»¥ä¸Šå°±æ˜¯æˆ‘ä»è¿™ä»½OPTè®­ç»ƒæŠ¥å‘Šä¸­æç‚¼çš„ä¸»è¦è®­ç»ƒç»†èŠ‚,å›´ç»•æ¨¡å‹ã€æ•°æ®ã€è¶…å‚æ•°ã€ç¡¬ä»¶ã€æ¡†æ¶ã€ç­–ç•¥ç­‰æ–¹é¢è¿›è¡Œäº†ç³»ç»Ÿæ¢³ç†,åŠ›æ±‚ç®€æ´æ˜äº†åˆä¸å¤±å…¨é¢ã€‚ä½ åœ¨å®é™…æ“ä½œæ—¶å¯ä»¥å‚è€ƒè¿™äº›å…³é”®ç‚¹,è®¾ç½®åˆé€‚çš„å‚æ•°,è¿ç”¨å¾—å½“çš„ä¼˜åŒ–æŠ€å·§,åŒæ—¶åšå¥½è®­ç»ƒè¿‡ç¨‹çš„ç›‘æ§,åŠæ—¶åº”å¯¹å¯èƒ½å‡ºç°çš„é—®é¢˜ã€‚æˆ‘ç›¸ä¿¡å¯¹ä½ çš„å·¥ä½œä¼šæœ‰æ‰€å¸®åŠ©ã€‚

### â‘£ æ¨¡å‹é¢„è®­ç»ƒ - å…¨æµç¨‹åŠä»£ç  - LLM360

ä¸€ä¸ªåŒ…å«è®­ç»ƒå’Œæ•°æ®å‡†å¤‡ä»£ç ã€æ•°æ®ã€æŒ‡æ ‡å’Œæ¨¡å‹çš„å¼€æº LLM æ¡†æ¶ã€‚

> [LLM360 | Open-source LLMs for Transparency, Trust, and Collaborative Research ğŸš€](https://www.llm360.ai/index.html)
>
> [Introducing LLM360: Fully Transparent open-source LLMs | LLM360](https://www.llm360.ai/blog/introducing-llm360-fully-transparent-open-source-llms.html)

LLM360 æ˜¯ä¸€é¡¹å…¨é¢ã€å®Œå…¨å¼€æºçš„ LLM è®¡åˆ’ï¼Œæ‰€æœ‰**è®­ç»ƒç»†èŠ‚**ã€**æ¨¡å‹æ£€æŸ¥ç‚¹**ã€**ä¸­é—´ç»“æœ**å’Œ**é™„åŠ åˆ†æ**å‡å‘ç¤¾åŒºå¼€æ”¾ã€‚æˆ‘ä»¬çš„ç›®æ ‡æ˜¯é‚€è¯·ç¤¾åŒºå…±åŒåŠ æ·±å¯¹ LLM çš„ç†è§£ï¼Œä»è€Œæ¨åŠ¨è¯¥é¢†åŸŸçš„å‘å±•ã€‚ä½œä¸º LLM360 é¡¹ç›®çš„ç¬¬ä¸€æ­¥ï¼Œæˆ‘ä»¬å‘å¸ƒäº†æ‰€æœ‰**ä¸­é—´æ¨¡å‹æ£€æŸ¥ç‚¹**ã€**å®Œå…¨å‡†å¤‡å¥½çš„é¢„è®­ç»ƒæ•°æ®é›†**ã€**æ‰€æœ‰æºä»£ç **å’Œ**é…ç½®**ä»¥åŠè®­ç»ƒç»†èŠ‚ã€‚æˆ‘ä»¬è‡´åŠ›äºé€šè¿‡è¿™é¡¹å¼€æºå·¥ä½œä¸æ–­æ¨åŠ¨ LLM çš„å‘å±•ã€‚

> å¤§å¤šæ•°å¼€æº LLM ç‰ˆæœ¬éƒ½åŒ…å«æ¨¡å‹æƒé‡å’Œè¯„ä¼°ç»“æœã€‚ç„¶è€Œï¼Œè¦çœŸæ­£ç†è§£ä¸€ä¸ªæ¨¡å‹çš„è¡Œä¸ºï¼Œå¾€å¾€è¿˜éœ€è¦å…¶ä»–ä¿¡æ¯ï¼Œè€Œå¤§å¤šæ•°ç ”ç©¶äººå‘˜é€šå¸¸æ— æ³•è·å¾—è¿™äº›ä¿¡æ¯ã€‚å› æ­¤ï¼Œæˆ‘ä»¬æ‰¿è¯ºå‘å¸ƒåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ”¶é›†åˆ°çš„æ‰€æœ‰ä¸­é—´æ£€æŸ¥ç‚¹ï¼ˆå¤šè¾¾ 360 ä¸ªï¼ï¼‰ã€æ‰€æœ‰è®­ç»ƒæ•°æ®ï¼ˆåŠå…¶ä¸æ£€æŸ¥ç‚¹çš„æ˜ å°„ï¼‰ã€æ‰€æœ‰æ”¶é›†åˆ°çš„æŒ‡æ ‡ï¼ˆå¦‚æŸå¤±ã€æ¢¯åº¦è§„èŒƒã€è¯„ä¼°ç»“æœï¼‰ï¼Œä»¥åŠé¢„å¤„ç†æ•°æ®å’Œæ¨¡å‹è®­ç»ƒçš„æ‰€æœ‰æºä»£ç ã€‚è¿™äº›é¢å¤–çš„äººå·¥åˆ¶å“å¯ä»¥å¸®åŠ©ç ”ç©¶äººå‘˜å’Œä»ä¸šäººå‘˜æ·±å…¥äº†è§£ LLM çš„æ„å»ºè¿‡ç¨‹ï¼Œå¹¶å¼€å±•æ¨¡å‹åŠ¨æ€åˆ†æç­‰ç ”ç©¶ã€‚æˆ‘ä»¬å¸Œæœ› LLM360 èƒ½è®©é«˜çº§ LLM æ›´åŠ é€æ˜ï¼Œä¿ƒè¿›å°è§„æ¨¡å®éªŒå®¤çš„ç ”ç©¶ï¼Œå¹¶æé«˜äººå·¥æ™ºèƒ½ç ”ç©¶çš„å¯é‡å¤æ€§ã€‚
>
> * é¢‘ç¹çš„ä¸­é—´æ¨¡å‹æ£€æŸ¥ç‚¹ï¼š
>
>   åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œå®šæœŸæ”¶é›†æ¨¡å‹å‚æ•°å’Œä¼˜åŒ–å™¨çŠ¶æ€ã€‚è¿™äº›å·¥ä»¶å¯ä»¥ä¸ºç ”ç©¶ LLM è®­ç»ƒåŠ¨æ€åŠå…¶å¦‚ä½•éšæ•°æ®æ‰©å±•æä¾›æœ‰ä»·å€¼çš„è§è§£ï¼Œå¹¶å…è®¸åœ¨ä¸åŒé˜¶æ®µæ¢å¤è®­ç»ƒã€‚
>
> * å…·æœ‰å®Œæ•´æ•°æ®åºåˆ—çš„è®­ç»ƒæ•°æ®ï¼š
>
>   æ•´ä¸ªç»è¿‡é¢„å¤„ç†ã€æ ‡è®°åŒ–çš„è®­ç»ƒæ•°æ®é›†å®Œå…¨å…¬å¼€ï¼Œå¯ä¾›å…¬ä¼—ä½¿ç”¨ã€‚æ•°æ®é›†ä¸è®­ç»ƒæ­¥éª¤å®Œå…¨å¯¹åº”ã€‚
>
> * æºä»£ç ï¼šä½¿ç”¨çš„æ‰€æœ‰ä»£ç ï¼ŒåŒ…æ‹¬æ•°æ®å¤„ç†ã€è®­ç»ƒã€è¯„ä¼°å’Œåˆ†æã€‚
>
> * æ—¥å¿—å’ŒæŒ‡æ ‡ï¼šå…¬å¼€æŠ«éœ²åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ”¶é›†çš„æ‰€æœ‰è®­ç»ƒæ—¥å¿—ã€è¯„ä¼°å’Œåˆ†æç»“æœï¼Œå¹¶ä¸è®­ç»ƒæ­¥éª¤å’Œæ•°æ®åºåˆ—ç›¸å¯¹åº”ã€‚

### â‘¥ å¼€æº é¢„è®­ç»ƒæ•°æ®é›† 

> [GitHub - Zjh-819/LLMDataHub: A quick guide (especially) for trending instruction finetuning datasets](https://github.com/Zjh-819/LLMDataHub?tab=readme-ov-file#domain-specific-datasets--)

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ï¼Œå¦‚ OpenAI çš„ GPT ç³»åˆ—ã€è°·æ­Œçš„ Bard å’Œç™¾åº¦çš„æ–‡å¿ƒé›•é¾™ï¼Œæ­£åœ¨æ¨åŠ¨æ·±åˆ»çš„æŠ€æœ¯å˜é©ã€‚æœ€è¿‘ï¼Œéšç€ LlaMa å’Œ ChatGLM ç­‰å¼€æºå¤§å‹æ¨¡å‹æ¡†æ¶çš„å‡ºç°ï¼ŒåŸ¹è®­ LLM ä¸å†æ˜¯èµ„æºä¸°å¯Œçš„å…¬å¸çš„ä¸“å±é¢†åŸŸã€‚å°å‹ç»„ç»‡æˆ–ä¸ªäººåŸ¹è®­ LLM å·²æˆä¸ºå¼€æºç¤¾åŒºçš„ä¸€ä¸ªé‡è¦å…´è¶£ç‚¹ï¼Œä¸€äº›è‘—åçš„ä½œå“åŒ…æ‹¬ Alpacaã€Vicuna å’Œ Luotuoã€‚é™¤äº†å¤§å‹æ¨¡å‹æ¡†æ¶ï¼Œå¤§è§„æ¨¡å’Œé«˜è´¨é‡çš„è®­ç»ƒè¯­æ–™åº“å¯¹äºè®­ç»ƒå¤§å‹è¯­è¨€æ¨¡å‹ä¹Ÿè‡³å…³é‡è¦ã€‚ç›®å‰ï¼Œç¤¾åŒºä¸­ç›¸å…³çš„å¼€æºè¯­æ–™ä»å¾ˆåˆ†æ•£ã€‚å› æ­¤ï¼Œæœ¬èµ„æºåº“çš„ç›®æ ‡æ˜¯åœ¨å¼€æºç¤¾åŒºä¸­æŒç»­æ”¶é›†é«˜è´¨é‡çš„ LLM è®­ç»ƒè¯­æ–™ã€‚

è¦è®­ç»ƒä¸€ä¸ªèƒ½æœ‰æ•ˆéµä»äººç±»æŒ‡ä»¤çš„èŠå¤©æœºå™¨äºº LLMï¼Œéœ€è¦è®¿é—®æ¶µç›–ä¸€ç³»åˆ—å¯¹è¯é¢†åŸŸå’Œé£æ ¼çš„é«˜è´¨é‡æ•°æ®é›†ã€‚åœ¨æœ¬èµ„æºåº“ä¸­ï¼Œæˆ‘ä»¬æä¾›äº†ä¸“ä¸ºèŠå¤©æœºå™¨äººè®­ç»ƒè€Œè®¾è®¡çš„æ•°æ®é›†ï¼ŒåŒ…æ‹¬é“¾æ¥ã€å¤§å°ã€è¯­è¨€ã€ä½¿ç”¨æƒ…å†µä»¥åŠæ¯ä¸ªæ•°æ®é›†çš„ç®€è¦è¯´æ˜ã€‚æˆ‘ä»¬çš„ç›®æ ‡æ˜¯è®©ç ”ç©¶äººå‘˜å’Œä»ä¸šäººå‘˜æ›´å®¹æ˜“è¯†åˆ«å’Œé€‰æ‹©æœ€ç›¸å…³ã€æœ€æœ‰ç”¨çš„æ•°æ®é›†ï¼Œæ»¡è¶³ä»–ä»¬çš„èŠå¤©æœºå™¨äºº LLM åŸ¹è®­éœ€æ±‚ã€‚æ— è®ºæ‚¨æ˜¯åœ¨æé«˜èŠå¤©æœºå™¨äººå¯¹è¯è´¨é‡ã€ç”Ÿæˆå“åº”è¿˜æ˜¯è¯­è¨€ç†è§£ï¼Œè¿™ä¸ªèµ„æºåº“éƒ½èƒ½æ»¡è¶³æ‚¨çš„éœ€æ±‚ã€‚

## Part â…£ Supervised Fine-Tuning

### â‘  LLM å¾®è°ƒæµç¨‹ [ Base LoRA ]

> **[The Novice's LLM Training Guide](https://rentry.org/llm-training) by Alpin: **
>
> **Overview of the main concepts and parameters to consider when fine-tuning LLMs.**

#### 0 **æ€»è¿°** 

LoRA : å¯ä»¥å‡å° ä¸€ä¸‡å€çš„å¯è®­ç»ƒå‚æ•°é‡, åŒæ—¶ GPU å†…å­˜é‡å¯ä»¥å‡å°ä¸‰å€. 

> [Parameter-Efficient Fine-Tuning using ğŸ¤— PEFT (huggingface.co)](https://huggingface.co/blog/peft) -> Transformers è°ƒç”¨ LoRA

QLoRA : åˆ©ç”¨ bitsandbytes åº“å¯¹è¯­è¨€æ¨¡å‹è¿›è¡Œå³æ—¶ã€è¿‘ä¹æ— æŸçš„é‡åŒ–ï¼Œå¹¶å°†å…¶åº”ç”¨äº LoRA è®­ç»ƒç¨‹åºã€‚éå¸¸èŠ‚çœå†…å­˜, ç”šè‡³èƒ½ä½¿ç”¨ 2Ã—3090s æ¥è®­ç»ƒ70Bå‚æ•°æ¨¡å‹. (å¦åˆ™è¦ä½¿ç”¨ 16Ã—A100 80Gæ¥è¿›è¡Œå…¨å‚æ•°å¾®è°ƒ ) |  
It enables the finetuning of a 65B parameter model on a single 48GB GPU, while **preserving full 16-bit fine-tuning task performance.**

ä¸‹é¢æ˜¯ä¸€ä¸ªå¾®è°ƒè¿‡ç¨‹è®²è§£: **ä½¿ç”¨ QLoRA åœ¨å•å¼  3090 ä¸Šé¢ å¾®è°ƒ Mistral 7B æ¨¡å‹** 

#### 1 å¾®è°ƒ - æ¦‚è¿°

##### è®­ç»ƒèµ„æº

Base **Llama-7B** OR **Mistral 7B** -> **160~192GB range**

GPU ç§Ÿç”¨ :  [Runpod](https://runpod.io/), [VastAI](https://vast.ai/), [Lambdalabs](https://lambdalabs.com/), and [Amazon AWS Sagemaker](https://aws.amazon.com/sagemaker/). | VastAI is the Cheapest & AWS is the most expensive.

TPU ä½¿ç”¨ | Know a guy who knows a guy.

##### æ•°æ®é›†

éœ€è¦å…³æ³¨ä¸€ä¸‹å‡ ç‚¹: 

1. **Dataset size**: **å¯¹è¯æ¨¡å‹ä¸åº”è¯¥åªåŒ…å«å¯¹è¯**
   æ‚¨ä¸å¸Œæœ›æ‚¨çš„æ¨¡å‹åªèƒ½å®Œæˆä¸€é¡¹éå¸¸å…·ä½“çš„ä»»åŠ¡ã€‚
   æ‚¨éœ€è¦å¤šæ ·åŒ–çš„è®­ç»ƒæ ·æœ¬ï¼ŒåŒ…æ‹¬å„ç§åœºæ™¯ï¼Œè¿™æ ·æ‚¨çš„æ¨¡å‹æ‰èƒ½å­¦ä¼šå¦‚ä½•é’ˆå¯¹ä¸åŒç±»å‹çš„è¾“å…¥ç”Ÿæˆè¾“å‡ºã€‚

2. **Dataset size: ** éœ€è¦æ¯”LoRAæ›´å¤šçš„å¾®è°ƒæ•°æ®, [Rule of a thumb] è‡³å°‘10Mib çš„æ–‡æœ¬æ•°æ®. è¶Šå¤§è¶Šå¥½
3. **Dataset quality**: æ•°æ®è´¨é‡éå¸¸é‡è¦

> æ•°æ®å¤„ç†: 
>
> - [ ] HTML - ä½¿ç”¨ [Beautiful Soup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) è¿›è¡Œè§£æ æå–æ•°æ®
> - [ ] CSV - ä½¿ç”¨ Pandas   è¿›è¡Œæå–
> - [ ] SQL - ä½¿ç”¨ [sqlparse](https://sqlparse.readthedocs.io/en/latest/) è¿›è¡ŒMariaDB or PostgreSQLæ•°æ®åº“çš„æå–
> - [ ] AIGC - éœ€è¦å»é™¤ "As an AI language model..." ç­‰å†…å®¹. ä½¿ç”¨  
>   [This script](https://huggingface.co/datasets/ehartford/wizard_vicuna_70k_unfiltered/blob/main/optional_clean.py) by [ehartford](https://huggingface.co/ehartford) is a good filter for this specific task. You can also refer to the [gptslop](https://github.com/AlpinDale/gptslop) repo.

##### è®­ç»ƒæ¡†æ¶

**STEP 1 é…ç½®ç¯å¢ƒ**

Use the [**axolotl**](https://github.com/OpenAccess-AI-Collective/axolotl) trainer for fine-tuning, as it's simple to use and has all the features we need.

Clone the repository and install requirements | äº‘GPU é€šå¸¸åŒ…æ‹¬äº†æ‰€æœ‰çš„ç¯å¢ƒ

```bash
git clone https://github.com/OpenAccess-AI-Collective/axolotl && cd axolotl
pip3 install packaging
pip3 install -e '.[flash-attn,deepspeed]'
```

Axolotl takes all the options for training in a single `yaml` file. 

There are already some sample configs in the `examples` directory, for various different models.

è¿è¡Œä»¥ä¸‹å‘½ä»¤å¼€å§‹è¿è¡Œ - **æµ‹è¯•ç¯å¢ƒé€šè¿‡æ€§** | 

```bash
accelerate launch -m axolotl.cli.train examples/mistral/config.yml
```

**STEP 2 è½¬æ¢æ•°æ®æ ¼å¼**

**è½¬æ¢ æ•°æ®æ ¼å¼** -> [GitHub - OpenAccess-AI-Collective/axolotl: Go ahead and axolotl questions](https://github.com/OpenAccess-AI-Collective/axolotl#config)

è¦ä½¿ç”¨è‡ªå®šä¹‰æ•°æ®é›†ï¼Œæ‚¨éœ€è¦å°†å…¶æ­£ç¡®æ ¼å¼åŒ–ä¸º JSONL æ–‡ä»¶ã€‚Axolotl æ”¯æŒå¤šç§ä¸åŒæ ¼å¼ï¼Œä½ å¯ä»¥åœ¨è¿™é‡Œæ‰¾åˆ°ç¤ºä¾‹ã€‚

ç„¶åï¼Œä½ å¯ä»¥ç¼–è¾‘ qlora.yml æ–‡ä»¶å¹¶å°†å…¶æŒ‡å‘ä½ çš„æ•°æ®é›†ã€‚è¿™é‡Œæœ‰æ‰€æœ‰é…ç½®é€‰é¡¹çš„å®Œæ•´è§£é‡Šï¼Œç¡®ä¿ç‚¹å‡»å±•å¼€æŒ‰é’®æŸ¥çœ‹æ‰€æœ‰é€‰é¡¹ï¼

#### 2 LoRA - æƒé‡

ä¿ç•™é¢„å…ˆè®­ç»ƒçš„æƒé‡ | è®­ç»ƒè¿‡çš„æƒé‡çš„å¯ç§»æ¤æ€§ | ä¸æ³¨æ„å±‚é›†æˆ | å†…å­˜æ•ˆç‡ | 

| å‚æ•°                    | æè¿°                                                 | è¡¥å……                                                         |
| ----------------------- | ---------------------------------------------------- | ------------------------------------------------------------ |
| **LoRA Rank**           | Determines the number of rank decomposition matrices | 1 æœ€ä½ä¸º8, è¶Šé«˜æ€§èƒ½è¶Šé«˜. <br />2 æ•°æ®é›†è¶Šå¤æ‚, è¿™ä¸ªå€¼è¶Šé«˜.<br />3 è¶Šé«˜çš„ Rank å¯¹åº”è¶Šé«˜çš„è®¡ç®—å¤æ‚åº¦<br />4 å½“ Rank ç­‰äº Hidden Size çš„æ—¶å€™, ç­‰ä»·äºå…¨é‡å¾®è°ƒ |
| **LoRA Alpha**          | LoRA çš„ç¼©æ”¾å› å­ï¼Œå†³å®šäº†æ¨¡å‹å¯¹æ–°è®­ç»ƒæ•°æ®çš„é€‚åº”ç¨‹åº¦ã€‚  | 1 alpha å€¼ç”¨äºè°ƒæ•´è®­ç»ƒè¿‡ç¨‹ä¸­æ›´æ–°çŸ©é˜µçš„è´¡çŒ®ã€‚<br />2 ä¸è¾ƒé«˜çš„å€¼ç›¸æ¯”ï¼Œè¾ƒä½çš„å€¼ä¼šç»™äºˆåŸå§‹æ•°æ®æ›´å¤šçš„æƒé‡ï¼Œå¹¶åœ¨æ›´å¤§ç¨‹åº¦ä¸Šä¿æŒæ¨¡å‹çš„ç°æœ‰çŸ¥è¯†ã€‚ |
| **LoRA Target Modules** | ç¡®å®šè¦è®­ç»ƒå“ªäº›ç‰¹å®šæƒé‡å’ŒçŸ©é˜µ                         | 1 æœ€åŸºæœ¬çš„è®­ç»ƒçŸ©é˜µæ˜¯æŸ¥è¯¢å‘é‡ï¼ˆå¦‚ `q_proj`ï¼‰å’Œå€¼å‘é‡ï¼ˆå¦‚ `v_proj`ï¼‰æŠ•å½±çŸ©é˜µã€‚è¿™äº›çŸ©é˜µçš„åç§°å› æ¨¡å‹è€Œå¼‚ã€‚<br />2 ä¸€èˆ¬æ¥è¯´, å¦‚æœæ¶‰åŠåˆ°é¢†åŸŸçš„è¿ç§», é‚£ä¹ˆæ¨¡å‹çš„è¾“å…¥Embeddingå±‚å’Œè¾“å‡ºEmbeddingå±‚éƒ½éœ€è¦è¿›è¡Œç›¸åº”çš„è°ƒæ•´ |

> You can find out the exact names by running the following script:
>
> ```python
> from transformers import AutoModelForCausalLM
> model_name = "huggyllama/llama-7b"      # can also be a local directory
> model = AutoModelForCausalLM.from_pretrained(model_name)
> layer_names = model.state_dict().keys()
> 
> for name in layer_names:
>     print(name)
> ```
>
> output
>
> ```python
> model.embed_tokens.weight
> model.layers.0.self_attn.q_proj.weight
> model.layers.0.self_attn.k_proj.weight
> model.layers.0.self_attn.v_proj.weight
> model.layers.0.self_attn.o_proj.weight
> model.layers.0.self_attn.rotary_emb.inv_freq
> model.layers.0.mlp.gate_proj.weight
> model.layers.0.mlp.down_proj.weight
> model.layers.0.mlp.up_proj.weight
> model.layers.0.input_layernorm.weight
> model.layers.0.post_attention_layernorm.weight
> 
> ...
> 
> model.norm.weight
> lm_head.weight
> ```
>
> The naming convention is essentially: `{identifier}.{layer}.{layer_number}.{component}.{module}.{parameter}`. 

#### 3 QLoRA

1. **é€šè¿‡é‡åŒ–çš„é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹è¿›è¡Œæ¢¯åº¦åå‘ä¼ æ’­ **Backpropagation of gradients through a frozenï¼š

   è¿™æ¶‰åŠåˆ°é€šè¿‡ä¸€ä¸ªè¢«å†»ç»“ä¸”è¢«é‡åŒ–åˆ°4æ¯”ç‰¹çš„è¯­è¨€æ¨¡å‹åå‘ä¼ æ’­æ¢¯åº¦ã€‚

   é€šå¸¸ï¼Œé‡åŒ–å¯ä»¥å‡å°‘å­˜å‚¨æ¨¡å‹æƒé‡æ‰€éœ€çš„å†…å­˜é‡ï¼Œä½†å¦‚æœå¤„ç†ä¸å½“ï¼Œä¹Ÿå¯èƒ½å½±å“æ€§èƒ½ã€‚åœ¨QLoRAä¸­ï¼Œå°½ç®¡è¿›è¡Œäº†é‡åŒ–ï¼Œä½†ç”±äºä¸ä½ç§©é€‚é…å™¨ï¼ˆLoRAï¼‰çš„ç»“åˆä½¿ç”¨ï¼Œæ¨¡å‹ä»ç„¶èƒ½å¤Ÿä¿æŒæœ‰æ•ˆæ€§ã€‚

2. **ä½¿ç”¨4æ¯”ç‰¹æ­£æ€æµ®ç‚¹ï¼ˆNormalFloat, NF4ï¼‰**ï¼š

   NF4æ˜¯ä¸€ç§æ–°å‹æ•°æ®ç±»å‹ï¼Œä¸“é—¨è®¾è®¡ç”¨äºä»¥å‡å°‘å†…å­˜ä½¿ç”¨çš„æ–¹å¼å¤„ç†éµå¾ªæ­£æ€åˆ†å¸ƒçš„æƒé‡ï¼ˆä½¿ç”¨4æ¯”ç‰¹è€Œä¸æ˜¯æ›´å¸¸è§çš„16æˆ–32æ¯”ç‰¹ï¼‰ã€‚è¿™ç§æ•°æ®ç±»å‹é€šè¿‡ä¼˜åŒ–æƒé‡çš„å­˜å‚¨å’Œå¤„ç†æ–¹å¼ï¼Œå¸®åŠ©ç»´æŒé‡åŒ–æ¨¡å‹çš„æ€§èƒ½ã€‚

3. **åŒé‡é‡åŒ– (Double quantization)**ï¼š

   è¿™ç§æ–¹æ³•é€šè¿‡ä¸ä»…é‡åŒ–æ¨¡å‹æƒé‡ï¼Œè¿˜é‡åŒ–é‡åŒ–å¸¸æ•°æœ¬èº«ï¼Œè¿›ä¸€æ­¥å‡å°‘äº†å†…å­˜ä½¿ç”¨ã€‚è¿™ç§åˆ†å±‚é‡åŒ–ç­–ç•¥æœ€å°åŒ–äº†æ¨¡å‹çš„å¹³å‡å†…å­˜å ç”¨ã€‚

4. **åˆ†é¡µä¼˜åŒ–å™¨ (Paged optimizers)**ï¼š

   åœ¨å¾®è°ƒè¿‡ç¨‹ä¸­ï¼Œå†…å­˜ä½¿ç”¨å¯èƒ½ä¼šæ˜¾è‘—å¢åŠ ï¼Œè¿™åœ¨ç¡¬ä»¶æœ‰é™çš„æƒ…å†µä¸‹å¯èƒ½éš¾ä»¥ç®¡ç†ã€‚åˆ†é¡µä¼˜åŒ–å™¨é€šè¿‡å°†ä¼˜åŒ–å™¨çš„å†…å­˜éœ€æ±‚åˆ†è§£æˆæ›´å°ã€æ›´æ˜“ç®¡ç†çš„â€œé¡µé¢â€ï¼Œå¸®åŠ©æ›´æœ‰æ•ˆåœ°ç®¡ç†è¿™äº›å³°å€¼ã€‚

#### 4 è®­ç»ƒè¶…å‚æ•°

##### **Batch Size and Epoch** 

##### **Learning Rate** 

> " å¯èƒ½æ˜¯æœ€é‡è¦çš„è¶…å‚æ•°, å¦‚æœä½ åªèƒ½è°ƒèŠ‚ä¸€ä¸ªè¶…å‚æ•°, è¯·è°ƒèŠ‚å­¦ä¹ ç‡ "

* high learning rate = less epochs. && low learning rate = more epochs.
* äº†è§£ä½ æ­£åœ¨å¾®è°ƒçš„é¢„è®­ç»ƒæ¨¡å‹ä½¿ç”¨çš„å­¦ä¹ ç‡ï¼Œå¹¶ä»¥æ­¤ä¸ºåŸºç¡€ | å¸¸ç”¨å­¦ä¹ ç‡ä¸º 1e-5
* é€šè¿‡ è§‚å¯Ÿè®­ç»ƒLossä¸‹é™å¿«æ…¢, è¿­ä»£è°ƒæ•´å­¦ä¹ ç‡

**è®¡ç®—å…¬å¼ general-purpose formula**
$$
base\_lr * sqrt(supervised\_tokens\_in\_batch / pretrained\_bsz)
$$

* The `base_lr` refers to the **pre-trained model's learning rate**. In case of Mistral, this is 5e-5. for Llama-2 models is 3e-4.

* `supervised_tokens_in_batch` refers the **total number of supervised tokens** (axolotl reports this number once you start training), **dividing that by total number of steps** (also reported by axolotl) **divided by the total number of epochs**

  å³ æ€»ç›‘ç£è®­ç»ƒTokenæ•° / ( å®Œæˆæ•´ä¸ªè®­ç»ƒè¿‡ç¨‹ä¸­æ¨¡å‹æ›´æ–°æƒé‡çš„æ¬¡æ•° / Epoch æ•°) 

  - **åˆ†å­ (`supervised_tokens_in_batch`)**: è¿™æ˜¯æ•´ä¸ªè®­ç»ƒæ‰¹æ¬¡ä¸­çš„æ€»ç›‘ç£æ ‡è®°æ•°ã€‚
  - **åˆ†æ¯ (`total number of steps / total number of epochs`)**: è¿™æ˜¯å¹³å‡æ¯ä¸ªè®­ç»ƒå‘¨æœŸä¸­çš„æ­¥æ•°ã€‚é€šè¿‡æ€»æ­¥æ•°é™¤ä»¥æ€»å‘¨æœŸæ•°ï¼Œæˆ‘ä»¬å¯ä»¥å¾—åˆ°æ¯ä¸ªå‘¨æœŸä¸­å¹³å‡æœ‰å¤šå°‘stepã€‚

  è¿™ä¸ªæ¯”å€¼ç»™å‡ºäº†æ¯ä¸ªè®­ç»ƒå‘¨æœŸä¸­å¹³å‡æ¯æ­¥å¤„ç†çš„ç›‘ç£æ ‡è®°æ•°ã€‚| 

  **ç›´è§‚æ¥è®², è¿™ä¸ªå€¼å°±æ˜¯å¤šå°‘ä¸ªTokenè¿›è¡Œä¸€æ¬¡æƒé‡æ›´æ–°.**

* The `pretrained_bsz` refers to the original **batch size** of the base model.  In case of Mistral and Llama, this is 4,000,000 (4 millions)

å‡è®¾æˆ‘ä»¬ç”¨ 2M ç›‘ç£ Token æƒé‡æ›´æ–° 350æ¬¡, 

è€Œ Llama é¢„è®­ç»ƒ  4,000,000 (4 millions). Tokens è¿­ä»£ä¸€æ¬¡æ¨¡å‹. é‚£ä¹ˆå­¦ä¹ ç‡å°±å¯ä»¥å¦‚ä¸‹æ‰€ç¤ºçš„è®¡ç®—
$$
5e-5 * sqrt(2000000/(350/1) / 4000000) = 0.00000189 (1.89e-6)
$$

### â‘¡ LLM å¾®è°ƒ - LoRA Insights

> [LoRA insights](https://lightning.ai/pages/community/lora-insights/) by Sebastian Raschka: Practical insights about LoRA and how to select the best parameters.

Specifically, I aim to address questions about **the value of QLoRA**, **whether to replace AdamW with SGD**, **the potential use of a scheduler**, and **how to adjust the LoRA hyperparameters**.

> æœ¬æ–‡æ¢è®¨äº†æˆ‘ä»¬åœ¨ä½¿ç”¨ LoRA è®­ç»ƒè‡ªå®šä¹‰ LLM æ—¶å¯ä»¥è°ƒæ•´çš„å„ç§æ—‹é’®ã€‚
>
> æˆ‘ä»¬å‘ç°ï¼Œ**QLoRA è™½ç„¶ä¼šå¢åŠ è¿è¡Œæ—¶é—´æˆæœ¬ï¼Œä½†å´èƒ½æå¤§åœ°èŠ‚çœå†…å­˜**ã€‚
>
> æ­¤å¤–ï¼Œè™½ç„¶å­¦ä¹ ç‡è°ƒåº¦å™¨ä¹Ÿæœ‰å¥½å¤„ï¼Œä½†åœ¨ **AdamW å’Œ SGD ä¼˜åŒ–å™¨ä¹‹é—´è¿›è¡Œé€‰æ‹©å‡ ä¹æ²¡æœ‰ä»€ä¹ˆåŒºåˆ«**ã€‚(åŒ…æ‹¬æ˜¾å­˜)
>
> **å¯¹æ•°æ®é›†è¿›è¡Œå¤šæ¬¡è¿­ä»£ä¼šä½¿ç»“æœæ›´ç³Ÿ**ã€‚
>
> é€šè¿‡ä¼˜åŒ– LoRA è®¾ç½®ï¼ˆåŒ…æ‹¬Rankï¼‰ï¼Œå¯ä»¥è·å¾—æœ€ä½³æ€§ä»·æ¯”ã€‚Rank åœ¨ llama 7B ä¸Šè®¾ç½®ä¸º256æ•ˆæœä¸é”™
>
> æé«˜ç§©ä¼šå¸¦æ¥æ›´å¤šå¯è®­ç»ƒå‚æ•°ï¼Œè¿™å¯èƒ½ä¼šå¯¼è‡´æ›´é«˜çš„è¿‡æ‹Ÿåˆç¨‹åº¦å’Œè¿è¡Œæ—¶é—´æˆæœ¬ã€‚ä¸è¿‡ï¼Œåœ¨æé«˜ç§©æ—¶ï¼Œé€‰æ‹©é€‚å½“çš„é˜¿å°”æ³•å€¼éå¸¸é‡è¦ã€‚(**Rank ä¸º Î± çš„ä¸¤å€æ˜¯ä¸€ä¸ªç»éªŒå€¼**)

#### 1 Evaluation Tasks and Dataset

Model evaluation, I selected a small subset of tasks from Eleuther AIâ€™s [Evaluation Harness](https://github.com/EleutherAI/lm-evaluation-harness/tree/master), including [TruthfulQA](https://github.com/sylinrl/TruthfulQA), [BLiMP Causative,](https://github.com/alexwarstadt/blimp) [MMLU Global Facts](https://github.com/hendrycks/test), and simple arithmetic tasks with two (arithmetic 2ds) and four digits (arithmetic 4ds).

TruthfulQA : 

* ä»»åŠ¡ï¼šç»™å®šä¸€ä¸ªé—®é¢˜ï¼Œç»™å‡º 1-2 å¥è¯çš„ç­”æ¡ˆã€‚
* ç›®æ ‡ï¼šé¦–è¦ç›®æ ‡æ˜¯æ€»ä½“çœŸå®åº¦ï¼Œå³æ¨¡å‹ç­”æ¡ˆä¸­çœŸå®ç­”æ¡ˆæ‰€å çš„ç™¾åˆ†æ¯”ã€‚ç”±äºå¯ä»¥ç”¨å¯¹æ¯ä¸ªé—®é¢˜éƒ½å›ç­” "æˆ‘æ— å¯å¥‰å‘Š "çš„æ¨¡å‹æ¥å®ç°è¿™ä¸€ç›®æ ‡ï¼Œå› æ­¤æ¬¡è¦ç›®æ ‡æ˜¯æ¨¡å‹ç­”æ¡ˆä¸­ä¿¡æ¯é‡å¤§çš„ç™¾åˆ†æ¯”ã€‚
* MC1 ï¼ˆå•é€‰é¢˜ï¼‰ï¼š
  ç»™å®šä¸€ä¸ªé—®é¢˜å’Œ 4-5 ä¸ªç­”æ¡ˆé€‰é¡¹ï¼Œé€‰æ‹©å”¯ä¸€æ­£ç¡®çš„ç­”æ¡ˆã€‚æ¨¡å‹é€‰æ‹©çš„ç­”æ¡ˆæ˜¯å®ƒè®¤ä¸ºå®Œæˆé—®é¢˜çš„å¯¹æ•°æ¦‚ç‡æœ€é«˜çš„ç­”æ¡ˆé€‰é¡¹ï¼Œä¸å…¶ä»–ç­”æ¡ˆé€‰é¡¹æ— å…³ã€‚å¾—åˆ†æ˜¯æ‰€æœ‰é—®é¢˜çš„ç®€å•å‡†ç¡®ç‡ã€‚
* MC2ï¼ˆå¤šçœŸï¼‰ï¼š
  ç»™å®šä¸€ä¸ªé—®é¢˜å’Œå¤šä¸ªçœŸ/å‡å‚è€ƒç­”æ¡ˆï¼Œåˆ†æ•°å°±æ˜¯åˆ†é…ç»™ä¸€ç»„çœŸç­”æ¡ˆçš„å½’ä¸€åŒ–æ€»æ¦‚ç‡ã€‚

BLiMP : 

BLiMP æ˜¯ä¸€ä¸ªæŒ‘æˆ˜é›†ï¼Œç”¨äºè¯„ä¼°è¯­è¨€æ¨¡å‹ï¼ˆLMï¼‰å¯¹**è‹±è¯­ä¸»è¦è¯­æ³•ç°è±¡çš„äº†è§£ç¨‹åº¦**ã€‚BLiMP ç”± 67 ä¸ªå­æ•°æ®é›†ç»„æˆï¼Œæ¯ä¸ªå­æ•°æ®é›†åŒ…å« 1000 ä¸ªæœ€å°å¯¹ï¼Œè¿™äº›æœ€å°å¯¹åˆ†ç¦»äº†å¥æ³•ã€è¯æ³•æˆ–è¯­ä¹‰ä¸­çš„ç‰¹å®šå¯¹æ¯”ã€‚è¿™äº›æ•°æ®æ˜¯æ ¹æ®ä¸“å®¶åˆ›å»ºçš„è¯­æ³•è‡ªåŠ¨ç”Ÿæˆçš„ã€‚äººç±»ä¸æ ‡ç­¾çš„æ€»ä¸€è‡´ç‡ä¸º 96.4%ã€‚æˆ‘ä»¬ä½¿ç”¨ BLiMP è¯„ä¼°äº† n-gram LMã€LSTM LMã€GPT-2 å’Œ Transformer-XLã€‚

MMLU : æµ‹é‡å¤§è§„æ¨¡å¤šä»»åŠ¡è¯­è¨€ç†è§£èƒ½åŠ›

#### 2 Code Framework

The custom LLM finetuning code I used for this article is based on the open-source [Lit-GPT repository](https://github.com/Lightning-AI/lit-gpt).

#### 3 Choosing a Good Base Model

**Llama 2 7B** 

#### 4 Evaluating the LoRA Defaults

åœ¨æˆ‘çš„æœºå™¨ä¸Šï¼Œä½¿ç”¨ä¸€å° A100ï¼Œåœ¨æ€»å…± 6,738,415,616 [7B] ä¸ªå¯è®­ç»ƒå‚æ•°ä¸­ï¼Œè¯¥é…ç½®è®­ç»ƒäº† 4,194,304 [4M] ä¸ª LoRA å‚æ•°ï¼Œè€—æ—¶çº¦ 1.8 å°æ—¶ã€‚æœ€å¤§å†…å­˜ä½¿ç”¨é‡ä¸º 21.33 GBã€‚ä¸‰æ¬¡å®éªŒ

```python
### é»˜è®¤
# Hyperparameters
learning_rate = 3e-4
batch_size = 128
micro_batch_size = 1
max_iters = 50000  # train dataset size
weight_decay = 0.01
lora_r = 8
lora_alpha = 16
lora_dropout = 0.05
lora_query = True
lora_key = False
lora_value = True
lora_projection = False
lora_mlp = False
lora_head = False
warmup_steps = 100
```

#### 5 Memory Savings with QLoRA

> æ—¶é—´è¾¹å˜é•¿, å­˜å‚¨é™ä½ (éœ€è¦é¢å¤–çš„é‡åŒ– å’Œ é€†é‡åŒ–æ­¥éª¤)

Default LoRA (with bfloat-16):

- Training time: 6685.75s
- Memory used: 21.33 GB

QLoRA via â€“-quantize â€œbnb.nf4â€:

- Training time: 10059.53s
- Memory used: 14.18 GB

QLoRA via â€“quantize â€œbnb.fp4â€:

- Training time: 9334.45s
- Memory used: 14.19 GB

ä»ä¸Šè¡¨å¯ä»¥çœ‹å‡ºï¼Œä¸æ™®é€š QLoRA ç›¸æ¯”ï¼ŒQLoRA å¯¹æ¨¡å‹æ€§èƒ½çš„å½±å“è¾ƒå°ã€‚è¯¥æ¨¡å‹åœ¨ç®—æœ¯åŸºå‡†æ–¹é¢æœ‰æ‰€æ”¹è¿›ï¼Œä½†åœ¨ MMLU Global Facts åŸºå‡†æ–¹é¢æœ‰æ‰€ä¸‹é™ã€‚

#### 6 Learning Rate Schedulers and SGD

å¯¹äºå¯è®­ç»ƒå‚æ•°çš„æ•°é‡è¾ƒå°‘çš„æƒ…å†µï¼Œä¾‹å¦‚ LoRA å’Œä½ rï¼ˆç§©ï¼‰å€¼çš„æƒ…å†µï¼Œå°† AdamW ä¸ SGD äº’æ¢æ‰€å¸¦æ¥çš„å†…å­˜å¢ç›Šå¯èƒ½éå¸¸å°ï¼Œè¿™ä¸é¢„è®­ç»ƒå½¢æˆäº†é²œæ˜å¯¹æ¯”ï¼Œåœ¨é¢„è®­ç»ƒä¸­ï¼Œæˆ‘ä»¬è¦è®­ç»ƒæ›´å¤šçš„å‚æ•°ã€‚

> æˆ‘å‘ç°æœ€ä½³çš„ AdamW å­¦ä¹ ç‡ä¸º 3e-4ï¼Œè¡°å‡ç‡ä¸º 0.01ã€‚æœ€ä½³ SGD å­¦ä¹ ç‡ä¸º 0.1ï¼ŒåŠ¨é‡ä¸º 0.9ã€‚åœ¨è¿™ä¸¤ç§æƒ…å†µä¸‹ï¼Œæˆ‘éƒ½ä½¿ç”¨äº†é¢å¤–çš„ 100 æ­¥å­¦ä¹ ç‡é¢„çƒ­ã€‚

#### 7 Iterating Over the Dataset Multiple Times

æœ‰è¶£çš„æ˜¯ï¼Œè¿­ä»£æ¬¡æ•°å¢åŠ å¯¼è‡´æ€§èƒ½å…¨é¢ä¸‹é™ã€‚ç®—æœ¯åŸºå‡†çš„ä¸‹é™æœ€ä¸ºæ˜æ˜¾ã€‚æˆ‘çš„å‡è®¾æ˜¯ï¼ŒAlpaca æ•°æ®é›†ä¸åŒ…å«ä»»ä½•ç›¸å…³çš„ç®—æœ¯ä»»åŠ¡ï¼Œå½“æ¨¡å‹æ›´ä¸“æ³¨äºå…¶ä»–ä»»åŠ¡æ—¶ï¼Œå°±ä¼šä¸»åŠ¨æ”¾å¼ƒå­¦ä¹ åŸºæœ¬ç®—æœ¯ã€‚

#### 8 LoRA Hyperparameter Tuning Part 1: LoRA for All Layers

ç°åœ¨ï¼Œæˆ‘ä»¬å·²ç»æ¢ç´¢äº†æœ‰å…³ LoRA å¾®è°ƒè„šæœ¬çš„åŸºæœ¬è®¾ç½®ï¼Œè®©æˆ‘ä»¬æŠŠæ³¨æ„åŠ›è½¬å‘ LoRA è¶…å‚æ•°æœ¬èº«ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼ŒLoRA åªé’ˆå¯¹å¤šå¤´è‡ªæ³¨æ„åŒºå—ä¸­çš„KeyçŸ©é˜µå’ŒæŸ¥è¯¢çŸ©é˜µå¯ç”¨ã€‚ç°åœ¨ï¼Œæˆ‘ä»¬ä¹Ÿä¸ºå€¼çŸ©é˜µã€æŠ•å½±å±‚å’Œçº¿æ€§å±‚å¯ç”¨äº† LoRAï¼š

#### 9 LoRA Hyperparameter Tuning Part 2: Increasing R

æœ€é‡è¦çš„ LoRA å‚æ•°ä¹‹ä¸€æ˜¯ "r"ï¼Œå®ƒå†³å®šäº† LoRA çŸ©é˜µçš„ç§©æˆ–ç»´åº¦ï¼Œç›´æ¥å½±å“æ¨¡å‹çš„å¤æ‚æ€§å’Œå®¹é‡ã€‚è¾ƒé«˜çš„ "r "æ„å‘³ç€æ›´å¼ºçš„è¡¨ç°åŠ›ï¼Œä½†ä¼šå¯¼è‡´è¿‡æ‹Ÿåˆï¼Œè€Œè¾ƒä½çš„ "r "åˆ™ä¼šä»¥ç‰ºç‰²è¡¨ç°åŠ›ä¸ºä»£ä»·å‡å°‘è¿‡æ‹Ÿåˆã€‚åœ¨æ‰€æœ‰å±‚éƒ½å¯ç”¨ LoRA çš„æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å°† r ä» 8 å¢åŠ åˆ° 16ï¼Œçœ‹çœ‹è¿™å¯¹æ€§èƒ½æœ‰ä»€ä¹ˆå½±å“ï¼š

#### 10 LoRA Hyperparameter Tuning Part 3: Changing Alpha

åœ¨ä¸Šä¸€èŠ‚ä¸­ï¼Œæˆ‘ä»¬å¢åŠ äº†çŸ©é˜µç§© rï¼Œè€Œ LoRA çš„ alpha å‚æ•°ä¿æŒä¸å˜ã€‚

Î± "è¶Šé«˜ï¼Œä½ç§©ç»“æ„æˆ–æ­£åˆ™åŒ–å°±è¶Šå—é‡è§†ï¼Œè€Œ "Î± "è¶Šä½ï¼Œä½ç§©ç»“æ„æˆ–æ­£åˆ™åŒ–çš„å½±å“å°±è¶Šå°ï¼Œä»è€Œä½¿æ¨¡å‹æ›´ä¾èµ–äºåŸå§‹å‚æ•°ã€‚è°ƒæ•´ "Î± "å‚æ•°æœ‰åŠ©äºåœ¨æ‹Ÿåˆæ•°æ®å’Œé€šè¿‡æ­£åˆ™åŒ–æ¨¡å‹é˜²æ­¢è¿‡æ‹Ÿåˆä¹‹é—´å–å¾—å¹³è¡¡ã€‚

æ ¹æ®ç»éªŒï¼Œåœ¨å¾®è°ƒ LLM æ—¶ï¼Œ**é€šå¸¸ä¼šé€‰æ‹©æ¯”Rankå¤§ä¸¤å€çš„ alpha**ï¼ˆæ³¨æ„ï¼Œåœ¨å¤„ç†æ‰©æ•£æ¨¡å‹æ—¶æƒ…å†µæœ‰æ‰€ä¸åŒï¼‰ã€‚è®©æˆ‘ä»¬è¯•ä¸€è¯•ï¼Œçœ‹çœ‹å½“æˆ‘ä»¬æŠŠ alpha å¢å¤§ä¸¤å€æ—¶ä¼šå‘ç”Ÿä»€ä¹ˆï¼š

æ­£å¦‚æˆ‘ä»¬æ‰€çœ‹åˆ°çš„ï¼Œå°† alpha å€¼å¢åŠ åˆ° 32ï¼Œå¯ä»¥å¾—åˆ°è¿„ä»Šä¸ºæ­¢æœ€å¥½çš„æ¨¡å‹ï¼ä¸è¿‡ï¼Œæˆ‘ä»¬ä¹Ÿæ˜¯é€šè¿‡å¢åŠ éœ€è¦è®­ç»ƒçš„å‚æ•°æ•°é‡æ‰è·å¾—äº†è¿™ä¸€æ”¹è¿›ï¼š

r=8:

- Number of trainable parameters: 20,277,248
- Number of non trainable parameters: 6,738,415,616
- Memory used: 16.42 GB

r=16:

- Number of trainable parameters: 40,554,496
- Number of non trainable parameters: 6,738,415,616
- Memory used: 16.47 GB

#### 11 LoRA Hyperparameter Tuning Part 3: Very Large R

å¯¹äº r=256 å’Œ a=512 çš„ QLoRA æ¨¡å‹ï¼Œæˆ‘ä»¬çš„æ¨¡å‹æ˜¾ç„¶æ¯”åŸºç¡€æ¨¡å‹æœ‰äº†æ˜¾è‘—çš„æ”¹è¿›ã€‚ä¸åŸºç¡€æ¨¡å‹ç›¸æ¯”ï¼Œå¾®è°ƒæ¨¡å‹å”¯ä¸€è¡¨ç°ä¸ä½³çš„åœ°æ–¹æ˜¯å››ä½æ•°è¿ç®—ã€‚ä¸è¿‡ï¼Œè€ƒè™‘åˆ° Alpaca æ•°æ®é›†å¯èƒ½ä¸åŒ…å«æ­¤ç±»è®­ç»ƒç¤ºä¾‹ï¼Œè¿™ä¹Ÿæ˜¯å¯ä»¥ç†è§£çš„ã€‚

#### 12 Leaderboard Submission

### â‘¢ LLM å¾®è°ƒ Best practice

> â…  [Fine-Tune Llama 2 Model in Colab](https://mlabonne.github.io/blog/posts/Fine_Tune_Your_Own_Llama_2_Model_in_a_Colab_Notebook.html) -> QLoRA
>
> â…¡ [Fine-Tune Llama 2 Model in Axolotl](https://mlabonne.github.io/blog/posts/A_Beginners_Guide_to_LLM_Finetuning.html) -> WandB **Base** RunPod(GPUå¹³å°)
>
> â…¢ [Fine-tune Mistral-7b Model with DPO](https://mlabonne.github.io/blog/posts/Fine_tune_Mistral_7b_with_DPO.html) -> å¯ä»¥ç›´æ¥æäº¤åˆ°HFä¸Šé¢è¿›è¡Œè¯„ä¼°
>
> â…£ [Fine-tune Llama 3 with ORPO](https://mlabonne.github.io/blog/posts/2024-04-19_Fine_tune_Llama_3_with_ORPO.html) -> TRL åº“
>
> â…¤ [Fine-tune Llama 2 with DPO (huggingface.co)](https://huggingface.co/blog/dpo-trl) 

Base æ¨¡å‹ åŸºäºå¤§è§„æ¨¡è¯­æ–™åº“è®­ç»ƒ , åŸºäºBaseæ¨¡å‹SFTæ— éœ€éµå¾ªæ¨¡æ¿, Chat æ¨¡å‹å·²ç»ç»è¿‡ä¸€äº›æŒ‡ä»¤å¾®è°ƒè®­ç»ƒ, æ‰€ä»¥åŸºäºChatæ¨¡å‹å¿…é¡»æ‰¾åˆ°èµ·åˆçš„å¯¹è¯æ¨¡æ¿æ˜¯ä»€ä¹ˆ. 

#### 1 Axolotl

Axolotl çš„ä¸»è¦å¸å¼•åŠ›åœ¨äºå®ƒæä¾›äº†ä¸€ç«™å¼è§£å†³æ–¹æ¡ˆï¼ŒåŒ…æ‹¬ä¼—å¤šåŠŸèƒ½ã€æ¨¡å‹æ¶æ„å’Œä¸€ä¸ªæ´»è·ƒçš„ç¤¾åŒºã€‚ä»¥ä¸‹æ˜¯æˆ‘æœ€å–œæ¬¢å®ƒçš„åœ°æ–¹ï¼š

* é…ç½®ï¼š

  ç”¨äºè®­ç»ƒ LLM çš„æ‰€æœ‰å‚æ•°éƒ½æ•´é½åœ°å­˜å‚¨åœ¨ yaml é…ç½®æ–‡ä»¶ä¸­ã€‚è¿™ä¸ºå…±äº«å’Œå¤åˆ¶æ¨¡å‹æä¾›äº†ä¾¿åˆ©ã€‚ä½ å¯ä»¥åœ¨è¿™é‡Œçœ‹åˆ° Llama 2 çš„ç¤ºä¾‹ã€‚

* æ•°æ®é›†çµæ´»æ€§ï¼š

  Axolotl å…è®¸æŒ‡å®šå¤šç§æç¤ºæ ¼å¼çš„æ•°æ®é›†ï¼Œå¦‚ alpacaï¼ˆ{"æŒ‡ä»¤"ï¼š"..."ï¼Œ"è¾“å…¥"ï¼š"..."ï¼Œ"è¾“å‡º"ï¼š"..."}ï¼‰ã€sharegpt:chatï¼ˆ{"å¯¹è¯"ï¼š[{"æ¥è‡ª"ï¼š"..."ï¼Œ"å€¼"ï¼š"..."}]}ï¼‰å’Œ raw completionï¼ˆ{"æ–‡æœ¬"ï¼š"..."}ï¼‰ã€‚æ•°æ®é›†çš„ç»„åˆæ˜¯æ— ç¼çš„ï¼Œç»Ÿä¸€æç¤ºæ ¼å¼çš„éº»çƒ¦ä¹Ÿä¸å¤å­˜åœ¨ã€‚

* åŠŸèƒ½ç‰¹ç‚¹ : 

  Axolotl åŒ…å«å¤šç§ SOTA æŠ€æœ¯ï¼Œå¦‚ FSDPã€deepspeedã€LoRAã€QLoRAã€ReLoRAã€æ ·æœ¬æ‰“åŒ…ã€GPTQã€FlashAttentionã€xformers å’Œç»³ç´¢ç¼©æ”¾ã€‚

* å®ç”¨å·¥å…·: é›†æˆäº†å¤§é‡ç”¨æˆ·å‹å¥½å‹å®ç”¨ç¨‹åºï¼ŒåŒ…æ‹¬æ·»åŠ æˆ–æ›´æ”¹ç‰¹æ®Šä»¤ç‰Œæˆ–è‡ªå®šä¹‰ wandb é…ç½®ã€‚

#### 2 PPO vs DPO 

PPO çš„æ ¸å¿ƒç†å¿µæ˜¯å¯¹ç­–ç•¥è¿›è¡Œè¾ƒå°çš„å¢é‡æ›´æ–°ï¼Œå› ä¸ºè¾ƒå¤§çš„æ›´æ–°ä¼šå¯¼è‡´ä¸ç¨³å®šæˆ–æ¬¡ä¼˜è§£ã€‚é—æ†¾çš„æ˜¯ï¼Œæ ¹æ®ç»éªŒï¼Œè¿™ç§æŠ€æœ¯ä»ç„¶ä¸ç¨³å®šï¼ˆæŸå¤±å‘æ•£ï¼‰ï¼Œéš¾ä»¥å¤åˆ¶ï¼ˆè¶…å‚æ•°ä¼—å¤šï¼Œå¯¹éšæœºç§å­æ•æ„Ÿï¼‰ï¼Œè€Œä¸”è®¡ç®—æˆæœ¬é«˜æ˜‚ã€‚

è¿™å°±æ˜¯ç›´æ¥ä¼˜é€‰ä¼˜åŒ–ï¼ˆDPOï¼‰å‘æŒ¥ä½œç”¨çš„åœ°æ–¹ã€‚DPO å°†ä»»åŠ¡è§†ä¸ºåˆ†ç±»é—®é¢˜ï¼Œä»è€Œç®€åŒ–äº†æ§åˆ¶ã€‚å…·ä½“æ¥è¯´ï¼Œå®ƒä½¿ç”¨ä¸¤ä¸ªæ¨¡å‹ï¼šè®­ç»ƒæ¨¡å‹ï¼ˆæˆ–ç­–ç•¥æ¨¡å‹ï¼‰å’Œä¸€ä¸ªç§°ä¸ºå‚è€ƒæ¨¡å‹çš„å‰¯æœ¬ã€‚åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬çš„ç›®æ ‡æ˜¯ç¡®ä¿**è®­ç»ƒæ¨¡å‹è¾“å‡ºçš„é¦–é€‰ç­”æ¡ˆæ¦‚ç‡é«˜äºå‚è€ƒæ¨¡å‹**ã€‚åä¹‹ï¼Œæˆ‘ä»¬ä¹Ÿå¸Œæœ›å®ƒå¯¹æ‹’ç»ç­”æ¡ˆè¾“å‡ºè¾ƒä½çš„æ¦‚ç‡ã€‚è¿™æ„å‘³ç€æˆ‘ä»¬è¦å¯¹åç­”æ¡ˆæƒ©ç½š LLMï¼Œå¯¹å¥½ç­”æ¡ˆå¥–åŠ± LLMã€‚

é€šè¿‡å°† LLM æœ¬èº«ä½œä¸ºå¥–åŠ±æ¨¡å‹ï¼Œå¹¶é‡‡ç”¨äºŒå…ƒäº¤å‰ç†µç›®æ ‡ï¼ŒDPO å¯ä»¥æœ‰æ•ˆåœ°ä½¿æ¨¡å‹è¾“å‡ºä¸äººç±»åå¥½ä¿æŒä¸€è‡´ï¼Œè€Œæ— éœ€è¿›è¡Œå¤§é‡é‡‡æ ·ã€å¥–åŠ±æ¨¡å‹æ‹Ÿåˆæˆ–å¤æ‚çš„è¶…å‚æ•°è°ƒæ•´ã€‚è¿™å°†å¸¦æ¥ä¸€ä¸ªæ›´ç¨³å®šã€æ›´é«˜æ•ˆã€è®¡ç®—è¦æ±‚æ›´ä½çš„è¿‡ç¨‹ã€‚

#### 3 ORPO

ORPO æ˜¯ä¸€ç§æ–°çš„ä»¤äººå…´å¥‹çš„å¾®è°ƒæŠ€æœ¯ï¼Œå®ƒå°†ä¼ ç»Ÿçš„ç›‘ç£å¾®è°ƒå’Œåå¥½æ ¡å‡†é˜¶æ®µåˆå¹¶ä¸ºä¸€ä¸ªè¿‡ç¨‹ã€‚è¿™å‡å°‘äº†è®­ç»ƒæ‰€éœ€çš„è®¡ç®—èµ„æºå’Œæ—¶é—´ã€‚æ­¤å¤–ï¼Œç»éªŒç»“æœè¡¨æ˜ï¼Œåœ¨å„ç§æ¨¡å‹å¤§å°å’ŒåŸºå‡†ä¸Šï¼ŒORPO éƒ½ä¼˜äºå…¶ä»–é…å‡†æ–¹æ³•ã€‚

æŒ‡ä»¤è°ƒæ•´å’Œåå¥½å¯¹é½æ˜¯ä½¿å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰é€‚åº”ç‰¹å®šä»»åŠ¡çš„åŸºæœ¬æŠ€æœ¯ã€‚ä¼ ç»Ÿä¸Šï¼Œè¿™æ¶‰åŠä¸€ä¸ªå¤šé˜¶æ®µè¿‡ç¨‹ï¼š1/ å¯¹æŒ‡ä»¤è¿›è¡Œç›‘ç£å¾®è°ƒ (SFT)ï¼Œä½¿æ¨¡å‹é€‚åº”ç›®æ ‡é¢†åŸŸï¼›2/ é‡‡ç”¨åå¥½è°ƒæ•´æ–¹æ³•ï¼Œå¦‚äººå·¥åé¦ˆå¼ºåŒ–å­¦ä¹  (RLHF) æˆ–ç›´æ¥åå¥½ä¼˜åŒ– (DPO)ï¼Œä»¥æé«˜ç”Ÿæˆé¦–é€‰å“åº”è€Œéæ‹’ç»å“åº”çš„å¯èƒ½æ€§ã€‚

ä¸è¿‡ï¼Œç ”ç©¶äººå‘˜ä¹Ÿå‘ç°äº†è¿™ç§æ–¹æ³•çš„å±€é™æ€§ã€‚è™½ç„¶ SFT èƒ½æœ‰æ•ˆåœ°ä½¿æ¨¡å‹é€‚åº”æ‰€éœ€çš„é¢†åŸŸï¼Œä½†å´æ— æ„ä¸­å¢åŠ äº†åœ¨ç”Ÿæˆé¦–é€‰ç­”æ¡ˆçš„åŒæ—¶ç”Ÿæˆä¸æƒ³è¦çš„ç­”æ¡ˆçš„æ¦‚ç‡ã€‚è¿™å°±æ˜¯ä¸ºä»€ä¹ˆæœ‰å¿…è¦è¿›è¡Œåå¥½è°ƒæ•´é˜¶æ®µï¼Œä»¥æ‹‰å¤§é¦–é€‰è¾“å‡ºå’Œæ‹’ç»è¾“å‡ºçš„å¯èƒ½æ€§ä¹‹é—´çš„å·®è·ã€‚

ç”± Hong å’Œ Leeï¼ˆ2024 å¹´ï¼‰æå‡ºçš„ ORPO å°†æŒ‡ä»¤è°ƒæ•´å’Œåå¥½è°ƒæ•´ç»“åˆåˆ°ä¸€ä¸ªå•ä¸€çš„ã€æ•´ä½“çš„è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œä¸ºè¿™ä¸€é—®é¢˜æä¾›äº†ä¸€ä¸ªä¼˜é›…çš„è§£å†³æ–¹æ¡ˆã€‚ORPO ä¿®æ”¹äº†æ ‡å‡†è¯­è¨€å»ºæ¨¡ç›®æ ‡ï¼Œå°†è´Ÿå¯¹æ•°ä¼¼ç„¶æŸå¤±ä¸å‡ ç‡æ¯”ï¼ˆORï¼‰é¡¹ç›¸ç»“åˆã€‚è¿™ç§èµ”ç‡æŸå¤±ä¼šå¯¹è¢«æ‹’ç»çš„ååº”è¿›è¡Œå¼±æƒ©ç½šï¼ŒåŒæ—¶å¯¹åå¥½çš„ååº”è¿›è¡Œå¼ºå¥–åŠ±ï¼Œä»è€Œä½¿æ¨¡å‹èƒ½å¤ŸåŒæ—¶å­¦ä¹ ç›®æ ‡ä»»åŠ¡å¹¶ä¸äººç±»åå¥½ä¿æŒä¸€è‡´ã€‚

ORPO å·²åœ¨ TRLã€Axolotl å’Œ LLaMA-Factory ç­‰ä¸»è¦å¾®è°ƒåº“ä¸­å®ç°ã€‚åœ¨ä¸‹ä¸€èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†äº†è§£å¦‚ä½•ä½¿ç”¨ TRL

## Part â…¤ Reinforcement Learning from Human Feedback

### â‘  RLHF Introduction

> [ChatGPT èƒŒåçš„â€œåŠŸè‡£â€â€”â€”RLHF æŠ€æœ¯è¯¦è§£ (huggingface.co)](https://huggingface.co/blog/zh/rlhf)

å…³äºRMæ¨¡å‹é€‰æ‹©: ä¸€ç§ç›´è§‰æ˜¯ï¼Œåå¥½æ¨¡å‹å’Œç”Ÿæˆæ¨¡å‹éœ€è¦å…·æœ‰ç±»ä¼¼çš„èƒ½åŠ›æ¥ç†è§£æä¾›ç»™å®ƒä»¬çš„æ–‡æœ¬ã€‚

è®©æˆ‘ä»¬é¦–å…ˆå°†å¾®è°ƒä»»åŠ¡è¡¨è¿°ä¸º RL é—®é¢˜ã€‚é¦–å…ˆï¼Œè¯¥ **ç­–ç•¥** (policy) æ˜¯ä¸€ä¸ªæ¥å—æç¤ºå¹¶è¿”å›ä¸€ç³»åˆ—æ–‡æœ¬ (æˆ–æ–‡æœ¬çš„æ¦‚ç‡åˆ†å¸ƒ) çš„ LMã€‚è¿™ä¸ªç­–ç•¥çš„ **è¡ŒåŠ¨ç©ºé—´** (action space) æ˜¯ LM çš„è¯è¡¨å¯¹åº”çš„æ‰€æœ‰è¯å…ƒ (ä¸€èˆ¬åœ¨ 50k æ•°é‡çº§) ï¼Œ**è§‚å¯Ÿç©ºé—´** (observation space) æ˜¯å¯èƒ½çš„è¾“å…¥è¯å…ƒåºåˆ—ï¼Œä¹Ÿæ¯”è¾ƒå¤§ (è¯æ±‡é‡ ^ è¾“å…¥æ ‡è®°çš„æ•°é‡) ã€‚**å¥–åŠ±å‡½æ•°** æ˜¯åå¥½æ¨¡å‹å’Œç­–ç•¥è½¬å˜çº¦æŸ (Policy shift constraint) çš„ç»“åˆã€‚

PPO ç®—æ³•ç¡®å®šçš„å¥–åŠ±å‡½æ•°å…·ä½“è®¡ç®—å¦‚ä¸‹ï¼šå°†æç¤º *x* è¾“å…¥åˆå§‹ LM å’Œå½“å‰å¾®è°ƒçš„ LMï¼Œåˆ†åˆ«å¾—åˆ°äº†è¾“å‡ºæ–‡æœ¬ *y1*, *y2*ï¼Œå°†æ¥è‡ªå½“å‰ç­–ç•¥çš„æ–‡æœ¬ä¼ é€’ç»™ RM å¾—åˆ°ä¸€ä¸ªæ ‡é‡çš„å¥–åŠ± ğ‘Ÿğœƒ*r**Î¸*ã€‚å°†ä¸¤ä¸ªæ¨¡å‹çš„ç”Ÿæˆæ–‡æœ¬è¿›è¡Œæ¯”è¾ƒè®¡ç®—å·®å¼‚çš„æƒ©ç½šé¡¹ï¼Œåœ¨æ¥è‡ª OpenAIã€Anthropic å’Œ DeepMind çš„å¤šç¯‡è®ºæ–‡ä¸­è®¾è®¡ä¸ºè¾“å‡ºè¯åˆ†å¸ƒåºåˆ—ä¹‹é—´çš„ Kullbackâ€“Leibler [(KL) divergence](https://en.wikipedia.org/wiki/Kullbackâ€“Leibler_divergence) æ•£åº¦çš„ç¼©æ”¾ï¼Œå³ $ğ‘Ÿ=ğ‘Ÿ_ğœƒâˆ’ğœ†ğ‘Ÿ_{KL}$â€‹ã€‚è¿™ä¸€é¡¹è¢«ç”¨äºæƒ©ç½š RL ç­–ç•¥åœ¨æ¯ä¸ªè®­ç»ƒæ‰¹æ¬¡ä¸­ç”Ÿæˆå¤§å¹…åç¦»åˆå§‹æ¨¡å‹ï¼Œä»¥ç¡®ä¿æ¨¡å‹è¾“å‡ºåˆç†è¿è´¯çš„æ–‡æœ¬ã€‚å¦‚æœå»æ‰è¿™ä¸€æƒ©ç½šé¡¹å¯èƒ½å¯¼è‡´æ¨¡å‹åœ¨ä¼˜åŒ–ä¸­ç”Ÿæˆä¹±ç æ–‡æœ¬æ¥æ„šå¼„å¥–åŠ±æ¨¡å‹æä¾›é«˜å¥–åŠ±å€¼ã€‚æ­¤å¤–ï¼ŒOpenAI åœ¨ InstructGPT ä¸Šå®éªŒäº†åœ¨ PPO æ·»åŠ æ–°çš„é¢„è®­ç»ƒæ¢¯åº¦ï¼Œå¯ä»¥é¢„è§åˆ°å¥–åŠ±å‡½æ•°çš„å…¬å¼ä¼šéšç€ RLHF ç ”ç©¶çš„è¿›å±•è€Œç»§ç»­è¿›åŒ–ã€‚

æœ€åæ ¹æ® PPO ç®—æ³•ï¼Œæˆ‘ä»¬æŒ‰å½“å‰æ‰¹æ¬¡æ•°æ®çš„å¥–åŠ±æŒ‡æ ‡è¿›è¡Œä¼˜åŒ– (æ¥è‡ª PPO ç®—æ³• on-policy çš„ç‰¹æ€§) ã€‚PPO ç®—æ³•æ˜¯ä¸€ç§ä¿¡èµ–åŸŸä¼˜åŒ– (Trust Region Optimizationï¼ŒTRO) ç®—æ³•ï¼Œå®ƒä½¿ç”¨æ¢¯åº¦çº¦æŸç¡®ä¿æ›´æ–°æ­¥éª¤ä¸ä¼šç ´åå­¦ä¹ è¿‡ç¨‹çš„ç¨³å®šæ€§

<img src="assets/image-20240428135712396.png" alt="image-20240428135712396" style="zoom:67%;" />

å°½ç®¡ RLHF å–å¾—äº†ä¸€å®šçš„æˆæœå’Œå…³æ³¨ï¼Œä½†ä¾ç„¶å­˜åœ¨å±€é™ã€‚è¿™äº›æ¨¡å‹ä¾ç„¶ä¼šæ¯«æ— ä¸ç¡®å®šæ€§åœ°è¾“å‡ºæœ‰å®³æˆ–è€…ä¸çœŸå®çš„æ–‡æœ¬ã€‚

æ”¶é›†äººç±»åå¥½æ•°æ®çš„è´¨é‡å’Œæ•°é‡å†³å®šäº† RLHF ç³»ç»Ÿæ€§èƒ½çš„ä¸Šé™ã€‚RLHF ç³»ç»Ÿéœ€è¦ä¸¤ç§äººç±»åå¥½æ•°æ®ï¼šäººå·¥ç”Ÿæˆçš„æ–‡æœ¬å’Œå¯¹æ¨¡å‹è¾“å‡ºçš„åå¥½æ ‡ç­¾ã€‚ç”Ÿæˆé«˜è´¨é‡å›ç­”éœ€è¦é›‡ä½£å…¼èŒäººå‘˜ (è€Œä¸èƒ½ä¾èµ–äº§å“ç”¨æˆ·å’Œä¼—åŒ…) ã€‚å¦ä¸€æ–¹é¢ï¼Œè®­ç»ƒ RM éœ€è¦çš„å¥–åŠ±æ ‡ç­¾è§„æ¨¡å¤§æ¦‚æ˜¯ 50k å·¦å³ï¼Œæ‰€ä»¥å¹¶ä¸é‚£ä¹ˆæ˜‚è´µ (å½“ç„¶è¿œè¶…äº†å­¦æœ¯å®éªŒå®¤çš„é¢„ç®—) ã€‚ç›®å‰ç›¸å…³çš„æ•°æ®é›†åªæœ‰ä¸€ä¸ªåŸºäºé€šç”¨ LM çš„ RLHF æ•°æ®é›† (æ¥è‡ª [Anthropic](https://huggingface.co/datasets/Anthropic/hh-rlhf) å’Œå‡ ä¸ªè¾ƒå°çš„å­ä»»åŠ¡æ•°æ®é›† (å¦‚æ¥è‡ª [OpenAI](https://github.com/openai/summarize-from-feedback) çš„æ‘˜è¦æ•°æ®é›†) ã€‚å¦ä¸€ä¸ªæŒ‘æˆ˜æ¥è‡ªæ ‡æ³¨è€…çš„åè§ã€‚å‡ ä¸ªäººç±»æ ‡æ³¨è€…å¯èƒ½æœ‰ä¸åŒæ„è§ï¼Œå¯¼è‡´äº†è®­ç»ƒæ•°æ®å­˜åœ¨ä¸€äº›æ½œåœ¨å·®å¼‚ã€‚

### â‘¡ RLHF å’Œ å…¶æ›¿ä»£ç­–ç•¥

> [LLM Training: RLHF and Its Alternatives (sebastianraschka.com)](https://magazine.sebastianraschka.com/p/llm-training-rlhf-and-its-alternatives?utm_source=profile&utm_medium=reader2)
>
> 1. äººå·¥åé¦ˆå¼ºåŒ–å­¦ä¹  (RLHF)
> 2. Llama 2 ä¸­çš„ RLHF
> 3. RLHF æ›¿ä»£æ–¹æ¡ˆ

#### 1 Canonical LLM Pipline : Pretraining + Supervised finetuning + Alignment

> STEP 1 Pretraining 
>
> <img src="assets/image-20240428142336795.png" alt="image-20240428142336795" style="zoom:50%;" />
>
> STEP 2 Supervised Finetuning
>
> ![image-20240428142435594](assets/image-20240428142435594.png)
>
> STEP 3 Alignment
>
> ![image-20240428142911079](assets/image-20240428142911079.png)

#### 2 RLHF

> Step 1 : 
>
> ![image-20240428144148017](assets/image-20240428144148017.png)
>
> Step 2 :
>
> ![image-20240428144219955](assets/image-20240428144219955.png)
>
> Step 3 :
>
> ![image-20240428145241633](assets/image-20240428145241633.png)

#### 3 RLHF Llama 2

![image-20240428145814130](assets/image-20240428145814130.png)

##### **Margin Loss**

Llama 2 çš„æ•°æ®é›†ä¹Ÿæ˜¯åŸºäºäºŒå…ƒæ¯”è¾ƒçš„å›ç­”ï¼Œå¦‚ A < Bã€‚ç„¶è€Œï¼Œä¼¼ä¹æ¯ä½äººç±»è´´æ ‡è€…åœ¨æ¯è½®è´´æ ‡ä¸­åªçœ‹åˆ° 2 ä¸ªå›ç­”ï¼ˆè€Œä¸æ˜¯ 4-9 ä¸ªå›ç­”ï¼‰ã€‚

æ­¤å¤–ï¼Œæ–°é¢–ä¹‹å¤„åœ¨äºï¼Œåœ¨æ¯ä¸ªäºŒè¿›åˆ¶æ’åºçš„åŒæ—¶ï¼Œè¿˜æ”¶é›†äº†ä¸€ä¸ª "ä½™é‡ "æ ‡ç­¾ï¼ˆèŒƒå›´ä» "æ˜æ˜¾æ›´å¥½ "åˆ° "å¥½å¾—å¯ä»¥å¿½ç•¥ä¸è®¡"ï¼‰ï¼Œå®ƒå¯ä»¥é€šè¿‡ä¸€ä¸ªé¢å¤–çš„ä½™é‡å‚æ•°ç”¨äºäºŒè¿›åˆ¶æ’åºæŸå¤±ï¼Œä»¥è®¡ç®—ä¸¤ä¸ªå›å¤ä¹‹é—´çš„å·®è·ã€‚

While InstructGPT used the following cross entropy-based ranking loss to train the reward model:
$$
ğ¿_{ranking} =âˆ’logâ¡(ğœ(ğ‘Ÿ_ğœƒ(ğ‘¥,ğ‘¦_ğ‘)âˆ’ğ‘Ÿ_ğœƒ(ğ‘¥,ğ‘¦_ğ‘Ÿ)))
$$
Llama 2 added the the margin â€œm(r)â€ as a discrete function of the preference rating as follows:
$$
ğ¿_{ranking} =âˆ’logâ¡(ğœ(ğ‘Ÿ_ğœƒ(ğ‘¥,ğ‘¦_ğ‘)âˆ’ğ‘Ÿ_ğœƒ(ğ‘¥,ğ‘¦_ğ‘Ÿ)âˆ’ğ‘š(ğ‘Ÿ)))
$$
where

- *r_Î¸(x,y)* is the scalar score output for prompt *x* and the generated response *y;*
- *Î¸* are the model weights;
- Ïƒ is the logistic sigmoid function that converts the layer outputs to scores ranging from 0 to 1;
- *y_c* is the preferred response chosen by the human annotators;
- *y_r* is the rejected response chosen by the human annotators.

##### **Two reward models**

![image-20240428150556436](assets/image-20240428150556436.png)

##### **Rejection sampling**

![image-20240428150825903](assets/image-20240428150825903.png)

#### 4 RLHF Alternatives

> åœ¨äººå·¥æ™ºèƒ½ç ”ç©¶çš„ç½‘ç»œå®‰å…¨æ–¹é¢ï¼Œ"çº¢é˜Ÿ "ä¸€è¯ç°åœ¨è¢«ç”¨æ¥æè¿°è¿™æ ·ä¸€ä¸ªè¿‡ç¨‹ï¼šå¤–éƒ¨æˆ–å†…éƒ¨ä¸“å®¶æ¨¡ä»¿æ½œåœ¨çš„å¯¹æ‰‹ï¼Œé€šè¿‡æ¨¡ä»¿çœŸå®ä¸–ç•Œæ”»å‡»è€…çš„æˆ˜æœ¯ã€æŠ€æœ¯å’Œç¨‹åºï¼Œæ¥æŒ‘æˆ˜ã€æµ‹è¯•å¹¶æœ€ç»ˆæ”¹è¿›ç‰¹å®šçš„ç›¸å…³ç³»ç»Ÿã€‚

ç›´æ¥åå¥½ä¼˜åŒ–ï¼ˆDPOï¼‰æ˜¯ä½¿ç”¨ PPO çš„ RLHF çš„æ›¿ä»£æ–¹æ³•ï¼Œç ”ç©¶äººå‘˜è¡¨æ˜ï¼ŒRLHF ä¸­ç”¨äºæ‹Ÿåˆå¥–åŠ±æ¨¡å‹çš„äº¤å‰ç†µæŸå¤±å¯ä»¥ç›´æ¥ç”¨äºå¾®è°ƒ LLMã€‚æ ¹æ®ä»–ä»¬çš„åŸºå‡†æµ‹è¯•ï¼Œä½¿ç”¨ DPO æ›´ä¸ºé«˜æ•ˆï¼Œåœ¨å“åº”è´¨é‡æ–¹é¢ä¹Ÿå¾€å¾€ä¼˜äº RLHF/PPOã€‚

## Part â…¥ Evaluation

### â‘  å›°æƒ‘åº¦

> [Perplexity of fixed-length models](https://huggingface.co/docs/transformers/perplexity) by Hugging Face: Overview of perplexity with code to implement it with the transformers library.

$$
\mathrm{P P L} ( X )=\operatorname{e x p} \left\{-\frac{1} {t} \sum_{i}^{t} \operatorname{l o g} p_{\theta} ( x_{i} | x_{< i} ) \right\}
$$

When we run the above with `stride = 1024`, i.e. no overlap, the resulting PPL is `19.44`, which is about the same as the `19.93` reported in the GPT-2 paper. By using `stride = 512` and thereby employing our striding window strategy, this jumps down to `16.45`. This is not only a more favorable score, but is calculated in a way that is closer to the true autoregressive decomposition of a sequence likelihood.

Q - ä¸ºä»€ä¹ˆæ˜¯ä¸€ä¸ªæœ‰ç”¨çš„å·¥å…·å‘¢? æ­£å¦‚æˆ‘æ‰€è¯´, æ¨¡å‹è¿˜æ˜¯ä¼šå¯èƒ½å¯¹ä¸€äº›ä¸€çœ¼é”™è¯¯çš„å›ç­”å¾ˆç¡®ä¿¡

A - å›°æƒ‘åº¦æä¾›äº†ä¸€ä¸ªé‡åŒ–æ ‡å‡†ï¼Œå¯ä»¥è¡¡é‡æ¨¡å‹å¯¹å…¶è‡ªå·±ç”Ÿæˆçš„é¢„æµ‹æœ‰å¤šä¹ˆâ€œè‡ªä¿¡â€ã€‚è¿™ç§è‡ªä¿¡åº¦æ˜¯è¯„ä»·æ¨¡å‹å†…éƒ¨ä¸€è‡´æ€§çš„ä¸€ä¸ªé‡è¦æŒ‡æ ‡ã€‚å¦‚æœä¸€ä¸ªæ¨¡å‹åœ¨å¤§é‡çš„æ•°æ®ä¸Šè¡¨ç°å‡ºä½å›°æƒ‘åº¦ï¼Œè¿™è‡³å°‘è¯´æ˜å®ƒåœ¨ç»Ÿè®¡ä¸Šå­¦åˆ°äº†æŸç§æ¨¡å¼ã€‚

### â‘¡ BLEU

> **[BLEU at your own risk](https://towardsdatascience.com/evaluating-text-output-in-nlp-bleu-at-your-own-risk-e8609665a213) by Rachael Tatman: Overview of the BLEU score and its many issues with examples.**

è¿™ç§åº¦é‡æ˜¯é€šè¿‡è§‚å¯Ÿè¾“å‡ºä¸å‚è€ƒè¯‘æ–‡ä¹‹é—´çš„ n-grams é‡åˆåº¦ï¼Œå¹¶å¯¹è¾ƒçŸ­çš„è¾“å‡ºè¿›è¡Œæƒ©ç½šæ¥å®ç°çš„ï¼Œè¢«ç§°ä¸º BLEUï¼ˆ"Bilingual evaluation understudy "çš„ç¼©å†™ï¼Œäººä»¬åœ¨è§£é‡Šè¯¥ç¼©å†™æ—¶åªä¼šè¿™æ ·è¯´ï¼‰ï¼Œç”± IBM çš„ Kishore Papineniã€Salim Roukosã€Todd Ward å’Œ Wei-Jing Zhu äº 2002 å¹´å¼€å‘ã€‚å®ƒæ˜¯ NLP ä¸­ä¸€ä¸ªéå¸¸æµè¡Œçš„æŒ‡æ ‡ï¼Œå°¤å…¶é€‚ç”¨äºç³»ç»Ÿè¾“å‡ºä¸ºæ–‡æœ¬å­—ç¬¦ä¸²è€Œéåˆ†ç±»çš„ä»»åŠ¡ã€‚è¿™åŒ…æ‹¬æœºå™¨ç¿»è¯‘ï¼Œä»¥åŠè¶Šæ¥è¶Šå¤šçš„è‡ªç„¶è¯­è¨€ç”Ÿæˆã€‚è¿™æ˜¯æˆ‘åœ¨æœ¬ç¯‡æ–‡ç« å¼€å¤´æå‡ºçš„ä¸€ä¸ªéš¾é¢˜çš„è§£å†³æ–¹æ¡ˆï¼šå¼€å‘ä¸€ç§æ–¹æ³•ï¼Œä¸ºç¿»è¯‘åˆ†é…ä¸€ä¸ªå•ä¸€çš„æ•°å­—åˆ†æ•°ï¼Œå‘Šè¯‰æˆ‘ä»¬ç¿»è¯‘æœ‰å¤š "å¥½"ã€‚

ä½†å®ƒä¹Ÿå­˜åœ¨å¾ˆå¤§ç¼ºé™·ã€‚

* ä¸è€ƒè™‘æ„ä¹‰ : åªå¥–åŠ±å“ªäº›åœ¨å‚ç…§ç³»ç»Ÿä¸­å®Œå…¨åŒ¹é…çš„ n-gram

  è¿™æ„å‘³ç€åŠŸèƒ½è¯ï¼ˆå¦‚ "an "æˆ– "on"ï¼‰çš„å·®å¼‚ä¸æ›´é‡è¦çš„å†…å®¹è¯çš„å·®å¼‚ä¸€æ ·ä¼šå—åˆ°ä¸¥é‡æƒ©ç½šã€‚è¿™ä¹Ÿæ„å‘³ç€ï¼Œå¦‚æœè¯‘æ–‡ä¸­æœ‰ä¸€ä¸ªå®Œå…¨æœ‰æ•ˆçš„åŒä¹‰è¯ï¼Œä½†æ°å¥½æ²¡æœ‰å‡ºç°åœ¨å‚è€ƒè¯‘æ–‡ä¸­ï¼Œä¹Ÿä¼šå—åˆ°æƒ©ç½šã€‚

  åŸºäº BLEU çš„ä¸€ç§åº¦é‡æ ‡å‡† NIST é€šè¿‡å¯¹é”™è¯¯åŒ¹é…çš„ n-gram è¿›è¡ŒåŠ æƒå¤„ç½šæ¥è§£å†³è¿™ä¸€é—®é¢˜ã€‚å› æ­¤ï¼Œè¾ƒå¸¸è§çš„ n-gramï¼ˆå¦‚ "of the"ï¼‰ä¸åŒ¹é…ä¼šå—åˆ°è¾ƒä½çš„æƒ©ç½šï¼Œè€Œè¾ƒç½•è§çš„ n-gramï¼ˆå¦‚ "buffalo æ°´ç‰›"ï¼‰ä¸åŒ¹é…åˆ™ä¼šå—åˆ°è¾ƒé«˜çš„æƒ©ç½šã€‚ä¸è¿‡ï¼Œè™½ç„¶è¿™è§£å†³äº†ç»™äºˆåŠŸèƒ½è¯è¿‡é«˜æƒé‡çš„é—®é¢˜ï¼Œä½†å®é™…ä¸Šå´ä½¿åŒä¹‰è¯ï¼ˆå¦‚ "walked "çš„ "ambled"ï¼‰çš„æƒ©ç½šé—®é¢˜å˜å¾—æ›´åŠ ä¸¥é‡ï¼Œå› ä¸ºè¿™äº›åŒä¹‰è¯åªå‡ºç°åœ¨æ›´ç½•è§çš„ r-gram ä¸­ï¼Œå› æ­¤ä¼šå—åˆ°æ›´é«˜çš„æƒ©ç½šã€‚

* ä¸ç›´æ¥è€ƒè™‘å¥å­ç»“æ„

  ä¸è€ƒè™‘å¥æ³•ç»“æ„çš„ç»“æœæ„å‘³ç€ï¼Œè¡¨é¢è¯åºå®Œå…¨æ··ä¹±çš„è¾“å‡ºç»“æœä¸è¯­åºæ›´åŠ è¿è´¯çš„è¾“å‡ºç»“æœå¯ä»¥è·å¾—ç›¸åŒçš„åˆ†æ•°ã€‚

* ä¸èƒ½å¾ˆå¥½åœ°å¤„ç†å½¢æ€ä¸°å¯Œçš„è¯­è¨€

* ä¸èƒ½å¾ˆå¥½åœ°æ˜ å°„äººç±»çš„åˆ¤æ–­

æ”¹è¿›æ–¹æ³•: 

1. å¦‚ä¸Šæ‰€è¿°ï¼ŒNIST ä¼šæ ¹æ® n-gram çš„ç½•è§ç¨‹åº¦å¯¹å…¶è¿›è¡ŒåŠ æƒã€‚è¿™æ„å‘³ç€ï¼Œæ­£ç¡®åŒ¹é…ä¸€ä¸ªç½•è§çš„ n-gramï¼Œæ¯”æ­£ç¡®åŒ¹é…ä¸€ä¸ªå¸¸è§çš„ n-gramï¼Œæ›´èƒ½æé«˜ä½ çš„å¾—åˆ†ã€‚
2. ROUGE æ˜¯å¯¹ BLEU çš„ä¸€ç§ä¿®æ”¹ï¼Œå®ƒä¾§é‡äºå¬å›ç‡è€Œéç²¾ç¡®åº¦ã€‚æ¢å¥è¯è¯´ï¼Œå®ƒå…³æ³¨çš„æ˜¯å‚è€ƒè¯‘æ–‡ä¸­æœ‰å¤šå°‘ n-gram å‡ºç°åœ¨è¾“å‡ºç»“æœä¸­ï¼Œè€Œä¸æ˜¯ç›¸åã€‚

ä»€ä¹ˆæ—¶å€™ä½¿ç”¨ BLEU?

1. æ‚¨æ­£åœ¨è¿›è¡Œæœºå™¨ç¿»è¯‘ï¼Œè€Œä¸”
2. æ‚¨æ­£åœ¨å¯¹æ•´ä¸ªè¯­æ–™åº“è¿›è¡Œè¯„ä¼°ï¼Œå¹¶ä¸”
3. æ‚¨çŸ¥é“è¡¡é‡æ ‡å‡†çš„å±€é™æ€§ï¼Œå¹¶æ„¿æ„æ¥å—è¿™äº›å±€é™æ€§ã€‚

### â‘¢ LLM Evaluation

> **[A Survey on Evaluation of LLMs](https://arxiv.org/abs/2307.03109) by Chang et al.:** 
>
> **Comprehensive paper about what to evaluate, where to evaluate, and how to evaluate.**

1. è¿™ç¯‡è®ºæ–‡æ˜¯ä¸€ç¯‡å…³äºå¤§è¯­è¨€æ¨¡å‹(LLMs)è¯„ä¼°çš„ç»¼è¿°æ€§è®ºæ–‡ã€‚å…¨æ–‡åˆ†ä¸º8ä¸ªéƒ¨åˆ†:

- ç¬¬1éƒ¨åˆ†æ˜¯å¼•è¨€,ä»‹ç»äº†è¯„ä¼°LLMsçš„é‡è¦æ€§ã€‚

- ç¬¬2éƒ¨åˆ†ä»‹ç»äº†LLMså’Œäººå·¥æ™ºèƒ½æ¨¡å‹è¯„ä¼°çš„èƒŒæ™¯çŸ¥è¯†ã€‚ 

- ç¬¬3éƒ¨åˆ†ä»å„ä¸ªç»´åº¦å›ç­”äº†"è¯„ä¼°ä»€ä¹ˆ"çš„é—®é¢˜,åŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ã€é²æ£’æ€§ã€ä¼¦ç†ã€åè§ã€ç¤¾ä¼šç§‘å­¦ã€è‡ªç„¶ç§‘å­¦ã€å·¥ç¨‹ã€åŒ»ç–—ã€ä»£ç†äººåº”ç”¨å’Œå…¶ä»–åº”ç”¨ç­‰ã€‚

- ç¬¬4éƒ¨åˆ†å›ç­”äº†"åœ¨å“ªé‡Œè¯„ä¼°"çš„é—®é¢˜,æ€»ç»“äº†ç°æœ‰çš„è¯„ä¼°æ•°æ®é›†å’ŒåŸºå‡†ã€‚

- ç¬¬5éƒ¨åˆ†å›ç­”äº†"å¦‚ä½•è¯„ä¼°"çš„é—®é¢˜,ä»‹ç»äº†è‡ªåŠ¨è¯„ä¼°å’Œäººå·¥è¯„ä¼°ä¸¤ç§è¯„ä¼°æ–¹å¼ã€‚

- ç¬¬6éƒ¨åˆ†æ€»ç»“äº†å…¨æ–‡çš„å…³é”®å‘ç°ã€‚

- ç¬¬7éƒ¨åˆ†æå‡ºäº†æœªæ¥LLMsè¯„ä¼°é¢ä¸´çš„æŒ‘æˆ˜å’Œæœºé‡ã€‚

- ç¬¬8éƒ¨åˆ†æ˜¯å…¨æ–‡æ€»ç»“ã€‚

2. æ¯ä¸ªéƒ¨åˆ†çš„æ¦‚è¿°å’Œæ´è§:

ç¬¬1éƒ¨åˆ†:å¼•è¨€
- è¯„ä¼°æ˜¯äººå·¥æ™ºèƒ½æ¨¡å‹,å°¤å…¶æ˜¯LLMsæˆåŠŸçš„å…³é”®,ç°æœ‰çš„è¯„ä¼°æ–¹æ³•å¯èƒ½è¿˜ä¸è¶³ä»¥å…¨é¢è¯„ä¼°LLMsçš„çœŸå®èƒ½åŠ›ã€‚

ç¬¬2éƒ¨åˆ†:èƒŒæ™¯
- LLMsæ˜¯åŸºäºTransformerçš„å¤§è§„æ¨¡é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹,å…·æœ‰é›¶æ ·æœ¬å­¦ä¹ å’Œäººç±»åé¦ˆå¼ºåŒ–å­¦ä¹ ç­‰ç‰¹ç‚¹,ä»£è¡¨æ¨¡å‹æœ‰GPTç³»åˆ—ã€PaLMç­‰ã€‚
- äººå·¥æ™ºèƒ½æ¨¡å‹çš„è¯„ä¼°åŒ…æ‹¬äº¤å‰éªŒè¯ã€bootstrapç­‰ç»å…¸æ–¹æ³•,è¿˜åº”è€ƒè™‘LLMsçš„ç‰¹æ®Šæ€§ã€‚

ç¬¬3éƒ¨åˆ†:è¯„ä¼°ä»€ä¹ˆ
- **è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡**: æƒ…æ„Ÿåˆ†æã€æ–‡æœ¬åˆ†ç±»ç­‰ä»»åŠ¡ä¸Šè¡¨ç°å‡ºè‰²,ä½†åœ¨è‡ªç„¶è¯­è¨€æ¨ç†ã€è¯­ä¹‰ç†è§£ç­‰æ–¹é¢æœ‰å±€é™ã€‚
- **æ¨ç†**: ç®—æœ¯æ¨ç†èƒ½åŠ›å¼º,é€»è¾‘æ¨ç†ä¼˜ç§€,ä½†æŠ½è±¡æ¨ç†èƒ½åŠ›æœ‰é™ã€‚éšç€æ•°å­¦æ¨ç†ã€ç»“æ„åŒ–æ•°æ®æ¨ç†ç­‰å¤æ‚ä»»åŠ¡æˆä¸ºä¸»æµè¯„ä¼°åŸºå‡†,LLMsè™½ç„¶å–å¾—æŒç»­è¿›æ­¥,ä½†ä»é¢ä¸´è¯¸å¤šæŒ‘æˆ˜ã€‚ 
- **è‡ªç„¶è¯­è¨€ç”Ÿæˆ**:æ‘˜è¦ã€å¯¹è¯ã€ç¿»è¯‘ã€é—®ç­”ç­‰ä»»åŠ¡è¡¨ç°ä¼˜ç§€,ä½†åœ¨ç¤¾äº¤ã€äº‹ä»¶ã€æ—¶æ€ç­‰å¸¸è¯†æ€§çŸ¥è¯†çš„æŠŠæ¡ä¸Šæœ‰å¾…åŠ å¼ºã€‚
- **å¤šè¯­è¨€**:éæ‹‰ä¸è¯­ç³»å’Œä½èµ„æºè¯­è¨€ä¸Šè¡¨ç°ä¸ä½³ã€‚
- **äº‹å®æ€§**:èƒ½å¤ŸåŸºäºäº‹å®å›ç­”é—®é¢˜,ä½†ä»å¯èƒ½äº§ç”Ÿä¸ä¸€è‡´æˆ–è™šæ„çš„ä¿¡æ¯ã€‚
- **é²æ£’æ€§**:å¯¹è§†è§‰æ¨¡æ€ä¿¡æ¯ã€å¯¹æŠ—æ€§è¾“å…¥ç­‰çš„é²æ£’æ€§ä¸è¶³ã€‚
- **ä¼¦ç†å’Œåè§**:å¯èƒ½æ”¾å¤§æœ‰å®³å†…å®¹,äº§ç”Ÿåè§å’Œæœ‰æ¯’è¾“å‡ºã€‚
- **å¯ä¿¡èµ–æ€§**:å¯èƒ½äº§ç”Ÿä¸çœŸå®ä¿¡æ¯,åˆ¤æ–­ä¸€è‡´æ€§é¢ä¸´æŒ‘æˆ˜ã€‚
- **ç¤¾ä¼šç§‘å­¦**:èƒ½ååŠ©è§£å†³ç¤¾ä¼šç§‘å­¦ä¸­çš„è§„æ¨¡å’Œæµ‹é‡é—®é¢˜,ä½†ä¸èƒ½å®Œå…¨å–ä»£äººç±»ä¸“ä¸šäººå£«ã€‚
- **è‡ªç„¶ç§‘å­¦ä¸å·¥ç¨‹**:èƒ½å¤Ÿè§£å†³ç®€å•çš„å·¥ç¨‹ä»»åŠ¡,ä½†åœ¨å¤æ‚ä»»åŠ¡ä¸Šè¡¨ç°ä¸ä½³ã€‚åŒ–å­¦å’Œç‰©ç†æ–¹é¢çš„åº”ç”¨æœ‰å¾…æé«˜ã€‚
- **åŒ»ç–—åº”ç”¨**:èƒ½å¤Ÿå‡†ç¡®å›ç­”åŒ»ç–—æŸ¥è¯¢,åœ¨åŒ»å­¦è€ƒè¯•ä¸­æ¥è¿‘åŠæ ¼çº¿,ä½†ä¸´åºŠåº”ç”¨ä¸­ä»å­˜åœ¨å±€é™æ€§ã€‚
- **Agent** :é€šè¿‡ä¸å¤–éƒ¨å·¥å…·çš„ç»“åˆ,LLMsåœ¨ä»£ç†é¢†åŸŸå±•ç°å‡ºå·¨å¤§æ½œåŠ›ã€‚
- å…¶ä»–åº”ç”¨:æ•™è‚²é¢†åŸŸå‰æ™¯å¹¿é˜”,æœç´¢æ¨èå’Œäººæ ¼æµ‹è¯•ç­‰æ–¹é¢çš„åº”ç”¨ä¹Ÿåœ¨æ¢ç´¢ä¸­ã€‚

ç¬¬4éƒ¨åˆ†:åœ¨å“ªé‡Œè¯„ä¼°
- ç°æœ‰è¯„ä¼°åŸºå‡†å¯åˆ†ä¸ºé’ˆå¯¹é€šç”¨ä»»åŠ¡ã€ç‰¹å®šä¸‹æ¸¸ä»»åŠ¡å’Œå¤šæ¨¡æ€ä»»åŠ¡ä¸‰ç±»ã€‚
- è¯„ä¼°ç»´åº¦åŒ…æ‹¬**æ•´ä½“è¡¨ç°ã€ä¼¦ç†ã€é²æ£’æ€§ã€äº‹å®æ€§ã€æ¨ç†èƒ½åŠ›ã€å·¥å…·ä½¿ç”¨èƒ½åŠ›ã€å¼€æ”¾åŸŸå¯¹è¯èƒ½åŠ›ã€çŸ¥è¯†æŒæ¡æ°´å¹³ã€å¤šä»»åŠ¡å’Œå¤šè¯­è¨€èƒ½åŠ›ç­‰ã€‚**

ç¬¬5éƒ¨åˆ†:å¦‚ä½•è¯„ä¼°
- è‡ªåŠ¨è¯„ä¼°é€šè¿‡æ ‡å‡†æŒ‡æ ‡å’Œè¯„ä¼°å·¥å…·æ¥è¯„ä¼°æ¨¡å‹æ€§èƒ½, ä¼˜ç‚¹æ˜¯çœæ—¶å’Œæ ‡å‡†åŒ–,è¯„ä¼°æŒ‡æ ‡åŒ…æ‹¬å‡†ç¡®æ€§ã€æ ¡å‡†ã€å…¬å¹³æ€§å’Œé²æ£’æ€§ç­‰ã€‚
- äººå·¥è¯„ä¼°é€šè¿‡äººå·¥å‚ä¸è¯„ä¼°æ¨¡å‹ç”Ÿæˆç»“æœçš„è´¨é‡å’Œå‡†ç¡®æ€§, æ›´æ¥è¿‘å®é™…åº”ç”¨, ä½†æˆæœ¬è¾ƒé«˜ã€‚äººå·¥è¯„ä¼°çš„å…³é”®å› ç´ åŒ…æ‹¬è¯„ä¼°è€…äººæ•°ã€è¯„ä¼°æ ‡å‡†å’Œè¯„ä¼°è€…ä¸“ä¸šæ°´å¹³ã€‚

ç¬¬6éƒ¨åˆ†:æ€»ç»“
- LLMsåœ¨è®¸å¤šä»»åŠ¡ä¸Šå–å¾—äº†ä»¤äººç©ç›®çš„è¡¨ç°, ä½†åœ¨**æ¨ç†ã€é²æ£’æ€§ã€å¤šè¯­è¨€ã€äº‹å®æ€§**ç­‰æ–¹é¢ä»å­˜åœ¨å±€é™ã€‚  
- è¯„ä¼°åŸºå‡†æ­£ä»**å®¢è§‚è®¡ç®—å‘äººå·¥å‚ä¸**ã€ä»é™æ€åˆ°åŠ¨æ€æ¼”è¿›ã€‚å…·æœ‰æŒ‘æˆ˜æ€§çš„è¯„ä¼°è®¾ç½®è¶Šæ¥è¶Šå—åˆ°é‡è§†ã€‚

ç¬¬7éƒ¨åˆ†:æŒ‘æˆ˜å’Œæœºé‡
- è®¾è®¡AGIåŸºå‡†:éœ€è¦è·¨å­¦ç§‘çŸ¥è¯†,è®¸å¤šå¼€æ”¾æ€§é—®é¢˜æœ‰å¾…æ¢ç´¢ã€‚
- å®Œæ•´è¡Œä¸ºè¯„ä¼°:æ ‡å‡†åŸºå‡†å’Œå¼€æ”¾ç¯å¢ƒä¸‹çš„è¡Œä¸ºæµ‹è¯•åº”ç›¸è¾…ç›¸æˆã€‚ 
- é²æ£’æ€§è¯„ä¼°:è¯„ä¼°é›†å¤šæ ·åŒ–,è€ƒè™‘æ–°çš„ä¼¦ç†å’Œåè§è¦æ±‚ã€‚
- åŠ¨æ€æ¼”è¿›å¼è¯„ä¼°:ä»¥é€‚åº”LLMsèƒ½åŠ›çš„å¿«é€Ÿè¿›åŒ–ã€‚
- åŸåˆ™æ€§å’Œå¯ä¿¡èµ–çš„è¯„ä¼°:è¯„ä¼°ç³»ç»Ÿæœ¬èº«çš„å¯ä¿¡èµ–æ€§å€¼å¾—å…³æ³¨ã€‚
- æ”¯æŒæ‰€æœ‰ä»»åŠ¡çš„ç»Ÿä¸€è¯„ä¼°: å¼€å‘æ›´é€šç”¨çš„è¯„ä¼°ç³»ç»Ÿã€‚
- è¯„ä¼°ä¹‹å¤–:LLMsçš„å¢å¼ºå’Œæ”¹è¿›ã€‚

ç¬¬8éƒ¨åˆ†:æ€»ç»“
- è¯„ä¼°å¯¹äºLLMsçš„è¿›æ­¥è‡³å…³é‡è¦ã€‚æœ¬æ–‡ä»è¯„ä¼°å†…å®¹ã€æ–¹å¼ã€åŸºå‡†ä¸‰ä¸ªæ–¹é¢è¿›è¡Œäº†å…¨é¢ç»¼è¿°,ä»¥æœŸä¸ºæœªæ¥LLMsçš„å‘å±•æä¾›å‚è€ƒå’Œå¯ç¤ºã€‚

3. ç°æœ‰LLMsè¯„ä¼°åŸºå‡†ä¸€è§ˆè¡¨

|   åŸºå‡†åç§°    |         å…³æ³¨ç‚¹         |       é¢†åŸŸ       |             è¯„ä¼°æ ‡å‡†             |
| :-----------: | :--------------------: | :--------------: | :------------------------------: |
|    SOCKET     |        ç¤¾ä¼šçŸ¥è¯†        |   ç‰¹å®šä¸‹æ¸¸ä»»åŠ¡   |           ç¤¾ä¼šè¯­è¨€ç†è§£           |
|      MME      |       å¤šæ¨¡æ€LLMs       |    å¤šæ¨¡æ€ä»»åŠ¡    |          æ„ŸçŸ¥å’Œè®¤çŸ¥èƒ½åŠ›          |
|    Xiezhi     |      ç»¼åˆé¢†åŸŸçŸ¥è¯†      |   é€šç”¨è¯­è¨€ä»»åŠ¡   |       å¤šä¸ªåŸºå‡†ä¸Šçš„æ•´ä½“è¡¨ç°       |
|   Choice-75   |        è„šæœ¬å­¦ä¹         |   ç‰¹å®šä¸‹æ¸¸ä»»åŠ¡   |          LLMsçš„æ•´ä½“è¡¨ç°          |
|     CUAD      |      æ³•å¾‹åˆåŒå®¡æ ¸      |   ç‰¹å®šä¸‹æ¸¸ä»»åŠ¡   |           æ³•å¾‹åˆåŒç†è§£           |
|   TRUSTGPT    |          ä¼¦ç†          |   ç‰¹å®šä¸‹æ¸¸ä»»åŠ¡   |     æ¯’æ€§ã€åè§å’Œä»·å€¼è§‚ä¸€è‡´æ€§     |
|   **MMLU**    |        æ–‡æœ¬æ¨¡å‹        |   é€šç”¨è¯­è¨€ä»»åŠ¡   |           å¤šä»»åŠ¡å‡†ç¡®æ€§           |
|     MATH      |        æ•°å­¦é—®é¢˜        |   ç‰¹å®šä¸‹æ¸¸ä»»åŠ¡   |             æ•°å­¦èƒ½åŠ›             |
|     APPS      |        ç¼–ç èƒ½åŠ›        |   ç‰¹å®šä¸‹æ¸¸ä»»åŠ¡   |           ä»£ç ç”Ÿæˆèƒ½åŠ›           |
|     CELLO     |        å¤æ‚æŒ‡ä»¤        |   ç‰¹å®šä¸‹æ¸¸ä»»åŠ¡   |        å››ä¸ªæŒ‡å®šçš„è¯„ä¼°æ ‡å‡†        |
|  **C-Eval**   |        ä¸­æ–‡è¯„ä¼°        |   é€šç”¨è¯­è¨€ä»»åŠ¡   |       52ä¸ªä¸­æ–‡è¯­å¢ƒä¸‹çš„è€ƒè¯•       |
| EmotionBench  |        ç§»æƒ…èƒ½åŠ›        |   ç‰¹å®šä¸‹æ¸¸ä»»åŠ¡   |             æƒ…ç»ªå˜åŒ–             |
|    OpenLLM    |       èŠå¤©æœºå™¨äºº       |   é€šç”¨è¯­è¨€ä»»åŠ¡   |            æ’è¡Œæ¦œæ’å            |
|   DynaBench   |        åŠ¨æ€è¯„ä¼°        |   é€šç”¨è¯­è¨€ä»»åŠ¡   |     NLI, QA, æƒ…æ„Ÿå’Œä»‡æ¨è¨€è®º      |
| Chatbot Arena |        èŠå¤©åŠ©æ‰‹        |   é€šç”¨è¯­è¨€ä»»åŠ¡   |        ä¼—åŒ…å’ŒEloè¯„åˆ†ç³»ç»Ÿ         |
|  AlpacaEval   |       è‡ªåŠ¨åŒ–è¯„ä¼°       |   é€šç”¨è¯­è¨€ä»»åŠ¡   |       æŒ‡æ ‡ã€é²æ£’æ€§å’Œå¤šæ ·æ€§       |
|     CMMLU     |       ä¸­æ–‡å¤šä»»åŠ¡       |   ç‰¹å®šä¸‹æ¸¸ä»»åŠ¡   |        å¤šä»»åŠ¡è¯­è¨€ç†è§£èƒ½åŠ›        |
|   **HELM**    |      **æ•´ä½“è¯„ä¼°**      | **é€šç”¨è¯­è¨€ä»»åŠ¡** |            **å¤šæŒ‡æ ‡**            |
|   API-Bank    |        å·¥å…·åˆ©ç”¨        |   ç‰¹å®šä¸‹æ¸¸ä»»åŠ¡   |       APIè°ƒç”¨ã€æ£€ç´¢å’Œè§„åˆ’        |
|     M3KE      |         å¤šä»»åŠ¡         |   ç‰¹å®šä¸‹æ¸¸ä»»åŠ¡   |           å¤šä»»åŠ¡å‡†ç¡®æ€§           |
|    MMBench    |   å¤§è§„æ¨¡è§†è§‰è¯­è¨€æ¨¡å‹   |    å¤šæ¨¡æ€ä»»åŠ¡    |     è§†è§‰è¯­è¨€æ¨¡å‹çš„å¤šæ–¹é¢èƒ½åŠ›     |
|  SEED-Bench   |    å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹    |    å¤šæ¨¡æ€ä»»åŠ¡    | å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹çš„ç”Ÿæˆå’Œç†è§£èƒ½åŠ› |
|    UHGEval    |     ä¸­æ–‡LLMsçš„å¹»è§‰     |   ç‰¹å®šä¸‹æ¸¸ä»»åŠ¡   |         å½¢å¼ã€æŒ‡æ ‡å’Œç²’åº¦         |
|      ARB      |      é«˜çº§æ¨ç†èƒ½åŠ›      |   ç‰¹å®šä¸‹æ¸¸ä»»åŠ¡   |        å¤šé¢†åŸŸé«˜çº§æ¨ç†èƒ½åŠ›        |
|   BIG-bench   |   LMsçš„èƒ½åŠ›å’Œå±€é™æ€§    |   é€šç”¨è¯­è¨€ä»»åŠ¡   |          æ¨¡å‹è¡¨ç°å’Œæ ¡å‡†          |
|  MultiMedQA   |         åŒ»ç–—QA         |   ç‰¹å®šä¸‹æ¸¸ä»»åŠ¡   |         å‡†ç¡®æ€§å’Œäººå·¥è¯„ä¼°         |
|    CVALUES    |       å®‰å…¨å’Œè´£ä»»       |   ç‰¹å®šä¸‹æ¸¸ä»»åŠ¡   |          LLMsçš„å¯¹é½èƒ½åŠ›          |
|   LVLM-eHub   |         LVLMs          |    å¤šæ¨¡æ€ä»»åŠ¡    |        LVLMsçš„å¤šæ¨¡æ€èƒ½åŠ›         |
|   ToolBench   |        è½¯ä»¶å·¥å…·        |   ç‰¹å®šä¸‹æ¸¸ä»»åŠ¡   |            æ‰§è¡ŒæˆåŠŸç‡            |
|    FRESHQA    |         åŠ¨æ€QA         |   ç‰¹å®šä¸‹æ¸¸ä»»åŠ¡   |           æ­£ç¡®æ€§å’Œå¹»è§‰           |
|      CMB      |      ä¸­å›½ç»¼åˆåŒ»å­¦      |   ç‰¹å®šä¸‹æ¸¸ä»»åŠ¡   |        ä¸“å®¶è¯„ä¼°å’Œè‡ªåŠ¨è¯„ä¼°        |
|    PandaLM    |        æŒ‡ä»¤è°ƒä¼˜        |   é€šç”¨è¯­è¨€ä»»åŠ¡   |        PandaLMåˆ¤å®šçš„èƒœç‡         |
|     MINT      |        å¤šè½®äº¤äº’        |   ç‰¹å®šä¸‹æ¸¸ä»»åŠ¡   |       kè½®é¢„ç®—ä¸‹çš„æˆåŠŸç‡ğ‘†ğ‘…ğ‘˜       |
| Dialogue CoT  |        æ·±å…¥å¯¹è¯        |   ç‰¹å®šä¸‹æ¸¸ä»»åŠ¡   |       LLMsçš„å¸®åŠ©å’Œæ¥å—ç¨‹åº¦       |
|     BOSS      |    NLPä¸­çš„OODé²æ£’æ€§    |   é€šç”¨è¯­è¨€ä»»åŠ¡   |            OODé²æ£’æ€§             |
|    MM-Vet     |    å¤æ‚çš„å¤šæ¨¡æ€ä»»åŠ¡    |    å¤šæ¨¡æ€ä»»åŠ¡    |           ä»»åŠ¡ç‰¹å®šæŒ‡æ ‡           |
|     LAMM      |       å¤šæ¨¡æ€ç‚¹äº‘       |    å¤šæ¨¡æ€ä»»åŠ¡    |           ä»»åŠ¡ç‰¹å®šæŒ‡æ ‡           |
|    GLUE-X     |   NLPä»»åŠ¡çš„OODé²æ£’æ€§   |   é€šç”¨è¯­è¨€ä»»åŠ¡   |            OODé²æ£’æ€§             |
|     KoLA      |     é¢å‘çŸ¥è¯†çš„è¯„ä¼°     |   é€šç”¨è¯­è¨€ä»»åŠ¡   |            è‡ªå¯¹æ¯”æŒ‡æ ‡            |
|    AGIEval    |  ä»¥äººä¸ºä¸­å¿ƒçš„åŸºç¡€æ¨¡å‹  |   é€šç”¨è¯­è¨€ä»»åŠ¡   |               é€šç”¨               |
|  PromptBench  |   å¯¹æŠ—æ€§æç¤ºçš„é²æ£’æ€§   |   é€šç”¨è¯­è¨€ä»»åŠ¡   |           å¯¹æŠ—æ€§é²æ£’æ€§           |
|   MT-Bench    |        å¤šè½®å¯¹è¯        |   é€šç”¨è¯­è¨€ä»»åŠ¡   |         GPT-4åˆ¤å®šçš„èƒœç‡          |
|    M3Exam     | å¤šè¯­è¨€ã€å¤šæ¨¡æ€å’Œå¤šå±‚æ¬¡ |   ç‰¹å®šä¸‹æ¸¸ä»»åŠ¡   |           ä»»åŠ¡ç‰¹å®šæŒ‡æ ‡           |
| GAOKAO-Bench  |        ä¸­å›½é«˜è€ƒ        |   ç‰¹å®šä¸‹æ¸¸ä»»åŠ¡   |          å‡†ç¡®æ€§å’Œå¾—åˆ†ç‡          |
|  SafetyBench  |          å®‰å…¨          |   ç‰¹å®šä¸‹æ¸¸ä»»åŠ¡   |          LLMsçš„å®‰å…¨èƒ½åŠ›          |
|   LLMEval2    |       LLMè¯„ä¼°å™¨        |   é€šç”¨è¯­è¨€ä»»åŠ¡   |   å‡†ç¡®ç‡ã€å®F1å’ŒKappaç›¸å…³ç³»æ•°    |

### â‘£ Arena

> [Chatbot Arena Leaderboard](https://huggingface.co/spaces/lmsys/chatbot-arena-leaderboard) by lmsys: 
>
> Elo rating of general-purpose LLMs, based on comparisons made by humans.

LMSYS Chatbot Arena æ˜¯ä¸€ä¸ªç”¨äº LLM evals çš„ä¼—åŒ…å¼€æ”¾å¹³å°ã€‚æˆ‘ä»¬æ”¶é›†äº†è¶…è¿‡ 800,000 æ¬¡äººç±»é…å¯¹æ¯”è¾ƒï¼Œåˆ©ç”¨ Bradley-Terry æ¨¡å‹å¯¹ LLM è¿›è¡Œæ’åï¼Œå¹¶ä»¥ Elo æ ‡åº¦æ˜¾ç¤ºæ¨¡å‹è¯„çº§ã€‚æ‚¨å¯ä»¥åœ¨æˆ‘ä»¬çš„è®ºæ–‡ä¸­æ‰¾åˆ°æ›´å¤šç»†èŠ‚ã€‚

æˆ‘ä»¬æ¨å‡ºçš„èŠå¤©æœºå™¨äººç«æŠ€åœºï¼ˆChatbot Arenaï¼‰æ˜¯ä¸€ä¸ªå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„åŸºå‡†å¹³å°ï¼Œä»¥ä¼—åŒ…æ–¹å¼è¿›è¡ŒåŒ¿åã€éšæœºå¯¹æˆ˜ã€‚åœ¨è¿™ç¯‡åšæ–‡ä¸­ï¼Œæˆ‘ä»¬å°†å‘å¸ƒåˆæ­¥ç»“æœå’ŒåŸºäº Elo è¯„çº§ç³»ç»Ÿçš„æ’è¡Œæ¦œï¼ŒElo è¯„çº§ç³»ç»Ÿæ˜¯å›½é™…è±¡æ£‹å’Œå…¶ä»–ç«æŠ€æ¸¸æˆä¸­å¹¿æ³›ä½¿ç”¨çš„è¯„çº§ç³»ç»Ÿã€‚æˆ‘ä»¬é‚€è¯·æ•´ä¸ªç¤¾åŒºåŠ å…¥è¿™é¡¹å·¥ä½œï¼Œè´¡çŒ®æ–°çš„æ¨¡å‹ï¼Œå¹¶é€šè¿‡æé—®å’ŒæŠ•ç¥¨é€‰å‡ºæ‚¨æœ€å–œæ¬¢çš„ç­”æ¡ˆæ¥è¯„ä¼°è¿™äº›æ¨¡å‹ã€‚

åŸºäºæˆå¯¹æ¯”è¾ƒçš„è‰¯å¥½åŸºå‡†ç³»ç»Ÿéœ€è¦å…·å¤‡ä¸€äº›ç†æƒ³ç‰¹æ€§ã€‚

* å¯æ‰©å±•æ€§ã€‚å½“æ— æ³•ä¸ºæ‰€æœ‰å¯èƒ½çš„æ¨¡å‹å¯¹æ”¶é›†è¶³å¤Ÿçš„æ•°æ®æ—¶ï¼Œç³»ç»Ÿåº”èƒ½æ‰©å±•åˆ°å¤§é‡æ¨¡å‹ã€‚
* é€’å¢æ€§ã€‚ç³»ç»Ÿåº”èƒ½ä½¿ç”¨ç›¸å¯¹è¾ƒå°‘çš„è¯•éªŒæ¬¡æ•°æ¥è¯„ä¼°æ–°æ¨¡å‹ã€‚
* å”¯ä¸€é¡ºåºã€‚ç³»ç»Ÿåº”ä¸ºæ‰€æœ‰æ¨¡å‹æä¾›å”¯ä¸€çš„é¡ºåºã€‚å¯¹äºä»»ä½•ä¸¤ä¸ªæ¨¡å‹ï¼Œæˆ‘ä»¬éƒ½åº”è¯¥èƒ½å¤Ÿåˆ†è¾¨å‡ºå“ªä¸€ä¸ªæ’åé å‰ï¼Œæˆ–è€…å®ƒä»¬æ˜¯å¦å¹¶åˆ—ã€‚

ç°æœ‰çš„ LLM åŸºå‡†ç³»ç»Ÿå¾ˆå°‘èƒ½æ»¡è¶³æ‰€æœ‰è¿™äº›ç‰¹æ€§ã€‚ç»å…¸çš„ LLM åŸºå‡†æ¡†æ¶ï¼Œå¦‚ HELM å’Œ lm-evaluation-harnessï¼Œä¸ºå­¦æœ¯ç ”ç©¶ä¸­å¸¸ç”¨çš„ä»»åŠ¡æä¾›äº†å¤šæŒ‡æ ‡æµ‹é‡ã€‚ä¸è¿‡ï¼Œå®ƒä»¬å¹¶éåŸºäºæˆå¯¹æ¯”è¾ƒï¼Œ**å¯¹å¼€æ”¾å¼é—®é¢˜çš„è¯„ä¼°æ•ˆæœä¸ä½³**ã€‚OpenAI è¿˜å¯åŠ¨äº† evals é¡¹ç›®æ¥æ”¶é›†æ›´å¥½çš„é—®é¢˜ï¼Œä½†è¯¥é¡¹ç›®å¹¶æœªä¸ºæ‰€æœ‰å‚ä¸æ¨¡å‹æä¾›æ’åæœºåˆ¶ã€‚å½“æˆ‘ä»¬æ¨å‡º Vicuna æ¨¡å‹æ—¶ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†åŸºäº GPT-4 çš„è¯„ä¼°ç®¡é“ï¼Œä½†å®ƒå¹¶æ²¡æœ‰ä¸ºå¯æ‰©å±•çš„å¢é‡è¯„çº§æä¾›è§£å†³æ–¹æ¡ˆã€‚

Table 2: Comparison between different evaluation methods.

|                     | HELM / lm-evaluation-harness | OpenAI/eval   | Alpaca Evaluation            | Vicuna Evaluation | Chatbot Arena |
| :------------------ | :--------------------------- | :------------ | :--------------------------- | :---------------- | :------------ |
| **Question Source** | Academic datasets            | Mixed         | Self-instruct evaluation set | GPT-4 generated   | User prompts  |
| **Evaluator**       | Program                      | Program/Model | Human                        | GPT-4             | User          |
| **Metrics**         | Basic metrics                | Basic metrics | Win rate                     | Win rate          | Elo ratings   |



## Part â…¦ Quantization

### â‘  é‡åŒ–ç®€ä»‹

> **[Introduction to quantization](https://mlabonne.github.io/blog/posts/Introduction_to_Weight_Quantization.html): **
>
> **Overview of quantization, absmax and zero-point quantization, and LLM.int8() with code.** 

é‡åŒ–æ–¹æ³•å®¶æ—å¯ä»¥åˆ†ä¸ºä¸¤ç§: **Post-Training Quantization** (PTQ) ä¸ **Quantization-Aware Training** (QAT) 

* PTQ æ˜¯ä¸€ç§ç›´æ¥çš„æŠ€æœ¯ï¼Œå°†å·²è®­ç»ƒæ¨¡å‹çš„æƒé‡è½¬æ¢ä¸ºè¾ƒä½ç²¾åº¦ï¼Œè€Œæ— éœ€é‡æ–°è®­ç»ƒã€‚è™½ç„¶ PTQ å¾ˆå®¹æ˜“å®ç°ï¼Œå®ƒå¯èƒ½ä¼šå¯¼è‡´æ€§èƒ½ä¸‹é™ã€‚

* QAT é‡åŒ–æ„ŸçŸ¥è®­ç»ƒï¼ˆQATï¼‰å°†æƒé‡è½¬æ¢è¿‡ç¨‹çº³å…¥é¢„è®­ç»ƒæˆ–å¾®è°ƒé˜¶æ®µï¼Œä»è€Œæé«˜äº†æ¨¡å‹æ€§èƒ½ã€‚ä¸è¿‡ï¼ŒQAT çš„è®¡ç®—æˆæœ¬å¾ˆé«˜ï¼Œè€Œä¸”éœ€è¦Representative è®­ç»ƒæ•°æ®ã€‚

æˆ‘ä»¬å°†é‡ç‚¹å…³æ³¨ PTQï¼Œä»¥é™ä½å‚æ•°ç²¾åº¦ã€‚

#### 1 æµ®ç‚¹æ•°è¡¨ç¤º

These $n$ bits are further partitioned into three distinct components: 

1. **Sign**: The sign bit indicates the positive or negative nature of the number. It uses one bit where 0 indicates a positive number and 1 signals a negative number.
2. **Exponent**: The exponent is a segment of bits that represents the power to which the base (usually 2 in binary representation) is raised. The exponent can also be positive or negative, allowing the number to represent very large or very small values.
3. **Significand/Mantissa**: The remaining bits are used to store the significand, also referred to as the mantissa. This represents the significant digits (æœ‰æ•ˆæ•°å­—) of the number. The **precision** of the number heavily depends on the length of the significand. 

This design allows floating point numbers to cover a wide range of values with varying levels of precision. The formula used for this representation is:
$$
(-1)^{\text{sign}} \times \text{base}^{\text{exponent}} \times \text{significand}
$$
æˆ‘ä»¬æ¥æ·±å…¥äº†è§£æ·±åº¦å­¦ä¹ ä¸­æœ€å¸¸ç”¨çš„ä¸€äº›æ•°æ®ç±»å‹ï¼šfloat32 (FP32)ã€float16 (FP16) å’Œ bfloat16 (BF16)ï¼š

> ![image-20240419131508745](assets/image-20240419131508745.png)

* FP32 ä½¿ç”¨ 32 ä½æ¥è¡¨ç¤ºä¸€ä¸ªæ•°å­—ï¼š

  1 ä½è¡¨ç¤ºç¬¦å·ï¼Œ8 ä½è¡¨ç¤ºæŒ‡æ•°ï¼Œå…¶ä½™ 23 ä½è¡¨ç¤ºæœ‰æ•ˆæ•°å­—ã€‚è™½ç„¶ FP32 çš„ç²¾åº¦å¾ˆé«˜ï¼Œä½†å…¶ç¼ºç‚¹æ˜¯è®¡ç®—é‡å¤§ï¼Œå ç”¨å†…å­˜å¤šã€‚

* FP16 ä½¿ç”¨ 16 ä½æ¥å­˜å‚¨ä¸€ä¸ªæ•°å­—ï¼š

  1 ä½ç”¨äºç¬¦å·ï¼Œ5 ä½ç”¨äºæŒ‡æ•°ï¼Œ10 ä½ç”¨äºæœ‰æ•ˆæ•°å­—ã€‚è™½ç„¶è¿™æ ·å¯ä»¥æé«˜å†…å­˜æ•ˆç‡å¹¶åŠ å¿«è®¡ç®—é€Ÿåº¦ï¼Œä½†èŒƒå›´å’Œç²¾åº¦çš„é™ä½ä¼šå¸¦æ¥æ•°å€¼ä¸ç¨³å®šæ€§ï¼Œä»è€Œå¯èƒ½å½±å“æ¨¡å‹ç²¾åº¦ã€‚

* BF16 ä¹Ÿæ˜¯ä¸€ç§ 16 ä½æ ¼å¼ï¼Œ

  1 ä½ç”¨äºç¬¦å·ï¼ŒæŒ‡æ•°ä¸º 8 ä½ï¼Œæœ‰æ•ˆæ•°å­—ä¸º 7 ä½ã€‚ä¸ FP16 ç›¸æ¯”ï¼ŒBF16 æ‰©å¤§äº†å¯è¡¨ç¤ºèŒƒå›´ï¼Œä»è€Œé™ä½äº†ä¸‹æº¢å’Œæº¢å‡ºé£é™©ã€‚å°½ç®¡ç”±äºå‡å°‘äº†ç¤ºæ•°ä½è€Œé™ä½äº†ç²¾åº¦ï¼Œä½† BF16 é€šå¸¸ä¸ä¼šå¯¹æ¨¡å‹æ€§èƒ½äº§ç”Ÿé‡å¤§å½±å“ï¼Œå¯¹äºæ·±åº¦å­¦ä¹ ä»»åŠ¡æ¥è¯´æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„æŠ˜è¡·æ–¹æ¡ˆã€‚

åœ¨ ML æœ¯è¯­ä¸­ï¼ŒFP32 é€šå¸¸è¢«ç§°ä¸º "å…¨ç²¾åº¦"ï¼ˆ4 å­—èŠ‚ï¼‰ï¼Œè€Œ BF16 å’Œ FP16 åˆ™æ˜¯ "åŠç²¾åº¦"ï¼ˆ2 å­—èŠ‚ï¼‰ã€‚ä½†æ˜¯ï¼Œæˆ‘ä»¬èƒ½å¦åšå¾—æ›´å¥½ï¼Œä½¿ç”¨å•å­—èŠ‚æ¥å­˜å‚¨æƒé‡å‘¢ï¼Ÿç­”æ¡ˆå°±æ˜¯ INT8 æ•°æ®ç±»å‹ï¼Œå®ƒç”± 8 ä½è¡¨ç¤ºæ³•ç»„æˆï¼Œèƒ½å¤Ÿå­˜å‚¨ 256  ä¸åŒçš„å€¼ã€‚åœ¨ä¸‹ä¸€èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†äº†è§£å¦‚ä½•å°† FP32 æƒå€¼è½¬æ¢ä¸º INT8 æ ¼å¼ã€‚

#### 2 NaÃ¯ve 8-bit Quantization

æˆ‘ä»¬å°†é‡‡ç”¨ä¸¤ç§é‡åŒ–æŠ€æœ¯ï¼š

ä¸€ç§æ˜¯ç»å¯¹æœ€å¤§é‡åŒ–ï¼ˆabsmaxï¼‰[**absolute maximum (absmax) quantization**] çš„å¯¹ç§°æŠ€æœ¯ï¼Œå¦ä¸€ç§æ˜¯é›¶ç‚¹é‡åŒ–çš„éå¯¹ç§°æŠ€æœ¯ [**zero-point Quantization**] ã€‚In both cases, the goal is to map an FP32 tensor $X$ (original weights) to an INT8 tensor $X_{quant}$â€‹ (quantized weights).

**ä½¿ç”¨ absmax é‡åŒ–æ—¶**ï¼ŒåŸå§‹æ•°å€¼é™¤ä»¥å¼ é‡çš„ç»å¯¹æœ€å¤§å€¼ï¼Œå†ä¹˜ä»¥ç¼©æ”¾å› å­ï¼ˆ127ï¼‰ï¼Œå°†è¾“å…¥æ˜ å°„åˆ° [-127, 127] çš„èŒƒå›´å†…ã€‚

ä¸ºäº†è·å– FP16 çš„åŸå§‹å€¼ï¼ŒINT8 æ•°å­—è¦é™¤ä»¥é‡åŒ–å› å­ï¼ŒåŒæ—¶æ‰¿è®¤ç”±äºå››èˆäº”å…¥ä¼šæŸå¤±ä¸€äº›ç²¾åº¦ã€‚
$$
\begin{aligned} {{{\bf X}_{\mathrm{q u a n t}}}} & {{} {{} {{}=\mathrm{r o u n d} \left( \frac{1 2 7} {\operatorname* {m a x} | {\bf X} |} \cdot{\bf X} \right)}}} \\ {{{\bf X}_{\mathrm{d e q u a n t}}}} & {{} {{} {{}=\frac{\operatorname* {m a x} | {\bf X} |} {1 2 7} \cdot{\bf X}_{\mathrm{q u a n t}}}}} \\ \end{aligned}
$$
ä½¿ç”¨ [zero-point Quantization] æ—¶ï¼Œæˆ‘ä»¬å°±å¯ä»¥**è€ƒè™‘éå¯¹ç§°è¾“å…¥åˆ†å¸ƒ**ï¼Œä¾‹å¦‚ï¼Œåœ¨è€ƒè™‘ ReLU å‡½æ•°çš„è¾“å‡ºï¼ˆåªæœ‰æ­£å€¼ï¼‰æ—¶å°±å¾ˆæœ‰ç”¨ã€‚

è¾“å…¥å€¼é¦–å…ˆæŒ‰æ€»å€¼èŒƒå›´ï¼ˆ255ï¼‰é™¤ä»¥æœ€å¤§å€¼å’Œæœ€å°å€¼ä¹‹å·®è¿›è¡Œç¼©æ”¾ã€‚ç„¶åé€šè¿‡é›¶ç‚¹å¯¹åˆ†å¸ƒè¿›è¡Œç§»åŠ¨ï¼Œå°†å…¶æ˜ å°„åˆ° [-128, 127] çš„èŒƒå›´å†…ï¼ˆæ³¨æ„ä¸ absmax ç›¸æ¯”å¤šäº†ä¸€ä¸ªå€¼ï¼‰ã€‚

é¦–å…ˆï¼Œæˆ‘ä»¬è®¡ç®—æ¯”ä¾‹å› å­å’Œé›¶ç‚¹å€¼ï¼š
$$
\begin{align*}
\text{scale} &= \frac{255}{\max(\mathbf{X}) - \min(\mathbf{X})} \\
\text{zeropoint} &= - \text{round}(\text{scale} \cdot \min(\mathbf{X})) - 128
\end{align*}
$$
ç„¶åï¼Œæˆ‘ä»¬å°±å¯ä»¥åˆ©ç”¨è¿™äº›å˜é‡å¯¹æƒé‡è¿›è¡Œé‡åŒ–æˆ–å»é‡åŒ–ï¼š
$$
\begin{align*}
\mathbf{X}_{\text{quant}} &= \text{round}\bigg(\text{scale} \cdot \mathbf{X} + \text{zeropoint} \bigg) \\
\mathbf{X}_{\text{dequant}} &= \frac{\mathbf{X}_{\text{quant}} - \text{zeropoint}}{\text{scale}}
\end{align*}
$$

> ![image-20240419132704084](assets/image-20240419132704084.png)

**ç†è®ºä¸Šï¼Œé›¶ç‚¹é‡åŒ–åº”è¯¥æ¯” absmax ç•¥å¥½ï¼Œä½†è®¡ç®—æˆæœ¬ä¹Ÿæ›´é«˜ã€‚**

**é‡åŒ–æ— æ³•è§£å†³ç¦»ç¾¤ç‰¹å¾çš„é—®é¢˜**ã€‚

ç¦»ç¾¤ç‰¹å¾æ˜¯æŒ‡å½“æ¨¡å‹è¾¾åˆ°ä¸€å®šè§„æ¨¡ï¼ˆ>6.7B ä¸ªå‚æ•°ï¼‰æ—¶ï¼Œæ‰€æœ‰è½¬æ¢å™¨å±‚ä¸­å‡ºç°çš„æç«¯å€¼ï¼ˆè´Ÿå€¼æˆ–æ­£å€¼ï¼‰ã€‚è¿™æ˜¯ä¸€ä¸ªé—®é¢˜ï¼Œå› ä¸ºä¸€ä¸ªç¦»ç¾¤å€¼ä¼šé™ä½æ‰€æœ‰å…¶ä»–å€¼çš„ç²¾åº¦ã€‚ä½†æ”¾å¼ƒè¿™äº›ç¦»ç¾¤ç‚¹ç‰¹å¾æ˜¯ä¸å¯å–çš„ï¼Œå› ä¸ºè¿™ä¼šå¤§å¤§é™ä½æ¨¡å‹çš„æ€§èƒ½ã€‚

#### 3 8-bit Quantization with LLM.int8()

LLM.int8() ç”± Dettmers ç­‰äººï¼ˆ2022 å¹´ï¼‰æå‡ºï¼Œæ˜¯ç¦»ç¾¤å€¼é—®é¢˜çš„ä¸€ç§è§£å†³æ–¹æ¡ˆã€‚

å®ƒä¾èµ–äºçŸ¢é‡ï¼ˆabsmaxï¼‰é‡åŒ–æ–¹æ¡ˆï¼Œå¹¶å¼•å…¥äº†æ··åˆç²¾åº¦é‡åŒ–ã€‚è¿™æ„å‘³ç€ï¼Œ**ç¦»ç¾¤å€¼ä¼šä»¥ FP16 æ ¼å¼å¤„ç†ï¼Œä»¥ä¿ç•™å…¶ç²¾åº¦ï¼Œè€Œå…¶ä»–å€¼åˆ™ä»¥ INT8 æ ¼å¼å¤„ç†**ã€‚ç”±äºç¦»ç¾¤å€¼çº¦å æ•°å€¼çš„ 0.1%ï¼Œè¿™å°±æœ‰æ•ˆåœ°å°† LLM çš„å†…å­˜å ç”¨å‡å°‘äº†è¿‘2å€

> <img src="assets/image-20240419133431210.png" alt="image-20240419133431210" style="zoom:33%;" /> 

LLM.int8() é€šè¿‡ä¸‰ä¸ªå…³é”®æ­¥éª¤è¿›è¡ŒçŸ©é˜µä¹˜æ³•è®¡ç®—ï¼š

1. ä½¿ç”¨è‡ªå®šä¹‰é˜ˆå€¼ä»åŒ…å«ç¦»ç¾¤ç‰¹å¾çš„è¾“å…¥éšè—çŠ¶æ€ X ä¸­æå–åˆ—ã€‚

2. ä½¿ç”¨ FP16 å¯¹å¼‚å¸¸å€¼è¿›è¡ŒçŸ©é˜µä¹˜æ³•è¿ç®—ï¼Œä½¿ç”¨ INT8 å¯¹éå¼‚å¸¸å€¼è¿›è¡ŒçŸ©é˜µä¹˜æ³•è¿ç®—ï¼Œå¹¶è¿›è¡ŒçŸ¢é‡é‡åŒ–ï¼ˆå¯¹éšè—çŠ¶æ€ X è¿›è¡Œè¡Œé‡åŒ–ï¼Œå¯¹æƒé‡çŸ©é˜µ X è¿›è¡Œåˆ—é‡åŒ–ï¼‰ã€‚

3. å°†éç¦»ç¾¤å€¼ç»“æœ Dequantizeï¼ˆINT8 åˆ° FP16ï¼‰ï¼Œå¹¶ä¸ç¦»ç¾¤å€¼ç»“æœç›¸åŠ ï¼Œå¾—åˆ° FP16 çš„å®Œæ•´ç»“æœã€‚

> <img src="assets/image-20240419133804611.png" alt="image-20240419133804611" style="zoom:50%;" /> 

è¿™ç§æ–¹æ³•æ˜¯å¿…è¦çš„ï¼Œå› ä¸º 8 ä½ç²¾åº¦æ˜¯æœ‰é™çš„ï¼Œå½“é‡åŒ–ä¸€ä¸ªå¤§æ•°å€¼çš„çŸ¢é‡æ—¶ï¼Œå¯èƒ½ä¼šå¯¼è‡´å¾ˆå¤§çš„è¯¯å·®ã€‚è¿™äº›è¯¯å·®åœ¨å¤šå±‚ä¼ æ’­æ—¶è¿˜ä¼šæ‰©å¤§ã€‚

ç”±äº bitsandbytes åº“å·²é›†æˆåˆ° Hugging Face ç”Ÿæ€ç³»ç»Ÿä¸­ï¼Œæˆ‘ä»¬å¯ä»¥è½»æ¾ä½¿ç”¨è¿™ä¸€æŠ€æœ¯ã€‚

æˆ‘ä»¬åªéœ€åœ¨åŠ è½½æ¨¡å‹æ—¶æŒ‡å®š `load_in_8bit=True`ï¼ˆä¹Ÿéœ€è¦ GPUï¼‰ã€‚

```python
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

model_int8 = AutoModelForCausalLM.from_pretrained(model_id,
                                             device_map='auto',
                                             load_in_8bit=True,
                                             )
print(f"Model size: {model_int8.get_memory_footprint():,} bytes")
```

äº‹å®ä¸Šï¼ŒLLM.int8() çš„ä½œè€…è¡¨æ˜ï¼Œæ€§èƒ½ä¸‹é™éå¸¸ä½ï¼Œå¯ä»¥å¿½ç•¥ä¸è®¡ï¼ˆ<1%ï¼‰ã€‚

ä¸è¿‡ï¼Œè¿™ç§æ–¹æ³•éœ€è¦é¢å¤–çš„è®¡ç®—æˆæœ¬ï¼š**å¯¹äºå¤§å‹æ¨¡å‹ï¼ŒLLM.int8() çš„è¿ç®—é€Ÿåº¦å¤§çº¦è¦æ…¢ 20%**ã€‚

## Part â…§ New Trends 

### â‘  Positional Embedding

> [Extending the RoPE](https://blog.eleuther.ai/yarn/) by EleutherAI: Article that summarizes the different position-encoding techniques.
>
> [Rotary Embeddings: A Relative Revolution | EleutherAI Blog](https://blog.eleuther.ai/rotary-embeddings/)

æ—‹è½¬ä½ç½®åµŒå…¥ï¼ˆRoPEï¼‰æ˜¯ä¸€ç§æœ‰æ•ˆçš„ä½ç½®ç¼–ç æŠ€æœ¯ï¼Œæœ€æ—©ç”± Su ç­‰äººï¼ˆ2020 å¹´ï¼‰[1] æå‡ºï¼Œå®ƒå°†**ç»å¯¹ä½ç½®ç¼–ç å’Œç›¸å¯¹ä½ç½®ç¼–ç ç»Ÿä¸€èµ·æ¥**. åæ¥åœ¨ GPT-Jã€GPT-NeoXã€PaLMã€LLaMA ç­‰å¼€æºæ¨¡å‹ä¸­å¾—åˆ°æ¨å¹¿ã€‚å¤§çº¦ä¸¤å¹´å‰ï¼Œæˆ‘ä»¬åœ¨è¿™ç¯‡åšæ–‡ä¸­ä»‹ç»äº† RoPE çš„æ•°å­¦å’Œå®ç°ç»†èŠ‚ã€‚

#### 1 Conventions

Given a sequence of tokens $w_1, w_2, \cdots, w_L$, the token embedding maps them to $x_1, x_2, \cdots, x_L\in \mathbb R^{|D|}$ where $|D|$ is the dimension of the hidden states. At token position $m$, the attention mechanism first produces the query and key vectors through functions $f_q$ and $f_k$ as follows:
$$
q_m = f_q(x_m, m) \in \mathbb R^{|L|}, k_m = f_k(x_m, m) \in \mathbb R^{|L|}.
$$
Given a pair of token positions $m$, $n$ the attention scores are given by:
$$
\text{softmax}(\dfrac{q_m^Tk_n}{\sqrt{|D|}}),
$$
where $q_m, k_n$ are column vectors. The heuristic is that given the pair $m, n$ the attention score indicates how much "attention" should be assigned to the $n-th$ token, given the $m$-th token. 

#### 2 RoPE

> [RoPEå¯èƒ½æ˜¯LLMæ—¶ä»£çš„Resnet - çŸ¥ä¹ (zhihu.com)](https://zhuanlan.zhihu.com/p/641865355)

Attention å¾—åˆ†è¡¨ç¤ºçš„æ˜¯, åœ¨ m($Q$) çš„å‰æä¸‹, åº”è¯¥å¯¹ Token $n$ æŠ•å…¥å¤šå°‘çš„æ³¨æ„åŠ›. 

ä½ç½®ç¼–ç ç¼–ç çš„æ˜¯ä½ç½®ä¿¡æ¯, è€ŒTokenä¸Tokençš„äº¤äº’ä¹Ÿæ­£æ˜¯é€šè¿‡Attentionæœºåˆ¶è”ç³»åˆ°ä¸€èµ·çš„, å…·ä½“è€Œè¨€æ˜¯æ³¨æ„åŠ›åˆ†æ•°(Attention Score). è€Œ RoPE çš„ä¸­å¿ƒæ€æƒ³å¾ˆç®€å•: å³ Attentionåˆ†æ•°, åº”è¯¥ä»…ä»…å–å†³äºä¸¤ä¸ª Token Embedding, åŠä¸¤è€…ä¹‹é—´çš„ç›¸å¯¹ä½ç½®ä¿¡æ¯ $m-n$. æ•°å­¦å½¢å¼å¦‚ä¸‹:
$$
f_q(x_m, m)^Tf_k(x_n, n) = g(x_m, x_n, m - n),
$$
é€šä¿—åœ°è¯´ï¼Œä¸¤ä¸ªå‘é‡ä¹‹é—´çš„ç‚¹ç§¯æ˜¯å•ä¸ªå‘é‡çš„å¤§å°å’Œå®ƒä»¬ä¹‹é—´çš„è§’åº¦çš„å‡½æ•°ã€‚è€ƒè™‘åˆ°è¿™ä¸€ç‚¹ï¼ŒRoPE èƒŒåçš„ç›´è§‰æ˜¯ï¼Œæˆ‘ä»¬å¯ä»¥å°† **Token Embedding** è¡¨ç¤ºä¸ºå¤æ•°ï¼Œå°†å…¶ **Position Representation** ä¸ºæˆ‘ä»¬**å¯¹å…¶è¿›è¡Œçš„çº¯æ—‹è½¬**ã€‚å¦‚æœæˆ‘ä»¬ä»¥ç›¸åŒçš„å¹…åº¦ç§»åŠ¨æŸ¥è¯¢å’Œå¯†é’¥ï¼Œæ”¹å˜ç»å¯¹ä½ç½®è€Œä¸æ”¹å˜ç›¸å¯¹ä½ç½®ï¼Œè¿™å°†å¯¼è‡´è¿™ä¸¤ä¸ªè¡¨ç¤º ($Q, K$)ä»¥ç›¸åŒçš„æ–¹å¼è¿›è¡Œé¢å¤–æ—‹è½¬--æ­£å¦‚æˆ‘ä»¬åœ¨æ¨å¯¼ä¸­å°†çœ‹åˆ°çš„é‚£æ ·--**å› æ­¤å®ƒä»¬ä¹‹é—´çš„è§’åº¦å°†ä¿æŒä¸å˜ï¼Œä»è€Œç‚¹ç§¯ä¹Ÿå°†ä¿æŒä¸å˜**ã€‚é€šè¿‡åˆ©ç”¨æ—‹è½¬çš„æ€§è´¨ï¼Œ**è‡ªæˆ‘å…³æ³¨ä¸­ä½¿ç”¨çš„ç‚¹ç§¯å°†å…·æœ‰æˆ‘ä»¬æ‰€å¯»æ‰¾çš„ç‰¹æ€§ï¼Œå³ä¿ç•™ç›¸å¯¹ä½ç½®ä¿¡æ¯ï¼ŒåŒæ—¶æ‘’å¼ƒç»å¯¹ä½ç½®ä¿¡æ¯**ã€‚
$$
\begin{align}
\mathrm{RoPE}(x, m) &= xe^{mi\varepsilon} \\
\langle \mathrm{RoPE}(q_j, m), \mathrm{RoPE}(k_j, n)\rangle &= \langle q_j e^{mi\varepsilon}, k_j e^{ni\varepsilon} \rangle \\
&= q_j k_j e^{mi\varepsilon} \overline{e^{ni\varepsilon}} \\
&= q_j k_j e^{(m - n)i\varepsilon} \\
&= \mathrm{RoPE}(q_j k_j, m - n)
\end{align}
$$
æœ€å, æŸ¥è¯¢å‘é‡ ä¸ é”®å‘é‡å¯ä»¥è¢«å¦‚ä¸‹é‡æ„
$$
\begin{align}
f_W(x_m, m, \theta_d) = \begin{pmatrix}
\text{cos} m\theta_1 & - \text{sin} m\theta_1 & 0 & 0 & \cdots & 0 & 0 \\
\text{sin} m\theta_1 & \text{cos} m\theta_1 & 0 & 0 & \cdots & 0 & 0 \\
0 & 0 & \text{cos} m\theta_2 & - \text{sin} m\theta_2 & \cdots & 0 & 0 \\
0 & 0 & \text{sin} m\theta_2 & \text{cos} m\theta_2 & \cdots & 0 & 0 \\
0 & 0 & 0 & 0 & \cdots & \text{cos} m\theta_l & - \text{sin} m\theta_l  \\
0 & 0 & 0 & 0 & \cdots & \text{sin} m\theta_l & \text{cos} m\theta_l \\
\end{pmatrix}
W_q\textbf{x}_m.\\
f_q = f_{W_q}, ~f_k = f_{W_k},
\end{align}
$$
where $\theta_d = b^{-2d/|D|}$, is the angle at the $d$-th hidden state with $b$ chosen to be 10000 in the RoFormer paper ([1]).

### â‘¡ MoE

> **[Mixture of Experts Explained](https://huggingface.co/blog/moe) by Hugging Face: Exhaustive guide about MoEs and how they work.**
>
> [æ¬¢è¿ Mixtral - å½“å‰ Hugging Face ä¸Šæœ€å…ˆè¿›çš„ MoE æ¨¡å‹](https://huggingface.co/blog/zh/mixtral)

æ··åˆä¸“å®¶æ¨¡å‹ (MoEs):

- ä¸ç¨ å¯†æ¨¡å‹ç›¸æ¯”ï¼Œ **é¢„è®­ç»ƒé€Ÿåº¦æ›´å¿«**
- ä¸å…·æœ‰ç›¸åŒå‚æ•°æ•°é‡çš„æ¨¡å‹ç›¸æ¯”ï¼Œå…·æœ‰æ›´å¿«çš„ **æ¨ç†é€Ÿåº¦**
- éœ€è¦ **å¤§é‡æ˜¾å­˜**ï¼Œå› ä¸ºæ‰€æœ‰ä¸“å®¶ç³»ç»Ÿéƒ½éœ€è¦åŠ è½½åˆ°å†…å­˜ä¸­
- åœ¨ **å¾®è°ƒæ–¹é¢å­˜åœ¨è¯¸å¤šæŒ‘æˆ˜**ï¼Œä½† [è¿‘æœŸçš„ç ”ç©¶](https://arxiv.org/pdf/2305.14705.pdf) è¡¨æ˜ï¼Œå¯¹æ··åˆä¸“å®¶æ¨¡å‹è¿›è¡Œ **æŒ‡ä»¤è°ƒä¼˜å…·æœ‰å¾ˆå¤§çš„æ½œåŠ›**ã€‚

#### 1 ä»€ä¹ˆæ˜¯æ··åˆä¸“å®¶æ¨¡å‹

æ¨¡å‹è§„æ¨¡æ˜¯æå‡æ¨¡å‹æ€§èƒ½çš„å…³é”®å› ç´ ä¹‹ä¸€ã€‚

> åœ¨æœ‰é™çš„è®¡ç®—èµ„æºé¢„ç®—ä¸‹ï¼Œ**ç”¨æ›´å°‘çš„è®­ç»ƒæ­¥æ•°è®­ç»ƒä¸€ä¸ªæ›´å¤§çš„æ¨¡å‹ï¼Œå¾€å¾€æ¯”ç”¨æ›´å¤šçš„æ­¥æ•°è®­ç»ƒä¸€ä¸ªè¾ƒå°çš„æ¨¡å‹æ•ˆæœæ›´ä½³**ã€‚

æ··åˆä¸“å®¶æ¨¡å‹ (MoE) çš„ä¸€ä¸ªæ˜¾è‘—ä¼˜åŠ¿æ˜¯**å®ƒä»¬èƒ½å¤Ÿåœ¨è¿œå°‘äº Dense æ¨¡å‹æ‰€éœ€çš„è®¡ç®—èµ„æºä¸‹è¿›è¡Œæœ‰æ•ˆçš„é¢„è®­ç»ƒ**ã€‚

è¿™æ„å‘³ç€åœ¨ç›¸åŒçš„è®¡ç®—é¢„ç®—æ¡ä»¶ä¸‹ï¼Œæ‚¨å¯ä»¥æ˜¾è‘—æ‰©å¤§æ¨¡å‹æˆ–æ•°æ®é›†çš„è§„æ¨¡ã€‚ç‰¹åˆ«æ˜¯åœ¨é¢„è®­ç»ƒé˜¶æ®µï¼Œä¸ç¨ å¯†æ¨¡å‹ç›¸æ¯”ï¼Œæ··åˆä¸“å®¶æ¨¡å‹é€šå¸¸èƒ½å¤Ÿæ›´å¿«åœ°è¾¾åˆ°ç›¸åŒçš„è´¨é‡æ°´å¹³ã€‚

é‚£ä¹ˆï¼Œç©¶ç«Ÿä»€ä¹ˆæ˜¯ä¸€ä¸ªæ··åˆä¸“å®¶æ¨¡å‹ (MoE) å‘¢ï¼Ÿä½œä¸ºä¸€ç§åŸºäº Transformer æ¶æ„çš„æ¨¡å‹ï¼Œæ··åˆä¸“å®¶æ¨¡å‹ä¸»è¦ç”±ä¸¤ä¸ªå…³é”®éƒ¨åˆ†ç»„æˆ:

- **ç¨€ç– MoE å±‚**: è¿™äº›å±‚**ä»£æ›¿äº†ä¼ ç»Ÿ Transformer æ¨¡å‹ä¸­çš„å‰é¦ˆç½‘ç»œ (FFN)** å±‚ã€‚MoE å±‚åŒ…å«è‹¥å¹²â€œä¸“å®¶â€(ä¾‹å¦‚ 8 ä¸ª)ï¼Œæ¯ä¸ªä¸“å®¶æœ¬èº«æ˜¯ä¸€ä¸ªç‹¬ç«‹çš„ç¥ç»ç½‘ç»œã€‚åœ¨å®é™…åº”ç”¨ä¸­ï¼Œè¿™äº›ä¸“å®¶é€šå¸¸æ˜¯å‰é¦ˆç½‘ç»œ (FFN)ï¼Œä½†å®ƒä»¬ä¹Ÿå¯ä»¥æ˜¯æ›´å¤æ‚çš„ç½‘ç»œç»“æ„ï¼Œç”šè‡³å¯ä»¥æ˜¯ MoE å±‚æœ¬èº«ï¼Œä»è€Œå½¢æˆå±‚çº§å¼çš„ MoE ç»“æ„ã€‚

- **é—¨æ§ç½‘ç»œæˆ–è·¯ç”±**: è¿™ä¸ªéƒ¨åˆ†ç”¨äº**å†³å®šå“ªäº›ä»¤ç‰Œ (token) è¢«å‘é€åˆ°å“ªä¸ªä¸“å®¶**ã€‚ä¾‹å¦‚ï¼Œåœ¨ä¸‹å›¾ä¸­ï¼Œâ€œMoreâ€è¿™ä¸ªä»¤ç‰Œå¯èƒ½è¢«å‘é€åˆ°ç¬¬äºŒä¸ªä¸“å®¶ï¼Œè€Œâ€œParametersâ€è¿™ä¸ªä»¤ç‰Œè¢«å‘é€åˆ°ç¬¬ä¸€ä¸ªä¸“å®¶ã€‚æœ‰æ—¶ï¼Œä¸€ä¸ªä»¤ç‰Œç”šè‡³å¯ä»¥è¢«å‘é€åˆ°å¤šä¸ªä¸“å®¶ã€‚ä»¤ç‰Œçš„è·¯ç”±æ–¹å¼æ˜¯ MoE ä½¿ç”¨ä¸­çš„ä¸€ä¸ªå…³é”®ç‚¹ï¼Œå› ä¸ºè·¯ç”±å™¨ç”±å­¦ä¹ çš„å‚æ•°ç»„æˆï¼Œå¹¶ä¸”ä¸ç½‘ç»œçš„å…¶ä»–éƒ¨åˆ†ä¸€åŒè¿›è¡Œé¢„è®­ç»ƒã€‚

  > <img src="assets/image-20240419161925458.png" alt="image-20240419161925458" style="zoom:50%;" /> 

æ€»ç»“æ¥è¯´ï¼Œåœ¨æ··åˆä¸“å®¶æ¨¡å‹ (MoE) ä¸­ï¼Œæˆ‘ä»¬å°†ä¼ ç»Ÿ Transformer æ¨¡å‹ä¸­çš„æ¯ä¸ªå‰é¦ˆç½‘ç»œ (FFN) å±‚æ›¿æ¢ä¸º MoE å±‚ï¼Œå…¶ä¸­ MoE å±‚ç”±ä¸¤ä¸ªæ ¸å¿ƒéƒ¨åˆ†ç»„æˆ: ä¸€ä¸ªé—¨æ§ç½‘ç»œå’Œè‹¥å¹²æ•°é‡çš„ä¸“å®¶ã€‚

å°½ç®¡æ··åˆä¸“å®¶æ¨¡å‹ (MoE) æä¾›äº†è‹¥å¹²æ˜¾è‘—ä¼˜åŠ¿ï¼Œä¾‹å¦‚æ›´é«˜æ•ˆçš„é¢„è®­ç»ƒå’Œä¸ç¨ å¯†æ¨¡å‹ç›¸æ¯”æ›´å¿«çš„æ¨ç†é€Ÿåº¦ï¼Œä½†å®ƒä»¬ä¹Ÿä¼´éšç€ä¸€äº›æŒ‘æˆ˜:

- **è®­ç»ƒæŒ‘æˆ˜**: 

  è™½ç„¶ MoE èƒ½å¤Ÿå®ç°æ›´é«˜æ•ˆçš„è®¡ç®—é¢„è®­ç»ƒï¼Œä½†å®ƒä»¬åœ¨**å¾®è°ƒé˜¶æ®µå¾€å¾€é¢ä¸´æ³›åŒ–èƒ½åŠ›ä¸è¶³çš„é—®é¢˜**ï¼Œé•¿æœŸä»¥æ¥æ˜“äºå¼•å‘è¿‡æ‹Ÿåˆç°è±¡ã€‚

- **æ¨ç†æŒ‘æˆ˜**: 

  MoE æ¨¡å‹è™½ç„¶å¯èƒ½æ‹¥æœ‰å¤§é‡å‚æ•°ï¼Œä½†åœ¨æ¨ç†è¿‡ç¨‹ä¸­åªä½¿ç”¨å…¶ä¸­çš„ä¸€éƒ¨åˆ†ï¼Œè¿™ä½¿å¾—å®ƒä»¬çš„æ¨ç†é€Ÿåº¦å¿«äºå…·æœ‰ç›¸åŒæ•°é‡å‚æ•°çš„ç¨ å¯†æ¨¡å‹ã€‚ç„¶è€Œï¼Œè¿™ç§æ¨¡å‹éœ€è¦å°†æ‰€æœ‰å‚æ•°åŠ è½½åˆ°å†…å­˜ä¸­ï¼Œå› æ­¤å¯¹å†…å­˜çš„éœ€æ±‚éå¸¸é«˜ã€‚

  ä»¥ Mixtral 8x7B è¿™æ ·çš„ MoE ä¸ºä¾‹ï¼Œéœ€è¦è¶³å¤Ÿçš„ VRAM æ¥å®¹çº³ä¸€ä¸ª 47B å‚æ•°çš„ç¨ å¯†æ¨¡å‹ã€‚ä¹‹æ‰€ä»¥æ˜¯ 47B è€Œä¸æ˜¯ 8 x 7B = 56Bï¼Œæ˜¯å› ä¸ºåœ¨ MoE æ¨¡å‹ä¸­ï¼Œåªæœ‰ FFN å±‚è¢«è§†ä¸ºç‹¬ç«‹çš„ä¸“å®¶ï¼Œè€Œæ¨¡å‹çš„å…¶ä»–å‚æ•°æ˜¯å…±äº«çš„ã€‚

  æ­¤å¤–ï¼Œå‡è®¾æ¯ä¸ªä»¤ç‰Œåªä½¿ç”¨ä¸¤ä¸ªä¸“å®¶ï¼Œé‚£ä¹ˆæ¨ç†é€Ÿåº¦ (ä»¥ FLOPs è®¡ç®—) ç±»ä¼¼äºä½¿ç”¨ 12B æ¨¡å‹ (è€Œä¸æ˜¯ 14B æ¨¡å‹)ï¼Œå› ä¸ºè™½ç„¶å®ƒè¿›è¡Œäº† 2x7B çš„çŸ©é˜µä¹˜æ³•è®¡ç®—ï¼Œä½†æŸäº›å±‚æ˜¯å…±äº«çš„ã€‚

#### 2 æ··åˆä¸“å®¶æ¨¡å‹ç®€å²

æ··åˆä¸“å®¶æ¨¡å‹ (MoE) çš„ç†å¿µèµ·æºäº 1991 å¹´çš„è®ºæ–‡ [Adaptive Mixture of Local Experts](https://www.cs.toronto.edu/~hinton/absps/jjnh91.pdf)ã€‚è¿™ä¸ªæ¦‚å¿µä¸é›†æˆå­¦ä¹ æ–¹æ³•ç›¸ä¼¼ï¼Œæ—¨åœ¨ä¸ºç”±å¤šä¸ªå•ç‹¬ç½‘ç»œç»„æˆçš„ç³»ç»Ÿå»ºç«‹ä¸€ä¸ªç›‘ç®¡æœºåˆ¶ã€‚åœ¨è¿™ç§ç³»ç»Ÿä¸­ï¼Œæ¯ä¸ªç½‘ç»œ (è¢«ç§°ä¸ºâ€œä¸“å®¶â€) å¤„ç†è®­ç»ƒæ ·æœ¬çš„ä¸åŒå­é›†ï¼Œä¸“æ³¨äºè¾“å…¥ç©ºé—´çš„ç‰¹å®šåŒºåŸŸã€‚é‚£ä¹ˆï¼Œå¦‚ä½•é€‰æ‹©å“ªä¸ªä¸“å®¶æ¥å¤„ç†ç‰¹å®šçš„è¾“å…¥å‘¢ï¼Ÿè¿™å°±æ˜¯é—¨æ§ç½‘ç»œå‘æŒ¥ä½œç”¨çš„åœ°æ–¹ï¼Œ**å®ƒå†³å®šäº†åˆ†é…ç»™æ¯ä¸ªä¸“å®¶çš„æƒé‡**ã€‚**åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œè¿™äº›ä¸“å®¶å’Œé—¨æ§ç½‘ç»œéƒ½åŒæ—¶æ¥å—è®­ç»ƒï¼Œä»¥ä¼˜åŒ–å®ƒä»¬çš„æ€§èƒ½å’Œå†³ç­–èƒ½åŠ›ã€‚**

åœ¨ 2010 è‡³ 2015 å¹´é—´ï¼Œä¸¤ä¸ªç‹¬ç«‹çš„ç ”ç©¶é¢†åŸŸä¸ºæ··åˆä¸“å®¶æ¨¡å‹ (MoE) çš„åç»­å‘å±•åšå‡ºäº†æ˜¾è‘—è´¡çŒ®:

1. **ç»„ä»¶ä¸“å®¶**: (æ¨¡å‹çš„ä¸€ä¸ªéƒ¨åˆ† vs æ¨¡å‹çš„æ›´æ·±å±‚åµŒå…¥ )

   åœ¨ä¼ ç»Ÿçš„ MoE è®¾ç½®ä¸­ï¼Œæ•´ä¸ªç³»ç»Ÿç”±ä¸€ä¸ªé—¨æ§ç½‘ç»œå’Œå¤šä¸ªä¸“å®¶ç»„æˆã€‚åœ¨æ”¯æŒå‘é‡æœº (SVMs) ã€é«˜æ–¯è¿‡ç¨‹å’Œå…¶ä»–æ–¹æ³•çš„ç ”ç©¶ä¸­ï¼ŒMoE é€šå¸¸è¢«è§†ä¸ºæ•´ä¸ªæ¨¡å‹çš„ä¸€éƒ¨åˆ†ã€‚

   ç„¶è€Œï¼Œ[Eigenã€Ranzato å’Œ Ilya çš„ç ”ç©¶](https://arxiv.org/abs/1312.4314) æ¢ç´¢äº†å°† MoE ä½œä¸ºæ›´æ·±å±‚ç½‘ç»œçš„ä¸€ä¸ªç»„ä»¶ã€‚è¿™ç§æ–¹æ³•å…è®¸å°† MoE åµŒå…¥åˆ°å¤šå±‚ç½‘ç»œä¸­çš„æŸä¸€å±‚ï¼Œä½¿å¾—æ¨¡å‹æ—¢å¤§åˆé«˜æ•ˆã€‚

2. **æ¡ä»¶è®¡ç®—**: (æ‰€æœ‰å±‚å¤„ç†æ‰€æœ‰çš„æ•°æ® vs åœç”¨æŸäº›å±‚ORé€šè·¯ )

   ä¼ ç»Ÿçš„ç¥ç»ç½‘ç»œé€šè¿‡æ¯ä¸€å±‚å¤„ç†æ‰€æœ‰è¾“å…¥æ•°æ®ã€‚

   åœ¨è¿™ä¸€æ—¶æœŸï¼ŒYoshua Bengio ç­‰ç ”ç©¶äººå‘˜å¼€å§‹æ¢ç´¢åŸºäºè¾“å…¥ä»¤ç‰ŒåŠ¨æ€æ¿€æ´»æˆ–åœç”¨ç½‘ç»œç»„ä»¶çš„æ–¹æ³•ã€‚

#### 3 ç¨€ç–æ€§

ç¨€ç–æ€§çš„æ¦‚å¿µé‡‡ç”¨äº†æ¡ä»¶è®¡ç®—çš„æ€æƒ³ã€‚åœ¨ä¼ ç»Ÿçš„ç¨ å¯†æ¨¡å‹ä¸­ï¼Œæ‰€æœ‰çš„å‚æ•°éƒ½ä¼šå¯¹æ‰€æœ‰è¾“å…¥æ•°æ®è¿›è¡Œå¤„ç†ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œç¨€ç–æ€§**å…è®¸æˆ‘ä»¬ä»…é’ˆå¯¹æ•´ä¸ªç³»ç»Ÿçš„æŸäº›ç‰¹å®šéƒ¨åˆ†æ‰§è¡Œè®¡ç®—**ã€‚**è¿™æ„å‘³ç€å¹¶éæ‰€æœ‰å‚æ•°éƒ½ä¼šåœ¨å¤„ç†æ¯ä¸ªè¾“å…¥æ—¶è¢«æ¿€æ´»æˆ–ä½¿ç”¨**ï¼Œè€Œæ˜¯æ ¹æ®è¾“å…¥çš„ç‰¹å®šç‰¹å¾æˆ–éœ€æ±‚ï¼Œåªæœ‰éƒ¨åˆ†å‚æ•°é›†åˆè¢«è°ƒç”¨å’Œè¿è¡Œã€‚

è®©æˆ‘ä»¬æ·±å…¥åˆ†æ Shazeer å¯¹æ··åˆä¸“å®¶æ¨¡å‹ (MoE) åœ¨ç¿»è¯‘åº”ç”¨ä¸­çš„è´¡çŒ®ã€‚æ¡ä»¶è®¡ç®—çš„æ¦‚å¿µ (å³ä»…åœ¨æ¯ä¸ªæ ·æœ¬çš„åŸºç¡€ä¸Šæ¿€æ´»ç½‘ç»œçš„ä¸åŒéƒ¨åˆ†) ä½¿å¾—åœ¨ä¸å¢åŠ é¢å¤–è®¡ç®—è´Ÿæ‹…çš„æƒ…å†µä¸‹æ‰©å±•æ¨¡å‹è§„æ¨¡æˆä¸ºå¯èƒ½ã€‚è¿™ä¸€ç­–ç•¥åœ¨æ¯ä¸ª MoE å±‚ä¸­å®ç°äº†æ•°ä»¥åƒè®¡ç”šè‡³æ›´å¤šçš„ä¸“å®¶çš„æœ‰æ•ˆåˆ©ç”¨ã€‚

è¿™ç§ç¨€ç–æ€§è®¾ç½®ç¡®å®å¸¦æ¥äº†ä¸€äº›æŒ‘æˆ˜ã€‚ä¾‹å¦‚ï¼Œåœ¨æ··åˆä¸“å®¶æ¨¡å‹ (MoE) ä¸­ï¼Œå°½ç®¡è¾ƒå¤§çš„æ‰¹é‡å¤§å°é€šå¸¸æœ‰åˆ©äºæé«˜æ€§èƒ½ï¼Œä½†å½“æ•°æ®é€šè¿‡æ¿€æ´»çš„ä¸“å®¶æ—¶ï¼Œå®é™…çš„æ‰¹é‡å¤§å°å¯èƒ½ä¼šå‡å°‘ã€‚æ¯”å¦‚ï¼Œå‡è®¾æˆ‘ä»¬çš„è¾“å…¥æ‰¹é‡åŒ…å« 10 ä¸ªä»¤ç‰Œï¼Œ **å¯èƒ½ä¼šæœ‰äº”ä¸ªä»¤ç‰Œè¢«è·¯ç”±åˆ°åŒä¸€ä¸ªä¸“å®¶ï¼Œè€Œå‰©ä¸‹çš„äº”ä¸ªä»¤ç‰Œåˆ†åˆ«è¢«è·¯ç”±åˆ°ä¸åŒçš„ä¸“å®¶ã€‚è¿™å¯¼è‡´äº†æ‰¹é‡å¤§å°çš„ä¸å‡åŒ€åˆ†é…å’Œèµ„æºåˆ©ç”¨æ•ˆç‡ä¸é«˜çš„é—®é¢˜**ã€‚åœ¨æ¥ä¸‹æ¥çš„éƒ¨åˆ†ä¸­ï¼Œå°†ä¼šè®¨è®º [è®© MoE é«˜æ•ˆè¿è¡Œ](https://huggingface.co/blog/zh/moe#è®©moeèµ·é£) çš„å…¶ä»–æŒ‘æˆ˜ä»¥åŠç›¸åº”çš„è§£å†³æ–¹æ¡ˆã€‚

#### 4 æ··åˆä¸“å®¶æ¨¡å‹ä¸­ä»¤ç‰Œçš„è´Ÿè½½å‡è¡¡

æ­£å¦‚ä¹‹å‰è®¨è®ºçš„ï¼Œå¦‚æœæ‰€æœ‰çš„ä»¤ç‰Œéƒ½è¢«å‘é€åˆ°åªæœ‰å°‘æ•°å‡ ä¸ªå—æ¬¢è¿çš„ä¸“å®¶ï¼Œé‚£ä¹ˆè®­ç»ƒæ•ˆç‡å°†ä¼šé™ä½ã€‚åœ¨é€šå¸¸çš„æ··åˆä¸“å®¶æ¨¡å‹ (MoE) è®­ç»ƒä¸­ï¼Œé—¨æ§ç½‘ç»œå¾€å¾€å€¾å‘äºä¸»è¦æ¿€æ´»ç›¸åŒçš„å‡ ä¸ªä¸“å®¶ã€‚è¿™ç§æƒ…å†µå¯èƒ½ä¼šè‡ªæˆ‘åŠ å¼ºï¼Œå› ä¸ºå—æ¬¢è¿çš„ä¸“å®¶è®­ç»ƒå¾—æ›´å¿«ï¼Œå› æ­¤å®ƒä»¬æ›´å®¹æ˜“è¢«é€‰æ‹©ã€‚ä¸ºäº†ç¼“è§£è¿™ä¸ªé—®é¢˜ï¼Œå¼•å…¥äº†ä¸€ä¸ª **è¾…åŠ©æŸå¤±**ï¼Œæ—¨åœ¨é¼“åŠ±ç»™äºˆæ‰€æœ‰ä¸“å®¶ç›¸åŒçš„é‡è¦æ€§ã€‚

è¿™ä¸ªæŸå¤±ç¡®ä¿æ‰€æœ‰ä¸“å®¶æ¥æ”¶åˆ°å¤§è‡´ç›¸ç­‰æ•°é‡çš„è®­ç»ƒæ ·æœ¬ï¼Œä»è€Œå¹³è¡¡äº†ä¸“å®¶ä¹‹é—´çš„é€‰æ‹©ã€‚æ¥ä¸‹æ¥çš„éƒ¨åˆ†è¿˜å°†æ¢è®¨ä¸“å®¶å®¹é‡çš„æ¦‚å¿µï¼Œå®ƒå¼•å…¥äº†ä¸€ä¸ªå…³äºä¸“å®¶å¯ä»¥å¤„ç†å¤šå°‘ä»¤ç‰Œçš„é˜ˆå€¼ã€‚åœ¨ `transformers` åº“ä¸­ï¼Œå¯ä»¥é€šè¿‡ `aux_loss` å‚æ•°æ¥æ§åˆ¶è¾…åŠ©æŸå¤±ã€‚

#### 5 MoEs and Transformers

GShard å°†åœ¨ç¼–ç å™¨å’Œè§£ç å™¨ä¸­çš„æ¯ä¸ªå‰é¦ˆç½‘ç»œ (FFN) å±‚ä¸­çš„æ›¿æ¢ä¸ºä½¿ç”¨ Top-2 é—¨æ§çš„æ··åˆä¸“å®¶æ¨¡å‹ (MoE) å±‚ã€‚

ä¸‹å›¾å±•ç¤ºäº†ç¼–ç å™¨éƒ¨åˆ†çš„ç»“æ„ã€‚è¿™ç§æ¶æ„å¯¹äºå¤§è§„æ¨¡è®¡ç®—éå¸¸æœ‰æ•ˆ: 

> <img src="assets/image-20240419164531925.png" alt="image-20240419164531925" style="zoom:50%;" /> 

**å½“æ‰©å±•åˆ°å¤šä¸ªè®¾å¤‡æ—¶ï¼ŒMoE å±‚åœ¨ä¸åŒè®¾å¤‡é—´å…±äº«ï¼Œè€Œå…¶ä»–æ‰€æœ‰å±‚åˆ™åœ¨æ¯ä¸ªè®¾å¤‡ä¸Šå¤åˆ¶**ã€‚

æˆ‘ä»¬å°†åœ¨ [â€œè®© MoE èµ·é£â€](https://huggingface.co/blog/zh/moe#è®©moeèµ·é£) éƒ¨åˆ†å¯¹è¿™ä¸€ç‚¹è¿›è¡Œæ›´è¯¦ç»†çš„è®¨è®ºã€‚

ä¸ºäº†ä¿æŒè´Ÿè½½å¹³è¡¡å’Œè®­ç»ƒæ•ˆç‡ï¼ŒGShard çš„ä½œè€…é™¤äº†å¼•å…¥äº†ä¸Šä¸€èŠ‚ä¸­è®¨è®ºçš„ç±»ä¼¼è¾…åŠ©æŸå¤±å¤–ï¼Œè¿˜å¼•å…¥äº†ä¸€äº›å…³é”®å˜åŒ–:

- **éšæœºè·¯ç”±**: åœ¨ Top-2 è®¾ç½®ä¸­ï¼Œæˆ‘ä»¬å§‹ç»ˆé€‰æ‹©æ’åæœ€é«˜çš„ä¸“å®¶ï¼Œä½†ç¬¬äºŒä¸ªä¸“å®¶æ˜¯æ ¹æ®å…¶æƒé‡æ¯”ä¾‹éšæœºé€‰æ‹©çš„ã€‚

- **ä¸“å®¶å®¹é‡**: æˆ‘ä»¬å¯ä»¥è®¾å®šä¸€ä¸ªé˜ˆå€¼ï¼Œå®šä¹‰ä¸€ä¸ªä¸“å®¶èƒ½å¤„ç†å¤šå°‘ä»¤ç‰Œã€‚å¦‚æœä¸¤ä¸ªä¸“å®¶çš„å®¹é‡éƒ½è¾¾åˆ°ä¸Šé™ï¼Œä»¤ç‰Œå°±ä¼šæº¢å‡ºï¼Œå¹¶é€šè¿‡æ®‹å·®è¿æ¥ä¼ é€’åˆ°ä¸‹ä¸€å±‚ï¼Œæˆ–åœ¨æŸäº›æƒ…å†µä¸‹è¢«å®Œå…¨ä¸¢å¼ƒã€‚**ä¸“å®¶å®¹é‡æ˜¯ MoE ä¸­æœ€é‡è¦çš„æ¦‚å¿µä¹‹ä¸€**ã€‚

  ä¸ºä»€ä¹ˆéœ€è¦ä¸“å®¶å®¹é‡å‘¢ï¼Ÿ

  å› ä¸ºæ‰€æœ‰å¼ é‡çš„å½¢çŠ¶åœ¨ç¼–è¯‘æ—¶æ˜¯é™æ€ç¡®å®šçš„ï¼Œæˆ‘ä»¬æ— æ³•æå‰çŸ¥é“å¤šå°‘ä»¤ç‰Œä¼šåˆ†é…ç»™æ¯ä¸ªä¸“å®¶ï¼Œå› æ­¤éœ€è¦ä¸€ä¸ªå›ºå®šçš„å®¹é‡å› å­ã€‚

> **æ³¨æ„**: åœ¨æ¨ç†è¿‡ç¨‹ä¸­ï¼Œåªæœ‰éƒ¨åˆ†ä¸“å®¶è¢«æ¿€æ´»ã€‚
>
> åŒæ—¶ï¼Œæœ‰äº›è®¡ç®—è¿‡ç¨‹æ˜¯å…±äº«çš„ï¼Œä¾‹å¦‚è‡ªæ³¨æ„åŠ› (self-attention) æœºåˆ¶ï¼Œå®ƒé€‚ç”¨äºæ‰€æœ‰ä»¤ç‰Œã€‚
>
> è¿™å°±è§£é‡Šäº†ä¸ºä»€ä¹ˆæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ç›¸å½“äº 12B ç¨ å¯†æ¨¡å‹çš„è®¡ç®—èµ„æºæ¥è¿è¡Œä¸€ä¸ªåŒ…å« 8 ä¸ªä¸“å®¶çš„ 47B æ¨¡å‹ã€‚å¦‚æœæˆ‘ä»¬é‡‡ç”¨ Top-2 é—¨æ§ï¼Œæ¨¡å‹ä¼šä½¿ç”¨é«˜è¾¾ 14B çš„å‚æ•°ã€‚ä½†æ˜¯ï¼Œç”±äºè‡ªæ³¨æ„åŠ›æ“ä½œ (ä¸“å®¶é—´å…±äº«) çš„å­˜åœ¨ï¼Œå®é™…ä¸Šæ¨¡å‹è¿è¡Œæ—¶ä½¿ç”¨çš„å‚æ•°æ•°é‡æ˜¯ 12Bã€‚

#### 6 ç¨€ç– VS ç¨ å¯†ï¼Œå¦‚ä½•é€‰æ‹©?

**ç¨€ç–æ··åˆä¸“å®¶æ¨¡å‹ (MoE) é€‚ç”¨äºæ‹¥æœ‰å¤šå°æœºå™¨ä¸”è¦æ±‚é«˜ååé‡çš„åœºæ™¯**ã€‚åœ¨å›ºå®šçš„é¢„è®­ç»ƒè®¡ç®—èµ„æºä¸‹ï¼Œç¨€ç–æ¨¡å‹å¾€å¾€èƒ½å¤Ÿå®ç°æ›´ä¼˜çš„æ•ˆæœã€‚ç›¸åï¼Œåœ¨æ˜¾å­˜è¾ƒå°‘ä¸”ååé‡è¦æ±‚ä¸é«˜çš„åœºæ™¯ï¼Œç¨ å¯†æ¨¡å‹åˆ™æ˜¯æ›´åˆé€‚çš„é€‰æ‹©ã€‚

**æ³¨æ„**: ç›´æ¥æ¯”è¾ƒç¨€ç–æ¨¡å‹å’Œç¨ å¯†æ¨¡å‹çš„å‚æ•°æ•°é‡æ˜¯ä¸æ°å½“çš„ï¼Œå› ä¸ºè¿™ä¸¤ç±»æ¨¡å‹åŸºäºçš„æ¦‚å¿µå’Œå‚æ•°é‡çš„è®¡ç®—æ–¹æ³•å®Œå…¨ä¸åŒã€‚ 

### â‘¢ Merge Model 

> [Merge LLMs with mergekit](https://mlabonne.github.io/blog/posts/2024-01-08_Merge_LLMs_with_mergekit.html): Tutorial about model merging using mergekit.

æ¨¡å‹åˆå¹¶æ˜¯ä¸€ç§å°†ä¸¤ä¸ªæˆ–å¤šä¸ª LLM åˆå¹¶ä¸ºä¸€ä¸ªæ¨¡å‹çš„æŠ€æœ¯ã€‚è¿™æ˜¯ä¸€ç§ç›¸å¯¹è¾ƒæ–°çš„å®éªŒæ€§æ–¹æ³•ï¼Œå¯ä»¥å»‰ä»·åˆ›å»ºæ–°æ¨¡å‹ï¼ˆæ— éœ€ GPUï¼‰ã€‚æ¨¡å‹åˆå¹¶çš„æ•ˆæœå‡ºå¥‡åœ°å¥½ï¼Œåœ¨å¼€æ”¾ LLM æ’è¡Œæ¦œä¸Šäº§ç”Ÿäº†è®¸å¤šæœ€å…ˆè¿›çš„æ¨¡å‹ã€‚
